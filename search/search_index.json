{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to our website.</p>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"course-description/","title":"Course Description for Conversational AI","text":"<p>Title: Conversational AI Grade Level: College Sophomores</p>"},{"location":"course-description/#why-this-course","title":"Why This Course?","text":"<p>Ever wondered how ChatGPT, Alexa, or customer service bots actually work? Want to build AI systems that can hold intelligent conversations, answer questions, and solve real problems? This course takes you from \"Hello, World!\" to deploying production-ready conversational AI systems that people will actually want to use.</p> <p>You'll start by building a simple chatbot in Week 2, and by the end of the semester, you'll have created sophisticated AI agents that understand context, search massive knowledge bases in milliseconds, and integrate with real databases\u2014all while keeping user data secure and private.</p> <p>This isn't just theory. You'll write code, ship projects, and build a portfolio that demonstrates real AI engineering skills. Whether you're eyeing a career in AI, want to add conversational interfaces to your projects, or are just fascinated by how machines learn to \"talk,\" this course will get you there.</p>"},{"location":"course-description/#prerequisites","title":"Prerequisites","text":"<p>What you need to get started:</p> <ul> <li>Basic Python programming (if you can write functions and loops or use Claude, you're good!)</li> <li>Comfort with terminal/shell commands (or willingness to learn in Weeks 1-2)</li> <li>VSCode IDE installed on your computer</li> <li>GitHub account (free) for sharing your projects</li> </ul> <p>Designed for Accessibility</p> <p>We've intentionally kept prerequisites minimal.  Non-CS majors are welcome! If you're new to GitHub or command-line tools, expect to invest extra time in the first two weeks getting up to speed. We'll provide resources and support to help you succeed.  If you have never used the terminal or GitHub we strongly suggest you use Anthropic Claude or ChatGPT.</p>"},{"location":"course-description/#course-overview-your-journey-from-novice-to-ai-engineer","title":"Course Overview: Your Journey from Novice to AI Engineer","text":""},{"location":"course-description/#act-i-foundations-weeks-1-4","title":"Act I: Foundations (Weeks 1-4)","text":"<p>Build your first chatbot and master the fundamentals</p> <p>You'll dive right in, building a working chatbot that answers questions from text files\u2014no AI magic yet, just smart keyword matching. Along the way, you'll discover why traditional search falls short and what makes semantic search so powerful. We'll explore how to measure search quality using precision, recall, and F-measures, giving you the vocabulary to talk about AI systems like a professional.</p> <p>Next, you'll peek under the hood at search performance, learning how reverse indexes and Page Rank make Google-scale search possible. Then comes the exciting part: Large Language Models (LLMs), tokenization, and natural language understanding. You'll learn to analyze FAQs, model user intent, and implement feedback loops that make your chatbot smarter over time.</p>"},{"location":"course-description/#act-ii-advanced-architectures-weeks-5-9","title":"Act II: Advanced Architectures (Weeks 5-9)","text":"<p>Level up with embeddings, vector stores, and RAG</p> <p>This is where it gets really interesting. You'll discover embeddings\u2014the mathematical representation of meaning that powers modern AI\u2014and learn to build vector stores that enable semantic search. We'll introduce the RAG (Retrieval Augmented Generation) pattern, the architecture behind most production chatbots today.</p> <p>But here's the kicker: RAG has limitations. You'll learn exactly what they are, then build something better\u2014GraphRAG. This cutting-edge approach uses curated knowledge graphs that become the \"central nervous system\" of organizations, connecting information in ways that simple retrieval can't match.</p>"},{"location":"course-description/#act-iii-production-systems-weeks-10-14","title":"Act III: Production Systems (Weeks 10-14)","text":"<p>Build real-world systems with databases, security, and dashboards</p> <p>Now you'll connect your chatbots to actual database services, learning to match natural language questions to structured queries and extract parameters on the fly. (\"Show me sales for Q3\" becomes <code>SELECT * FROM sales WHERE quarter = 3</code>\u2014automatically!)</p> <p>We'll tackle the serious stuff: user context, security, role-based access control, and privacy concerns. You'll learn to build chatbot dashboards with KPIs, analyze usage patterns with Pareto analysis, and tune performance for real-world deployment.</p>"},{"location":"course-description/#the-finale-your-capstone-project","title":"The Finale: Your Capstone Project","text":"<p>Bring it all together</p> <p>You'll design and build a complete conversational AI system that showcases everything you've learned\u2014your portfolio piece that demonstrates you can ship production-quality AI applications.</p>"},{"location":"course-description/#what-makes-this-course-different","title":"What Makes This Course Different","text":"<p>Hands-on from Day 1: No endless lectures\u2014you'll build working systems immediately and using AI to help get unstuck Real tools, real frameworks: Use the same technologies deployed in production by companies worldwide Progressive complexity: Each project builds on the last, creating a clear learning path Career-focused: Every skill taught is directly applicable to AI engineering roles Privacy and ethics integrated: Learn to build responsible AI systems, not just powerful ones</p>"},{"location":"course-description/#topics-covered-the-complete-skillset","title":"Topics Covered: The Complete Skillset","text":""},{"location":"course-description/#ai-fundamentals-context","title":"AI Fundamentals &amp; Context","text":"<ul> <li>Artificial Intelligence fundamentals - Understanding the landscape</li> <li>AI Timelines - How we got here and where we're going</li> <li>AI Doubling Rate - Why AI is accelerating faster than Moore's Law</li> <li>Corporate Nervous Systems - How AI becomes organizational infrastructure</li> </ul>"},{"location":"course-description/#search-technologies-from-simple-to-semantic","title":"Search Technologies (From Simple to Semantic)","text":"<ul> <li>Traditional Search - Grep, keyword search, and their limitations</li> <li>Advanced Search Techniques - Synonym expansion, ontology enrichment, metadata tagging</li> <li>Semantic Search - Understanding meaning, not just keywords</li> <li>Search Performance - Reverse indexes, Page Rank, and scaling to billions of documents</li> <li>Vector Search &amp; TF-IDF - The math behind modern search</li> </ul>"},{"location":"course-description/#natural-language-processing","title":"Natural Language Processing","text":"<ul> <li>NLP Fundamentals - How machines understand human language</li> <li>Tokenization - Breaking language into processable units</li> <li>Intent Modeling - Understanding what users really want</li> <li>FAQ Analysis - Extracting patterns from common questions</li> <li>NLP Pipelines - Production-ready text processing systems</li> <li>Entity Extraction - Identifying people, places, things, and concepts automatically</li> </ul>"},{"location":"course-description/#large-language-models-llms","title":"Large Language Models (LLMs)","text":"<ul> <li>LLM Architecture - How ChatGPT-style models work (without building them from scratch)</li> <li>Embeddings - The vector representations that power semantic understanding</li> <li>Vector Stores - Storing and searching billions of embeddings efficiently</li> </ul>"},{"location":"course-description/#conversational-ai-architectures","title":"Conversational AI Architectures","text":"<ul> <li>Building Your First Chatbot - From idea to implementation</li> <li>The RAG Pattern - Retrieval Augmented Generation in depth</li> <li>Limitations of RAG - When retrieval isn't enough</li> <li>The GraphRAG Pattern - Next-generation architecture using knowledge graphs</li> <li>Knowledge Graphs - Structuring knowledge for AI systems</li> <li>Graph Databases &amp; Cypher - Neo4j and graph query languages</li> </ul>"},{"location":"course-description/#search-quality-metrics","title":"Search Quality &amp; Metrics","text":"<ul> <li>Precision &amp; Recall - The fundamental tradeoff</li> <li>F-Measures &amp; F1 - Combining metrics for holistic evaluation</li> <li>Measuring Response Quality - Beyond accuracy</li> <li>Chatbot KPIs - Metrics that matter in production</li> <li>Acceptance Rate - Are users satisfied?</li> <li>Query Frequency Analysis - Using Pareto principles to prioritize improvements</li> </ul>"},{"location":"course-description/#production-systems-engineering","title":"Production Systems Engineering","text":"<ul> <li>Database Integration - Connecting chatbots to real data</li> <li>Query Execution - From natural language to SQL</li> <li>Parameter Extraction - Pulling structured data from conversations</li> <li>User Context - Maintaining conversation state</li> <li>Security &amp; Privacy - Protecting user data</li> <li>Role-based Access Control - Who can ask what?</li> <li>Logging &amp; Monitoring - Tracking conversations responsibly</li> <li>Privacy Considerations - Handling PII in chat logs</li> </ul>"},{"location":"course-description/#user-experience-feedback","title":"User Experience &amp; Feedback","text":"<ul> <li>User Interfaces - Building chatbot UIs that people love</li> <li>Feedback Mechanisms - Thumbs up/down and beyond</li> <li>The AI Flywheel - Using feedback to continuously improve</li> <li>Chatbot Dashboards - Visualizing performance</li> </ul>"},{"location":"course-description/#tools-frameworks","title":"Tools &amp; Frameworks","text":"<ul> <li>Chatbot Frameworks - Industry-standard tools and when to use them</li> <li>JavaScript Libraries - Frontend integration</li> <li>Performance Tuning - Making chatbots fast and efficient</li> <li>Performance Tradeoffs - Balancing speed, accuracy, and cost</li> </ul>"},{"location":"course-description/#professional-development","title":"Professional Development","text":"<ul> <li>Team Projects - Collaborating on AI systems</li> <li>Capstone Project - Your portfolio showcase</li> <li>Chatbot Careers - Where this skillset takes you</li> <li>External vs. Internal Knowledge - Public data vs. private organizational knowledge</li> </ul>"},{"location":"course-description/#what-were-not-covering-and-why","title":"What We're NOT Covering (And Why)","text":"<p>This course focuses on building and deploying conversational AI systems, not on the underlying ML theory. We deliberately skip:</p> <ul> <li>Deep neural network internals - You'll use pre-trained models, not build them from scratch</li> <li>LLM training &amp; customization - Training GPT-style models requires millions in compute; we'll teach you to use them effectively instead</li> <li>LLM performance optimization - Advanced model optimization is its own semester-long course</li> <li>Semantic web technologies (SPARQL, RDF, Triples) - Historically interesting but not part of modern graph databases and conversational AI</li> </ul> <p>The philosophy: We teach you to build AI systems that solve real problems today, using production tools and best practices. Deep learning theory and semantic web protocols are fascinating but won't help you ship your first chatbot.</p>"},{"location":"course-description/#learning-objectives-what-youll-actually-be-able-to-do","title":"Learning Objectives: What You'll Actually Be Able to Do","text":"<p>We've structured this course around Bloom's Taxonomy to ensure you don't just memorize facts\u2014you'll develop deep understanding and hands-on skills. Here's what you'll master:</p>"},{"location":"course-description/#remember","title":"Remember","text":"<ul> <li>Define key terms including LLM, tokenization, embeddings, vector stores, and RAG</li> <li>List the components of a conversational AI system</li> <li>Identify the differences between keyword search and semantic search</li> <li>Recall the metrics used to measure search quality (precision, recall, F-measures)</li> <li>Name common chatbot frameworks and JavaScript libraries</li> <li>Recognize the structure of NLP pipelines</li> </ul>"},{"location":"course-description/#understand","title":"Understand","text":"<ul> <li>Explain how semantic search improves upon traditional keyword search</li> <li>Describe the RAG (Retrieval Augmented Generation) pattern and its components</li> <li>Summarize the limitations of RAG and how GraphRAG addresses them</li> <li>Discuss the role of reverse indexes and Page Rank in search performance</li> <li>Explain how embeddings and vector stores enable semantic search</li> <li>Interpret chatbot KPIs and dashboard metrics</li> <li>Clarify the importance of knowledge graphs as organizational nervous systems</li> </ul>"},{"location":"course-description/#apply","title":"Apply","text":"<ul> <li>Build a simple chatbot using keyword search</li> <li>Implement a RAG-based chatbot using embeddings and vector stores</li> <li>Use NLP pipelines to process and analyze text</li> <li>Apply TF-IDF techniques for text analysis</li> <li>Configure logging for chatbot responses</li> <li>Execute queries with extracted parameters from user questions</li> <li>Implement role-based access control for chatbot queries</li> </ul>"},{"location":"course-description/#analyze","title":"Analyze","text":"<ul> <li>Compare the effectiveness of keyword search versus semantic search</li> <li>Examine chatbot logs to identify frequently asked questions with incorrect answers</li> <li>Perform Pareto analysis on query frequency data</li> <li>Break down the differences between RAG and GraphRAG patterns</li> <li>Differentiate between external public knowledge and internal private knowledge sources</li> <li>Analyze user feedback to improve chatbot performance</li> <li>Investigate privacy concerns related to storing PII in chat logs</li> </ul>"},{"location":"course-description/#evaluate","title":"Evaluate","text":"<ul> <li>Assess chatbot response quality using appropriate metrics</li> <li>Critique the trade-offs between different search approaches</li> <li>Judge the acceptance rate and user satisfaction of chatbot responses</li> <li>Evaluate the security implications of query execution and user permissions</li> <li>Determine which chatbot framework best fits specific use cases</li> <li>Appraise the performance trade-offs in chatbot design decisions</li> <li>Measure and evaluate the effectiveness of intent modeling approaches</li> </ul>"},{"location":"course-description/#create","title":"Create","text":"<ul> <li>Design and develop a complete RAG-based chatbot system</li> <li>Construct a GraphRAG implementation with curated knowledge graphs</li> <li>Generate a chatbot dashboard with relevant KPIs and metrics</li> <li>Develop an entity extraction system for building knowledge graphs</li> <li>Design a query matching system that extracts parameters from natural language questions</li> <li>Produce a comprehensive chatbot evaluation framework</li> <li>Complete a capstone project integrating multiple conversational AI concepts</li> </ul>"},{"location":"course-description/#grading","title":"Grading","text":"<ul> <li>Homework and class participation (25%)</li> <li>Midterm project (15%)</li> <li>Final capstone project (35%)</li> <li>Final exam - in person Q&amp;A with instructor (25%)</li> </ul>"},{"location":"feedback/","title":"Feedback on Graph Data Modeling","text":"<p>You are welcome to connect with me on anytime on LinkedIn or submit any issues to GitHub Issue Log.  All pull-requests with fixes to errors or additions are always welcome.</p> <p>If you would like to fill out a short survey and give us ideas on how we can create better tools for intelligent textbooks in the future.</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#term","title":"Term","text":"<p>This is the definition of the term.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Site References","text":"<ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"chapters/","title":"Chapters","text":"<p>This textbook is organized into 14 chapters covering 200 concepts in Conversational AI.</p>"},{"location":"chapters/#chapter-overview","title":"Chapter Overview","text":"<ol> <li> <p>Foundations of Artificial Intelligence and Natural Language Processing - This chapter introduces core AI concepts, timelines, and foundational NLP principles including text processing, string matching, and regular expressions.</p> </li> <li> <p>Search Technologies and Indexing Techniques - This chapter covers fundamental search approaches including keyword search, search indexing, inverted indexes, full-text search, and Boolean search operators.</p> </li> <li> <p>Semantic Search and Quality Metrics - This chapter explores advanced search techniques including synonym expansion, ontologies, taxonomies, semantic search, TF-IDF, Page Rank, and introduces search quality metrics like precision, recall, F-measures, and confusion matrices.</p> </li> <li> <p>Large Language Models and Tokenization - This chapter introduces large language models, transformer architecture, attention mechanisms, and various tokenization techniques including byte pair encoding.</p> </li> <li> <p>Embeddings and Vector Databases - This chapter covers word embeddings, embedding vectors, vector space models, embedding models (Word2Vec, GloVe, FastText), sentence embeddings, vector databases, and approximate nearest neighbor search algorithms.</p> </li> <li> <p>Building Chatbots and Intent Recognition - This chapter introduces chatbots, conversational agents, dialog systems, intent recognition and modeling, entity extraction, and FAQ systems.</p> </li> <li> <p>Chatbot Frameworks and User Interfaces - This chapter explores chatbot frameworks (Rasa, Dialogflow, LangChain, LlamaIndex), JavaScript libraries, user interface design, chat interfaces, and session management.</p> </li> <li> <p>User Feedback and Continuous Improvement - This chapter covers user feedback mechanisms, feedback buttons, the AI flywheel, continuous improvement cycles, user context, personalization, and chat history management.</p> </li> <li> <p>The Retrieval Augmented Generation Pattern - This chapter introduces the RAG pattern, external and internal knowledge sources, document corpus management, retrieval steps, augmentation, generation, context windows, prompt engineering, and RAG limitations including hallucination.</p> </li> <li> <p>Knowledge Graphs and GraphRAG - This chapter covers knowledge graphs, graph databases, nodes, edges, triples, RDF, graph query languages (OpenCypher, Cypher), Neo4j, GraphRAG patterns, and corporate nervous systems.</p> </li> <li> <p>NLP Pipelines and Text Processing - This chapter explores NLP pipelines, text preprocessing, normalization, stemming, lemmatization, part-of-speech tagging, dependency parsing, and coreference resolution.</p> </li> <li> <p>Database Queries and Parameter Extraction - This chapter covers database queries, SQL, query parameters, parameter extraction, query templates, parameterized queries, natural language to SQL conversion, and slot filling techniques.</p> </li> <li> <p>Security, Privacy, and User Management - This chapter addresses security, authentication, authorization, role-based access control (RBAC), data privacy, PII, GDPR compliance, data retention, logging systems, and log analysis.</p> </li> <li> <p>Evaluation, Optimization, and Career Development - This chapter covers chatbot evaluation metrics, KPIs, dashboards, acceptance rates, user satisfaction, response accuracy, A/B testing, performance tuning, optimization strategies, team projects, capstone projects, and chatbot career paths.</p> </li> </ol>"},{"location":"chapters/#how-to-use-this-textbook","title":"How to Use This Textbook","text":"<p>Progress through the chapters sequentially, as each chapter builds on concepts from previous chapters. The textbook follows a pedagogical progression from foundational AI concepts through search technologies, language models, embeddings, chatbot development, advanced patterns like RAG and GraphRAG, and finally security and evaluation topics. Dependencies between concepts are carefully respected to ensure a smooth learning experience.</p> <p>Note: Each chapter includes a list of concepts covered. Make sure to complete prerequisites before moving to advanced chapters.</p>"},{"location":"chapters/01-foundations-ai-nlp/","title":"Foundations of Artificial Intelligence and Natural Language Processing","text":""},{"location":"chapters/01-foundations-ai-nlp/#summary","title":"Summary","text":"<p>This chapter introduces the foundational concepts of artificial intelligence and natural language processing that underpin all conversational AI systems. You will learn about the history and evolution of AI, key milestones in AI development, and fundamental NLP techniques for text processing. By the end of this chapter, you will understand core AI principles, the exponential growth of AI capabilities, and basic text manipulation techniques including string matching and regular expressions.</p>"},{"location":"chapters/01-foundations-ai-nlp/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 9 concepts from the learning graph:</p> <ol> <li>Artificial Intelligence</li> <li>AI Timeline</li> <li>AI Doubling Rate</li> <li>Moore's Law</li> <li>Natural Language Processing</li> <li>Text Processing</li> <li>String Matching</li> <li>Regular Expressions</li> <li>Grep Command</li> </ol>"},{"location":"chapters/01-foundations-ai-nlp/#prerequisites","title":"Prerequisites","text":"<p>This chapter assumes only the prerequisites listed in the course description. No prior AI or NLP knowledge is required.</p>"},{"location":"chapters/01-foundations-ai-nlp/#introduction-to-artificial-intelligence","title":"Introduction to Artificial Intelligence","text":"<p>Artificial Intelligence (AI) represents one of the most transformative technological developments of the modern era, fundamentally changing how machines interact with information, make decisions, and communicate with humans. At its core, AI encompasses computational systems that can perform tasks traditionally requiring human intelligence, such as visual perception, speech recognition, decision-making, and language translation. This chapter establishes the foundational knowledge needed to understand conversational AI systems by exploring the historical evolution of AI, the exponential growth in computational capabilities, and the fundamental natural language processing techniques that enable machines to understand and generate human language.</p> <p>The field of AI has progressed from early theoretical foundations in the 1950s to today's sophisticated systems that power virtual assistants, chatbots, and language translation services. Understanding this progression provides crucial context for the conversational AI techniques we'll explore throughout this course. Moreover, grasping the exponential nature of AI advancement helps explain why capabilities that seemed impossible a decade ago are now commonplace in consumer applications.</p>"},{"location":"chapters/01-foundations-ai-nlp/#what-is-artificial-intelligence","title":"What is Artificial Intelligence?","text":"<p>Artificial Intelligence refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning (acquiring information and rules for using it), reasoning (using rules to reach approximate or definite conclusions), and self-correction. Modern AI systems typically fall into several categories:</p> <ul> <li>Narrow AI (Weak AI): Systems designed to perform specific tasks, such as facial recognition, voice assistants, or recommendation algorithms</li> <li>General AI (Strong AI): Hypothetical systems with human-like cognitive abilities across diverse domains (not yet achieved)</li> <li>Machine Learning: AI systems that improve automatically through experience without being explicitly programmed</li> <li>Deep Learning: ML approaches using neural networks with multiple layers to progressively extract higher-level features from raw input</li> </ul> <p>Contemporary conversational AI systems primarily leverage narrow AI techniques, specifically those from natural language processing and machine learning. These systems excel at understanding and generating human language within defined contexts, though they lack the general reasoning capabilities of human intelligence.</p> Evolution of Artificial Intelligence Timeline     Type: timeline      Purpose: Illustrate the major milestones in AI development from its inception to modern conversational AI systems      Time period: 1950-2025      Orientation: Horizontal      Events:     - 1950: Alan Turing publishes \"Computing Machinery and Intelligence,\" proposing the Turing Test     - 1956: Dartmouth Conference coins the term \"Artificial Intelligence\" (John McCarthy, Marvin Minsky, et al.)     - 1957: Perceptron algorithm developed by Frank Rosenblatt (early neural network)     - 1966: ELIZA chatbot created by Joseph Weizenbaum (pattern matching conversation)     - 1969-1979: First AI Winter (reduced funding due to unmet expectations)     - 1980-1987: Expert systems boom (rule-based AI for specialized domains)     - 1987-1993: Second AI Winter (expert systems limitations, hardware constraints)     - 1997: IBM Deep Blue defeats world chess champion Garry Kasparov     - 2006: Geoffrey Hinton revitalizes deep learning with breakthrough in training deep networks     - 2011: IBM Watson wins Jeopardy! using natural language processing     - 2012: AlexNet wins ImageNet competition, sparking deep learning revolution     - 2014: Generative Adversarial Networks (GANs) introduced by Ian Goodfellow     - 2017: Transformer architecture published (\"Attention Is All You Need\" paper)     - 2018: BERT (Bidirectional Encoder Representations from Transformers) released by Google     - 2020: GPT-3 demonstrates few-shot learning with 175 billion parameters     - 2022: ChatGPT launches, bringing conversational AI to mainstream adoption     - 2023: GPT-4 and competing models achieve multimodal capabilities     - 2024-2025: Widespread enterprise adoption of conversational AI and RAG systems      Visual style: Horizontal timeline with alternating above/below placement      Color coding:     - Blue: Foundational research era (1950-1980)     - Red: AI Winter periods (1969-1979, 1987-1993)     - Orange: Expert systems and traditional AI (1980-2000)     - Purple: Modern ML renaissance (2000-2012)     - Green: Deep learning era (2012-2020)     - Gold: Transformer and LLM era (2017-present)      Interactive features:     - Hover over each milestone to see detailed description and impact     - Click to expand with key figures and publications     - Highlight different eras by clicking color-coded legend      Implementation: vis-timeline JavaScript library with custom styling  <p>The timeline above demonstrates several critical patterns in AI development. First, progress has been non-linear, with periods of rapid advancement followed by \"AI winters\" when funding and interest declined due to unmet expectations. Second, breakthrough moments often resulted from novel algorithms combined with increased computational power and available data. The 2012 deep learning revolution, for instance, succeeded because GPU computing made training large neural networks practical, while internet-scale datasets provided training material.</p>"},{"location":"chapters/01-foundations-ai-nlp/#the-exponential-growth-of-ai-capabilities","title":"The Exponential Growth of AI Capabilities","text":"<p>Understanding AI's rapid advancement requires examining two interconnected phenomena: Moore's Law and the AI doubling rate. These concepts explain why AI capabilities that were science fiction in the 1990s are now embedded in everyday consumer devices.</p>"},{"location":"chapters/01-foundations-ai-nlp/#moores-law-and-computing-power","title":"Moore's Law and Computing Power","text":"<p>Moore's Law, named after Intel co-founder Gordon Moore, observes that the number of transistors on integrated circuits doubles approximately every two years, leading to exponential increases in computational power while costs decrease. First articulated in 1965, this trend has held remarkably consistent for over five decades, enabling the progression from room-sized mainframes to smartphones with processing power exceeding 1990s supercomputers.</p> <p>For AI development, Moore's Law has profound implications. Training complex neural networks requires massive computational resources\u2014modern large language models consume millions of GPU-hours during training. The exponential increase in available computing power has made previously infeasible AI approaches practical. Deep learning, which requires training networks with millions or billions of parameters, became viable only when GPU computing could process the necessary calculations in reasonable timeframes.</p> <p>The relationship between computational power and AI capability is captured in the following comparison:</p> Era Representative System Transistor Count AI Capability Example Application 1970s Intel 4004 2,300 Rule-based expert systems Medical diagnosis (MYCIN) 1990s Pentium Pro 5.5 million Statistical ML, decision trees Spam filtering 2000s Intel Core 2 291 million Support vector machines, basic NLP Search engine ranking 2010s Intel Core i7 (Skylake) 1.75 billion Deep learning, CNNs Image recognition 2020s Apple M1 Max 57 billion Transformer models, LLMs Conversational AI, ChatGPT"},{"location":"chapters/01-foundations-ai-nlp/#ai-doubling-rate","title":"AI Doubling Rate","text":"<p>While Moore's Law describes hardware capability growth, the AI doubling rate measures the exponential improvement in AI performance on specific tasks. Research from OpenAI and others demonstrates that AI capabilities have been doubling approximately every 3.4 months in recent years, far exceeding Moore's Law's two-year doubling period. This acceleration results from algorithmic innovations, better training techniques, larger datasets, and architectural improvements, not merely hardware advances.</p> AI Performance Doubling Rate Visualization     Type: chart      Chart type: Line chart with logarithmic Y-axis      Purpose: Show the exponential improvement in AI performance on ImageNet classification task from 2010-2023, demonstrating doubling rate faster than Moore's Law      X-axis: Year (2010-2023)     Y-axis: ImageNet Top-5 Error Rate (%, logarithmic scale from 1% to 50%)      Data series:     1. AI Performance (blue line with markers):        - 2010: 28.2% error (baseline)        - 2011: 25.8% error        - 2012: 16.4% error (AlexNet breakthrough)        - 2013: 11.7% error        - 2014: 7.3% error (GoogLeNet, VGG)        - 2015: 3.6% error (ResNet)        - 2016: 3.0% error        - 2017: 2.3% error (squeeze-and-excitation networks)        - 2018-2023: 1.0-2.0% error (surpassing human performance)      2. Human Performance (horizontal red dashed line):        - Constant at 5.1% error across all years      3. Moore's Law Projected Improvement (orange dotted line):        - Starting at 28.2% in 2010        - Showing theoretical improvement if progress followed hardware doubling (2-year cycle)        - Much slower than actual AI improvement      Title: \"AI Performance Improvement Exceeds Moore's Law\"     Subtitle: \"ImageNet Top-5 Classification Error Rate (2010-2023)\"      Legend: Position top-right      Annotations:     - Arrow at 2012: \"AlexNet: Deep learning breakthrough\"     - Arrow at 2015: \"ResNet: Residual connections enable very deep networks\"     - Horizontal line at human performance: \"Human-level performance (5.1%)\"     - Shaded region below human performance: \"Superhuman performance\"      Key insights callout box:     - \"AI performance doubled every 3.4 months from 2012-2018\"     - \"Exceeded Moore's Law improvement rate by 7x\"     - \"Surpassed human performance in 2015\"      Implementation: Chart.js with logarithmic scale plugin     Canvas size: 800x500px  <p>This acceleration has profound implications for conversational AI. Language understanding capabilities that required extensive manual rule crafting in the 1990s (like ELIZA's pattern matching) now emerge from training large transformer models on internet-scale text corpora. The GPT series exemplifies this trend: GPT-1 (2018) had 117 million parameters, GPT-2 (2019) had 1.5 billion, GPT-3 (2020) had 175 billion, and GPT-4 (2023) is estimated to have over 1 trillion parameters, with each generation demonstrating qualitatively new capabilities.</p>"},{"location":"chapters/01-foundations-ai-nlp/#natural-language-processing-fundamentals","title":"Natural Language Processing Fundamentals","text":"<p>Natural Language Processing (NLP) constitutes the subfield of AI focused on enabling computers to understand, interpret, and generate human language. Unlike programming languages with rigid syntax and unambiguous semantics, natural languages exhibit ambiguity, context-dependence, and cultural variation. NLP systems must handle these complexities while extracting meaningful information from text or speech.</p> <p>Modern conversational AI systems rely heavily on NLP techniques across several stages:</p> <ul> <li>Preprocessing: Cleaning and normalizing text (removing punctuation, converting to lowercase, handling special characters)</li> <li>Tokenization: Breaking text into individual units (words, subwords, or characters)</li> <li>Linguistic Analysis: Understanding grammar, parts of speech, and sentence structure</li> <li>Semantic Understanding: Extracting meaning, intent, and context</li> <li>Generation: Producing grammatically correct and contextually appropriate responses</li> </ul> <p>This course focuses primarily on conversational AI applications, but understanding fundamental text processing techniques provides essential groundwork for the more advanced embedding and transformer-based approaches we'll explore in later chapters.</p>"},{"location":"chapters/01-foundations-ai-nlp/#text-processing-basics","title":"Text Processing Basics","text":"<p>Before applying sophisticated machine learning models, NLP systems typically perform basic text processing to standardize and clean input data. These preprocessing steps ensure consistency and reduce noise that could confuse downstream algorithms.</p> <p>Common text processing operations include:</p> <ol> <li>Case normalization: Converting all text to lowercase to treat \"Python,\" \"python,\" and \"PYTHON\" as identical</li> <li>Whitespace handling: Removing extra spaces, tabs, and newlines</li> <li>Punctuation processing: Either removing or standardizing punctuation marks</li> <li>Number handling: Deciding whether to preserve numeric values or convert them to text</li> <li>Special character removal: Filtering out emoji, symbols, or non-alphanumeric characters depending on application needs</li> </ol> <p>Consider processing user input to a chatbot. The raw input \"Hello!!!   How's your  performance today?\" might be normalized to \"hello how's your performance today\" before further analysis. This standardization ensures that pattern matching and text search operations function reliably.</p> Text Processing Pipeline Workflow     Type: workflow      Purpose: Illustrate the typical stages in preprocessing text for NLP applications      Visual style: Flowchart with process rectangles connected by arrows      Steps:     1. Start: \"Raw Text Input\"        Hover text: \"Example: 'Hello!!! How's your performance TODAY? :)'\"      2. Process: \"Lowercase Conversion\"        Hover text: \"Convert all characters to lowercase for case-insensitive matching\"        Result: \"hello!!! how's your performance today? :)\"      3. Process: \"Special Character Removal\"        Hover text: \"Remove or replace emoji, excessive punctuation, and non-alphanumeric characters\"        Result: \"hello how's your performance today\"      4. Process: \"Whitespace Normalization\"        Hover text: \"Replace multiple spaces with single space, trim leading/trailing whitespace\"        Result: \"hello how's your performance today\"      5. Decision: \"Keep Punctuation?\"        Hover text: \"Application-dependent: keep for sentence splitting, remove for keyword matching\"      6a. Process: \"Remove Punctuation\" (if No)         Hover text: \"Strip all punctuation marks\"         Result: \"hello hows your performance today\"      6b. Process: \"Preserve Punctuation\" (if Yes)         Hover text: \"Maintain punctuation for sentence boundary detection\"         Result: \"hello how's your performance today\"      7. Process: \"Tokenization\"        Hover text: \"Split text into individual tokens (words or subwords)\"        Result: \"['hello', 'how's', 'your', 'performance', 'today']\"      8. Decision: \"Apply Stemming/Lemmatization?\"        Hover text: \"Reduce words to root forms (e.g., 'running' \u2192 'run')\"      9a. Process: \"Apply Morphological Processing\" (if Yes)         Hover text: \"Stemming (simple suffix removal) or lemmatization (dictionary-based root forms)\"      9b. Process: \"Keep Original Tokens\" (if No)         Hover text: \"Preserve original word forms\"      10. End: \"Processed Tokens Ready for Analysis\"         Hover text: \"Clean tokens ready for search, classification, or embedding\"      Color coding:     - Light blue: Input/output     - Green: Text transformation steps     - Yellow: Decision points     - Purple: Final tokenization      Implementation: Mermaid.js flowchart     Canvas size: 800x700px"},{"location":"chapters/01-foundations-ai-nlp/#string-matching-techniques","title":"String Matching Techniques","text":"<p>String matching forms the foundation of text search and pattern recognition. At its simplest, string matching determines whether a specific sequence of characters (the pattern) appears within a larger text (the target). While modern NLP systems employ sophisticated semantic search techniques, understanding basic string matching remains essential for tasks like exact keyword search, code analysis, and log file processing.</p>"},{"location":"chapters/01-foundations-ai-nlp/#exact-matching","title":"Exact Matching","text":"<p>Exact string matching searches for literal character sequences. In Python, this is straightforward using the <code>in</code> operator or string methods:</p> <pre><code>text = \"natural language processing enables conversational ai\"\npattern = \"language processing\"\n\nif pattern in text:\n    print(f\"Found '{pattern}' in text\")\n# Output: Found 'language processing' in text\n</code></pre> <p>Exact matching proves useful for finding specific terms, codes, or identifiers but fails when text variations exist. Searching for \"color\" won't find \"colour,\" and searching for \"AI\" won't match \"artificial intelligence\" unless explicitly programmed to handle synonyms.</p>"},{"location":"chapters/01-foundations-ai-nlp/#case-insensitive-matching","title":"Case-Insensitive Matching","text":"<p>Many search scenarios require case-insensitive matching. This can be achieved by normalizing both the pattern and text to the same case:</p> <pre><code>text = \"Natural Language Processing enables Conversational AI\"\npattern = \"LANGUAGE PROCESSING\"\n\nif pattern.lower() in text.lower():\n    print(\"Match found (case-insensitive)\")\n</code></pre>"},{"location":"chapters/01-foundations-ai-nlp/#substring-search-and-position-finding","title":"Substring Search and Position Finding","text":"<p>Beyond boolean matching (does the pattern exist?), applications often need to locate where patterns occur or extract surrounding context:</p> <pre><code>text = \"NLP includes tokenization, parsing, and semantic analysis\"\npattern = \"parsing\"\n\nposition = text.find(pattern)\nif position != -1:\n    print(f\"Found '{pattern}' at position {position}\")\n    # Extract context: 10 characters before and after\n    start = max(0, position - 10)\n    end = min(len(text), position + len(pattern) + 10)\n    context = text[start:end]\n    print(f\"Context: ...{context}...\")\n</code></pre>"},{"location":"chapters/01-foundations-ai-nlp/#regular-expressions-for-pattern-matching","title":"Regular Expressions for Pattern Matching","text":"<p>While exact string matching handles literal text search, regular expressions (regex) provide a powerful language for describing text patterns. Regular expressions allow matching classes of strings rather than specific strings, enabling flexible pattern recognition essential for many NLP tasks.</p> <p>A regular expression defines a search pattern using ordinary characters (like 'a' or '1') combined with special metacharacters that represent classes or quantities of characters:</p> <p>Common regex metacharacters and patterns:</p> Pattern Meaning Example Matches <code>.</code> Any single character <code>c.t</code> \"cat\", \"cot\", \"c9t\" <code>*</code> Zero or more of preceding <code>ab*c</code> \"ac\", \"abc\", \"abbc\" <code>+</code> One or more of preceding <code>ab+c</code> \"abc\", \"abbc\" (not \"ac\") <code>?</code> Zero or one of preceding <code>colou?r</code> \"color\", \"colour\" <code>\\d</code> Any digit <code>\\d{3}</code> \"123\", \"456\" <code>\\w</code> Any word character (letter, digit, underscore) <code>\\w+</code> \"hello\", \"test_123\" <code>\\s</code> Any whitespace <code>hello\\s+world</code> \"hello world\", \"hello  world\" <code>[abc]</code> Any character in set <code>[Pp]ython</code> \"Python\", \"python\" <code>[a-z]</code> Any character in range <code>[0-9]{2}</code> \"42\", \"99\" <code>^</code> Start of string <code>^Hello</code> \"Hello world\" (not \"Say Hello\") <code>$</code> End of string <code>world$</code> \"Hello world\" (not \"world peace\") <p>Regular expressions excel at tasks like:</p> <ul> <li>Email validation: Ensuring user input matches email format patterns</li> <li>Phone number extraction: Finding phone numbers regardless of formatting (123-456-7890, (123) 456-7890, etc.)</li> <li>URL parsing: Extracting domain names, paths, or parameters from web addresses</li> <li>Date formatting: Recognizing various date representations (2024-01-15, 01/15/2024, January 15, 2024)</li> <li>Log file analysis: Extracting timestamps, error codes, or user IDs from structured logs</li> </ul>"},{"location":"chapters/01-foundations-ai-nlp/#python-regular-expression-examples","title":"Python Regular Expression Examples","text":"<p>Python's <code>re</code> module provides regular expression functionality:</p> <pre><code>import re\n\n# Example 1: Email validation\nemail_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\nemails = [\"user@example.com\", \"invalid.email\", \"test.user+filter@domain.co.uk\"]\n\nfor email in emails:\n    if re.match(email_pattern, email):\n        print(f\"Valid: {email}\")\n    else:\n        print(f\"Invalid: {email}\")\n\n# Example 2: Extract all numbers from text\ntext = \"The model achieved 94.7% accuracy on 1,250 test samples.\"\nnumbers = re.findall(r'\\d+\\.?\\d*', text)\nprint(f\"Numbers found: {numbers}\")  # ['94.7', '1', '250']\n\n# Example 3: Find hashtags in social media text\ntweet = \"Excited about #AI and #MachineLearning! #NLP is fascinating.\"\nhashtags = re.findall(r'#\\w+', tweet)\nprint(f\"Hashtags: {hashtags}\")  # ['#AI', '#MachineLearning', '#NLP']\n\n# Example 4: Replace multiple spaces with single space\nmessy_text = \"Too    many     spaces    here\"\ncleaned = re.sub(r'\\s+', ' ', messy_text)\nprint(f\"Cleaned: {cleaned}\")  # \"Too many spaces here\"\n</code></pre> Interactive Regular Expression Pattern Matcher MicroSim     Type: microsim      Learning objective: Allow students to experiment with regular expression patterns and immediately see what text they match, building intuition for regex syntax and capabilities      Canvas layout (900x700px):     - Top section (900x150): Input area     - Middle section (900x400): Main visualization area     - Right section (200x400): Control panel     - Bottom section (900x150): Results and explanation area      Visual elements:      Top section:     - Text area: \"Enter test text\" (600px wide)     - Text input: \"Enter regex pattern\" (600px wide)     - Example text: \"Contact us at support@example.com or call (555) 123-4567. Visit https://www.example.com for more info.\"      Middle visualization area:     - Display the test text with matches highlighted in yellow     - Show capture groups in different colors (green, blue, purple)     - Display line numbers if multiline text     - Highlight current match when hovering      Right control panel:     - Dropdown: \"Example patterns\" with options:       - Email addresses       - Phone numbers       - URLs       - Dates       - Numbers       - Hashtags       - Custom     - Checkboxes for regex flags:       - Case insensitive (i)       - Multiline (m)       - Global (g)       - Dot matches all (s)     - Button: \"Test Pattern\"     - Button: \"Clear\"     - Display: Match count      Bottom results area:     - List of all matches found     - For each match: show the matched text, position (start-end), and any capture groups     - Explanation panel: dynamically explain what each part of the regex pattern means      Default parameters:     - Pattern: `\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b`     - Test text: \"Contact us at support@example.com or sales@company.org\"     - Flags: Global enabled      Example patterns (selectable from dropdown):     1. Email: `\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b`     2. Phone (US): `\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}`     3. URL: `https?://[^\\s]+`     4. Date (YYYY-MM-DD): `\\d{4}-\\d{2}-\\d{2}`     5. Hashtag: `#\\w+`     6. Numbers: `\\d+\\.?\\d*`      Behavior:     - When user types or selects a pattern, automatically test against text     - Highlight all matches in the visualization area     - Update match count and results list in real-time     - When hovering over a match in the visualization, highlight the corresponding entry in results list     - When selecting an example pattern, load both the pattern and appropriate test text     - Display error message if regex pattern is invalid      Educational features:     - Pattern explanation panel that breaks down the regex:       - `\\b` = word boundary       - `[A-Za-z0-9._%+-]+` = one or more email-valid characters       - `@` = literal @ symbol       - etc.     - Show capture groups with labels if pattern includes groups     - Provide hints for common regex mistakes      Implementation notes:     - Use p5.js for rendering and interaction     - Use JavaScript RegExp for pattern matching     - Store example patterns as array of objects with {name, pattern, testText, explanation}     - Update visualization on each text or pattern change (debounce input for performance)     - Use different highlight colors for different capture groups     - Canvas size: 900x700px      Accessibility:     - Provide text description of matches for screen readers     - Keyboard shortcuts: Ctrl+Enter to test pattern, Esc to clear  <p>The interactive MicroSim above allows experimentation with regex patterns, building intuition for this powerful text processing tool. Regular expressions become particularly important when building conversational AI systems that need to extract structured information from user queries\u2014for instance, parsing dates from \"What's the weather next Friday?\" or extracting product codes from \"Show me details for item SKU-12345.\"</p>"},{"location":"chapters/01-foundations-ai-nlp/#the-grep-command-pattern-search-in-files","title":"The Grep Command: Pattern Search in Files","text":"<p>The <code>grep</code> command (Global Regular Expression Print) represents one of the most essential text processing utilities in Unix/Linux environments. Originally developed in the 1970s, grep searches files or streams for lines matching a pattern and prints those lines to standard output. While seemingly simple, grep's power and flexibility have made it indispensable for developers, system administrators, and data analysts.</p>"},{"location":"chapters/01-foundations-ai-nlp/#basic-grep-usage","title":"Basic Grep Usage","text":"<p>At its core, grep takes a pattern and one or more files, printing lines that match:</p> <pre><code># Search for the word \"error\" in a log file\ngrep \"error\" application.log\n\n# Search case-insensitively\ngrep -i \"error\" application.log  # matches \"Error\", \"ERROR\", \"error\"\n\n# Search recursively in all files within a directory\ngrep -r \"TODO\" ./src/\n\n# Count matching lines instead of displaying them\ngrep -c \"warning\" system.log\n\n# Show line numbers with matches\ngrep -n \"exception\" debug.log\n</code></pre>"},{"location":"chapters/01-foundations-ai-nlp/#grep-with-regular-expressions","title":"Grep with Regular Expressions","text":"<p>Grep supports regular expressions, enabling sophisticated pattern searches:</p> <pre><code># Find lines containing email addresses\ngrep -E '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b' contacts.txt\n\n# Find lines starting with \"Error:\" followed by a number\ngrep '^Error: [0-9]' logs/*.log\n\n# Find Python function definitions (lines starting with \"def \")\ngrep '^\\s*def\\s' *.py\n\n# Find lines with 3-digit numbers\ngrep '\\b[0-9]{3}\\b' data.txt\n</code></pre>"},{"location":"chapters/01-foundations-ai-nlp/#practical-grep-applications-in-nlp-and-ai-development","title":"Practical Grep Applications in NLP and AI Development","text":"<p>Grep proves invaluable when working with conversational AI systems:</p> <ol> <li>Log analysis: Finding errors, specific user queries, or response patterns in chatbot interaction logs</li> <li>Code search: Locating function definitions, API calls, or configuration parameters across codebases</li> <li>Data exploration: Quickly sampling records from large text datasets before loading into Python</li> <li>Debugging: Finding where specific variables or functions are used during troubleshooting</li> <li>Data validation: Checking if expected patterns appear in output files</li> </ol> <p>Example workflow for analyzing chatbot logs:</p> <pre><code># Find all queries about pricing\ngrep -i \"price\\|cost\\|pricing\" chatbot_logs.txt &gt; pricing_queries.txt\n\n# Count how many times users encountered errors\ngrep -c \"ERROR\" chatbot_logs.txt\n\n# Extract timestamp and error message for all failures\ngrep \"ERROR\" chatbot_logs.txt | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}.*'\n\n# Find queries that mentioned specific products\ngrep -E \"(product|item).*[A-Z]{2,4}-[0-9]{4,6}\" chatbot_logs.txt\n</code></pre> <p>Common grep options:</p> Option Purpose Example Usage <code>-i</code> Case-insensitive search <code>grep -i \"python\" file.txt</code> <code>-v</code> Invert match (show non-matching lines) <code>grep -v \"test\" data.txt</code> <code>-r</code> or <code>-R</code> Recursive directory search <code>grep -r \"function\" ./src/</code> <code>-n</code> Show line numbers <code>grep -n \"error\" log.txt</code> <code>-c</code> Count matching lines <code>grep -c \"warning\" log.txt</code> <code>-l</code> Show only filenames with matches <code>grep -l \"TODO\" *.py</code> <code>-A 3</code> Show 3 lines after match <code>grep -A 3 \"exception\" log.txt</code> <code>-B 3</code> Show 3 lines before match <code>grep -B 3 \"error\" log.txt</code> <code>-C 3</code> Show 3 lines of context (before and after) <code>grep -C 3 \"critical\" log.txt</code> <code>-E</code> Extended regex (supports +, ?, |, etc.) <code>grep -E \"error\\|warning\" log.txt</code> <code>-w</code> Match whole words only <code>grep -w \"is\" text.txt</code> <p>While modern conversational AI relies primarily on semantic search using embeddings and vector databases (topics we'll cover in later chapters), grep and pattern matching remain essential for data preprocessing, log analysis, and debugging. Understanding these foundational text processing techniques provides context for appreciating why semantic search represents such a significant advancement.</p>"},{"location":"chapters/01-foundations-ai-nlp/#connecting-foundations-to-conversational-ai","title":"Connecting Foundations to Conversational AI","text":"<p>The concepts introduced in this chapter form the bedrock for understanding modern conversational AI systems. The exponential growth in AI capabilities, driven by both Moore's Law and algorithmic innovations, explains how today's language models achieve performance that would have seemed impossible even a decade ago. The progression from rule-based chatbots like ELIZA (which relied solely on pattern matching) to modern transformer-based systems demonstrates this evolution clearly.</p> <p>Text processing fundamentals\u2014string matching, regular expressions, and pattern search\u2014remain relevant even in the era of large language models:</p> <ul> <li>Preprocessing: Before text enters embedding models or LLMs, it undergoes cleaning and normalization using techniques discussed in this chapter</li> <li>Hybrid systems: Production chatbots often combine semantic search for understanding with regex-based extraction for structured data (dates, product codes, tracking numbers)</li> <li>Debugging and analysis: Developers use grep and pattern matching to analyze chatbot conversation logs, identify problematic queries, and measure system performance</li> <li>Fallback mechanisms: When semantic understanding fails, rule-based pattern matching can provide fallback responses</li> </ul> <p>As we progress through this course, we'll build increasingly sophisticated conversational AI systems. Chapter 2 introduces keyword search and its limitations, motivating the need for semantic understanding. Later chapters explore embeddings, vector stores, the RAG (Retrieval Augmented Generation) pattern, and GraphRAG implementations. Throughout this progression, the foundational concepts from this chapter\u2014understanding AI's exponential growth, recognizing text processing requirements, and applying pattern matching techniques\u2014will prove essential for both conceptual understanding and practical implementation.</p>"},{"location":"chapters/01-foundations-ai-nlp/#key-takeaways","title":"Key Takeaways","text":"<p>Before moving to the next chapter, ensure you understand these core concepts:</p> <ul> <li>Artificial Intelligence encompasses computational systems performing tasks requiring human-like intelligence, with current conversational AI systems using narrow AI techniques focused on language understanding and generation</li> <li>AI development has progressed non-linearly through multiple boom-and-bust cycles, with the modern deep learning era beginning around 2012 and transformer-based language models emerging in 2017</li> <li>Moore's Law describes the doubling of transistor density every two years, providing the computational foundation for modern AI, while the AI doubling rate shows capability improvements occurring even faster (every 3-4 months)</li> <li>Natural Language Processing enables computers to understand and generate human language through preprocessing, tokenization, linguistic analysis, semantic understanding, and generation</li> <li>Text processing fundamentals include case normalization, whitespace handling, punctuation processing, and tokenization as essential preprocessing steps</li> <li>String matching provides exact or case-insensitive literal text search, useful for specific term identification but limited by its inability to handle variations</li> <li>Regular expressions offer a powerful pattern language enabling flexible matching of character classes, quantities, and positions, essential for extracting structured data from text</li> <li>Grep serves as a command-line tool for pattern searching across files, invaluable for log analysis, code search, and data exploration in AI development workflows</li> </ul> <p>These foundations prepare you for exploring keyword search, semantic search, and the conversational AI architectures that build upon these basic text processing capabilities.</p>"},{"location":"chapters/02-search-technologies-indexing/","title":"Search Technologies and Indexing Techniques","text":""},{"location":"chapters/02-search-technologies-indexing/#summary","title":"Summary","text":"<p>This chapter explores fundamental search technologies and indexing techniques that form the backbone of information retrieval systems. You will learn about different types of search approaches, how search indexes are constructed and used, and techniques for expanding search capabilities beyond simple keyword matching. Understanding these concepts is essential for building effective chatbots that can retrieve relevant information from knowledge bases.</p>"},{"location":"chapters/02-search-technologies-indexing/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 14 concepts from the learning graph:</p> <ol> <li>Keyword Search</li> <li>Search Index</li> <li>Inverted Index</li> <li>Reverse Index</li> <li>Full-Text Search</li> <li>Boolean Search</li> <li>Search Query</li> <li>Query Parser</li> <li>Synonym Expansion</li> <li>Thesaurus</li> <li>Ontology</li> <li>Taxonomy</li> <li>Controlled Vocabulary</li> <li>Metadata</li> </ol>"},{"location":"chapters/02-search-technologies-indexing/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> </ul>"},{"location":"chapters/02-search-technologies-indexing/#introduction-why-search-matters-for-conversational-ai","title":"Introduction: Why Search Matters for Conversational AI","text":"<p>Before a chatbot can answer questions intelligently, it must first locate relevant information within potentially massive knowledge bases containing thousands or millions of documents. The difference between a chatbot that responds in milliseconds versus one that makes users wait seconds (or worse, times out) often comes down to search technology. Understanding how search systems index, query, and retrieve information is fundamental to building conversational agents that feel responsive and helpful rather than frustratingly slow.</p> <p>In this chapter, you'll explore the core technologies that power information retrieval systems, from simple keyword matching to sophisticated query expansion techniques. These concepts form the foundation upon which modern chatbots are built, enabling them to quickly find the right information to answer user questions. While you may never implement a search index from scratch in production (existing libraries handle this efficiently), understanding how they work will help you make informed architectural decisions and debug performance issues when building conversational AI systems.</p>"},{"location":"chapters/02-search-technologies-indexing/#the-fundamentals-of-keyword-search","title":"The Fundamentals of Keyword Search","text":"<p>Keyword search represents the most intuitive approach to finding information: match the exact words a user types against words appearing in documents. When you search for \"database backup procedure\" using keyword search, the system looks for documents containing those exact terms. This approach mirrors how you might search for a specific phrase in a book by scanning pages for matching words.</p> <p>While conceptually straightforward, keyword search suffers from several limitations that become apparent in conversational AI contexts. First, it's brittle\u2014users must guess the exact terminology used in source documents. If documentation uses \"RDBMS\" but users search for \"relational database,\" keyword search finds nothing despite these terms being synonymous. Second, keyword search lacks understanding of context or intent; searching for \"Apple\" returns documents about both fruit and technology companies with equal enthusiasm, regardless of which the user actually wants.</p> <p>Despite these limitations, keyword search remains valuable as a foundation for understanding more sophisticated approaches. Many production search systems still use keyword matching as a first-pass filter before applying more computationally expensive semantic techniques. Additionally, for highly technical domains with controlled vocabularies where users and documents employ consistent terminology, keyword search can deliver excellent precision with minimal computational overhead.</p>"},{"location":"chapters/02-search-technologies-indexing/#when-users-actually-type-search-queries","title":"When Users Actually Type Search Queries","text":"<p>A search query represents the formal expression of a user's information need\u2014the actual text string submitted to a search system. In conversational AI applications, queries might arrive as natural language questions (\"How do I restore a database backup?\"), as keywords (\"database restore\"), or as commands (\"show restore procedure\"). Understanding query structure and intent forms a critical skill for chatbot developers because users rarely formulate perfect queries on their first attempt.</p> <p>Search queries typically fall into several categories that reveal user intent:</p> <ul> <li>Navigational queries: User seeks a specific known document (\"employee handbook\")</li> <li>Informational queries: User wants to learn something (\"what is a reverse index\")</li> <li>Transactional queries: User wants to perform an action (\"reset my password\")</li> <li>Comparison queries: User evaluates options (\"RDBMS versus graph database\")</li> </ul> Query Types and Chatbot Response Strategies     Type: markdown-table  Purpose: Show how different query types should be handled differently by chatbot systems  | Query Type | Example | Best Response Strategy | Why This Approach Works | |------------|---------|------------------------|-------------------------| | Navigational | \"employee handbook\" | Direct link to document | User knows what they want, minimize friction | | Informational | \"what is a reverse index\" | Concise explanation with option to dive deeper | User wants understanding, not overwhelm | | Transactional | \"reset my password\" | Step-by-step procedure or execute action | User has immediate task, needs actionable steps | | Comparison | \"RDBMS vs graph database\" | Side-by-side feature table | User making decision, needs structured comparison | | Exploratory | \"tell me about search\" | Multiple related topics with navigation | User not sure what they need, offer guided exploration |   <p>The challenge for conversational AI systems lies in correctly classifying query type and intent, then routing to appropriate handlers. A navigational query answered with a lengthy explanation frustrates users who wanted a quick link, while an informational query answered with just a URL leaves users feeling the chatbot didn't actually help.</p>"},{"location":"chapters/02-search-technologies-indexing/#building-the-foundation-search-indexes","title":"Building the Foundation: Search Indexes","text":"<p>Imagine trying to answer \"Which documents mention PostgreSQL?\" by opening every file in a 10,000-document knowledge base and scanning each one sequentially. Even on modern hardware, this naive approach would take seconds or minutes\u2014unacceptable latency for chatbot interactions. Search indexes solve this performance problem by preprocessing documents to enable near-instantaneous lookups.</p> <p>A search index functions as a specialized data structure\u2014essentially a lookup table mapping terms to the documents containing them. When you index a document collection, the system extracts important terms from each document and records \"document D contains terms T1, T2, T3, ...\" in the index. Subsequently, when users query for term T1, the system simply looks up T1 in the index and instantly retrieves the list of documents containing it, without re-scanning any actual document content.</p> <p>The performance difference is dramatic: sequential scanning scales O(n) with document count (doubling your knowledge base doubles search time), while indexed lookups typically operate in O(log n) or even O(1) time depending on index structure. This architectural choice\u2014paying upfront indexing costs to enable fast queries\u2014represents a fundamental tradeoff in information retrieval systems.</p>"},{"location":"chapters/02-search-technologies-indexing/#the-inverted-index-the-core-data-structure","title":"The Inverted Index: The Core Data Structure","text":"<p>An inverted index (also called a reverse index\u2014the terms are synonymous) represents the most common search index implementation, so named because it inverts the natural document-to-terms relationship into a terms-to-documents mapping. Rather than storing \"Document 1 contains: database, backup, restore,\" an inverted index stores \"database \u2192 Documents 1, 5, 7, 23\" and \"backup \u2192 Documents 1, 15, 22\" and \"restore \u2192 Documents 1, 8, 15.\"</p> <p>The structure typically consists of two components: a dictionary (vocabulary) containing all unique terms encountered during indexing, and a postings list for each term listing all documents containing that term. Modern implementations enhance postings lists with additional metadata such as term frequency (how many times the term appears in each document) and term positions (where in the document the term appears), enabling more sophisticated ranking and phrase matching.</p> Inverted Index Structure Visualization     Type: diagram  Purpose: Illustrate the structure of an inverted index showing how terms map to documents with metadata  Components: 1. Source Documents (left side):    - Doc 1: \"Database backup procedures are critical\"    - Doc 2: \"Backup your database regularly\"    - Doc 3: \"Critical system database maintenance\"  2. Indexing Process (middle, with arrow pointing right):    - Tokenization step    - Normalization step (lowercase, stemming)    - Index building step  3. Inverted Index Structure (right side):    - Dictionary/Vocabulary section (sorted terms):      * \"backup\" \u2192 Postings list      * \"critical\" \u2192 Postings list      * \"database\" \u2192 Postings list      * \"maintenance\" \u2192 Postings list      * \"procedure\" \u2192 Postings list      * \"regularly\" \u2192 Postings list      * \"system\" \u2192 Postings list  4. Detailed Postings List for \"database\" (expanded):    - Doc 1: frequency=1, positions=[0]    - Doc 2: frequency=1, positions=[2]    - Doc 3: frequency=1, positions=[3]  Layout: Left-to-right flow diagram showing transformation from documents to index  Visual style: Block diagram with clear arrows showing data flow  Color scheme: - Documents: Light blue boxes - Processing steps: Orange arrows with labels - Dictionary: Green box with sorted list - Postings lists: Yellow boxes with document IDs  Labels: - \"Source Documents\" (left) - \"Indexing Pipeline\" (middle arrows) - \"Inverted Index\" (right) - \"Dictionary (Vocabulary)\" on term list - \"Postings List (Document IDs + Metadata)\" on document lists  Implementation: Can be created as an SVG diagram or using diagram generation tools  <p>Building an inverted index involves several preprocessing steps that significantly impact search quality. Tokenization splits text into terms (deciding whether \"database-backup\" becomes one term or two). Normalization converts terms to canonical forms (lowercase \"Database\" to \"database,\" stem \"running\" to \"run\"). Stop word removal optionally discards extremely common terms like \"the\" and \"is\" that provide little discriminative value. Each decision in this pipeline affects both index size and retrieval effectiveness.</p>"},{"location":"chapters/02-search-technologies-indexing/#full-text-search-capabilities","title":"Full-Text Search Capabilities","text":"<p>Full-text search extends basic keyword matching by indexing every significant word in every document, not just titles or metadata fields. This comprehensive indexing approach enables users to find documents based on any content they contain, not just carefully curated tags or summaries. For conversational AI applications dealing with extensive documentation, full-text search is essentially mandatory\u2014users ask about obscure details buried in paragraph text, not just high-level topics.</p> <p>Full-text search systems typically implement additional capabilities beyond simple term lookup:</p> <ul> <li>Phrase matching: Finding \"database backup\" as an exact sequence, not just documents containing both words separately</li> <li>Proximity search: Locating documents where \"database\" and \"backup\" appear within N words of each other</li> <li>Stemming: Matching \"backing\" and \"backup\" and \"backed\" to the same root term</li> <li>Case-insensitive matching: Treating \"PostgreSQL\" and \"postgresql\" as equivalent</li> <li>Wildcard support: Searching for \"datab*\" to match \"database,\" \"databases,\" \"databank\"</li> </ul> Full-Text Search Capabilities Interactive Demo     Type: microsim  Learning objective: Demonstrate how different full-text search features find matches in a document corpus and understand trade-offs between precision and recall  Canvas layout (900x700px): - Top section (900x150): Document corpus display showing 5 sample documents - Middle section (900x400): Main visualization area showing matching results - Bottom section (900x150): Control panel  Visual elements: - 5 document cards across the top, each showing title and first 100 characters - Search results area showing matched documents with highlighting - Match type indicators (exact, stemmed, proximity, wildcard) - Result count and match quality score  Sample documents: 1. \"Database Backup Procedures: Regular database backups are critical...\" 2. \"Backing Up Your Data: Learn how to back up databases effectively...\" 3. \"Critical System Maintenance: Database systems require regular backing procedures...\" 4. \"PostgreSQL Administration Guide: postgresql databases need backup...\" 5. \"Data Recovery Methods: Restoring backed-up database content...\"  Interactive controls: - Text input: Search query (default: \"database backup\") - Checkboxes: Enable features   * Case-insensitive (default: ON)   * Stemming (default: OFF)   * Phrase matching (default: OFF)   * Proximity search (default: OFF, with slider for distance: 1-10 words)   * Wildcard support (default: OFF) - Display area: Shows which documents matched and why - Metrics display: Precision, Recall, F1 score based on predefined \"relevant\" set  Default parameters: - Query: \"database backup\" - All features: OFF initially (to show basic matching) - Case-insensitive: ON  Behavior: - As user types query, results update in real-time - When features are toggled, highlighting changes to show what matched - Different colored highlights for different match types:   * Blue: Exact match   * Green: Stemmed match   * Yellow: Proximity match   * Orange: Wildcard match - Display shows reason for each match (\"Matched: exact 'database', exact 'backup'\") - Metrics update to show how feature choices affect retrieval effectiveness  Educational notes panel: - Shows trade-offs: \"Stemming increased recall from 2 to 4 docs but decreased precision\" - Highlights when features conflict or complement each other  Implementation notes: - Use p5.js for rendering and interaction - Implement simple stemming algorithm (Porter stemmer or similar) - Pre-define \"relevant\" document set for metric calculation - Use regex for wildcard matching - Store document text in arrays for highlighting  <p>The computational cost of full-text search varies significantly based on implementation. Simple boolean matching (document contains term or doesn't) is inexpensive, while ranked retrieval (sorting results by relevance) requires calculating scores for every matching document. Production systems employ various optimizations\u2014caching frequent queries, using approximate top-k algorithms, pre-computing document statistics\u2014to keep search latency under 100 milliseconds even for large corpora.</p>"},{"location":"chapters/02-search-technologies-indexing/#boolean-search-combining-query-terms","title":"Boolean Search: Combining Query Terms","text":"<p>Boolean search allows users to construct complex queries by combining terms with logical operators AND, OR, and NOT. Rather than retrieving documents containing any query term (implicit OR) or all query terms (implicit AND), users explicitly specify the desired logic: \"database AND backup,\" \"PostgreSQL OR MySQL,\" \"security NOT password.\" This capability provides precision for users who know exactly what they want, though it requires understanding Boolean logic that many casual users lack.</p> <p>The implementation of Boolean search atop an inverted index is remarkably elegant. For \"database AND backup,\" the system retrieves the postings list for \"database\" and the postings list for \"backup,\" then computes their intersection (document IDs appearing in both lists). For OR operations, compute the union of postings lists. For NOT operations, compute the set difference. These set operations execute efficiently when postings lists are sorted, which most indexes maintain.</p> <p>Boolean search becomes particularly powerful when combined with parentheses for grouping: \"(PostgreSQL OR MySQL) AND (backup OR restore) NOT disaster\" precisely specifies a complex information need that would be difficult to express in natural language. However, this power comes at a cost\u2014most users find Boolean syntax confusing and make errors. Modern search interfaces often hide Boolean operators behind friendlier UI elements (checkboxes for facets, sliders for numeric ranges) while translating to Boolean queries internally.</p>"},{"location":"chapters/02-search-technologies-indexing/#understanding-query-processing-the-query-parser","title":"Understanding Query Processing: The Query Parser","text":"<p>Before a search system can execute a query, it must interpret what the user typed\u2014a task performed by the query parser. This component transforms the raw query string into a structured internal representation that the search engine can process. For simple queries like \"database backup,\" parsing is straightforward: split into terms, perhaps apply stemming, look up each term. For complex queries with operators, phrases, wildcards, and field restrictions, parsing becomes significantly more sophisticated.</p> <p>A typical query parser handles multiple responsibilities:</p> <ul> <li>Tokenization: Splitting the query string into individual terms and operators</li> <li>Operator recognition: Identifying AND, OR, NOT, parentheses, quotes for phrases</li> <li>Field qualification: Parsing queries like \"title:database author:Smith\"</li> <li>Syntax validation: Detecting malformed queries like \"database AND\" or unmatched quotes</li> <li>Query expansion: Potentially adding synonyms or related terms (covered in the next section)</li> <li>Query transformation: Rewriting queries for efficiency or to apply search policies</li> </ul> Query Parser Processing Pipeline     Type: workflow  Purpose: Show the step-by-step process a query parser follows to transform user input into an executable search query  Visual style: Flowchart with process rectangles, decision diamonds, and parallel processing paths  Steps:  1. Start: \"User Query Input\"    Hover text: \"Raw query string exactly as user typed it: \\\"(database OR PostgreSQL) AND backup title:procedures\\\"\"  2. Process: \"Lexical Analysis (Tokenization)\"    Hover text: \"Split query into tokens: ['(', 'database', 'OR', 'PostgreSQL', ')', 'AND', 'backup', 'title', ':', 'procedures']\"  3. Process: \"Syntax Analysis (Parsing)\"    Hover text: \"Build abstract syntax tree recognizing operators, field qualifiers, and grouping\"  4. Decision: \"Syntax Valid?\"    Hover text: \"Check for balanced parentheses, valid operator placement, complete field qualifiers\"  5a. Process: \"Return Syntax Error\" (if invalid)     Hover text: \"Provide helpful error message: 'Unmatched parenthesis at position 15'\"     \u2192 End: \"Error Returned to User\"  5b. Process: \"Normalize Terms\" (if valid)     Hover text: \"Apply lowercase, stemming: 'database'\u2192'databas', 'procedures'\u2192'procedur'\"  6. Process: \"Apply Query Expansion (Optional)\"    Hover text: \"Add synonyms if enabled: 'database' \u2192 ['database', 'RDBMS', 'datastore']\"  7. Process: \"Optimize Query Structure\"    Hover text: \"Reorder terms for efficiency, push NOT operations down, eliminate redundancy\"  8. Process: \"Field Mapping\"    Hover text: \"Map field names to internal index field names: 'title' \u2192 'document.title.analyzed'\"  9. Process: \"Generate Execution Plan\"    Hover text: \"Determine optimal order to retrieve and combine postings lists\"  10. End: \"Executable Query Object\"     Hover text: \"Structured query ready for search engine execution with all terms, operators, and fields resolved\"  Color coding: - Light blue: Input/Output stages - Green: Text processing stages - Orange: Validation and decision points - Purple: Optimization stages - Gold: Final execution preparation  Parallel paths: - After normalization, some parsers run spell-checking in parallel - Query expansion may happen concurrently with optimization  Error handling path clearly marked in red from decision diamond  Implementation: Mermaid.js or similar flowchart tool with interactive hover states  <p>Advanced query parsers implement features like spell correction (\"databse\" \u2192 \"database\"), query suggestion (\"did you mean: database backup?\"), and query classification (identifying whether the query is navigational, informational, or transactional to route to specialized handlers). For conversational AI applications, the query parser often integrates with natural language processing pipelines to extract intent and entities from conversational input that may not follow traditional search syntax.</p>"},{"location":"chapters/02-search-technologies-indexing/#expanding-search-with-synonyms-and-vocabularies","title":"Expanding Search with Synonyms and Vocabularies","text":"<p>One of the fundamental challenges in keyword-based search is the vocabulary mismatch problem: users and document authors often use different words for the same concept. A user searching for \"car\" won't find documents about \"automobiles\" unless the system understands these terms are related. Synonym expansion addresses this issue by automatically adding related terms to queries, transforming \"car\" into \"car OR automobile OR vehicle\" behind the scenes.</p> <p>Synonym expansion can be applied at two different stages\u2014query time or indexing time\u2014each with distinct tradeoffs. Query-time expansion modifies the user's query before execution, keeping indexes compact but requiring expansion for every query. Index-time expansion adds synonyms to documents during indexing, creating larger indexes but enabling faster query execution. Production systems often employ hybrid approaches, expanding some terms at query time and others at index time based on frequency and importance.</p> <p>The source of synonyms significantly impacts expansion quality. Manual synonym lists curated by domain experts provide high precision but require ongoing maintenance. Automated approaches using statistical methods (terms that co-occur frequently are likely related) or word embeddings (terms with similar vector representations in embedding space) scale better but introduce more errors. For specialized domains like medicine or law, controlled vocabularies and thesauri developed by professional organizations offer superior synonym coverage compared to generic approaches.</p>"},{"location":"chapters/02-search-technologies-indexing/#thesauri-and-controlled-vocabularies","title":"Thesauri and Controlled Vocabularies","text":"<p>A thesaurus in information retrieval contexts represents a structured vocabulary defining relationships between terms, including synonyms (equivalent terms), broader terms (hypernyms), narrower terms (hyponyms), and related terms. Unlike casual thesauri in word processors that suggest stylistic alternatives, search thesauri formalize domain knowledge to improve retrieval effectiveness. The Medical Subject Headings (MeSH) thesaurus, for instance, defines relationships among 30,000+ biomedical terms, enabling medical literature searches to automatically expand \"heart attack\" to include \"myocardial infarction,\" \"cardiac arrest,\" and related concepts.</p> <p>Controlled vocabularies take this concept further by restricting document indexing and query formulation to an approved term list. Library cataloging systems exemplify this approach: librarians tag books with terms from standardized vocabularies like the Library of Congress Subject Headings rather than inventing arbitrary tags. This discipline eliminates vocabulary mismatch\u2014if documents and queries both use controlled terms, matching becomes deterministic.</p> <p>The benefits of controlled vocabularies include:</p> <ul> <li>Consistency: Different people assign the same concepts the same tags</li> <li>Precision: Controlled terms have specific, well-defined meanings</li> <li>Comprehensive retrieval: Synonym relationships are explicitly encoded</li> <li>Faceted navigation: Hierarchical vocabularies enable browsing by category</li> </ul> <p>However, controlled vocabularies impose significant costs. Creating and maintaining them requires expert effort. Users must learn the approved vocabulary or rely on mapping systems that translate natural language to controlled terms. In fast-moving domains where new concepts emerge frequently (like technology), controlled vocabularies struggle to keep pace. For these reasons, many modern systems employ hybrid approaches\u2014using controlled vocabularies for high-value domains while accepting free-text in others.</p>"},{"location":"chapters/02-search-technologies-indexing/#taxonomies-hierarchical-organization","title":"Taxonomies: Hierarchical Organization","text":"<p>A taxonomy organizes concepts into hierarchical relationships, typically using \"is-a\" or \"type-of\" relationships to create tree structures. In search contexts, taxonomies enable query expansion along hierarchical dimensions. A query for \"database\" might automatically expand to include narrower terms like \"relational database,\" \"NoSQL database,\" \"graph database,\" and \"document database.\" Conversely, a query for the specific term \"PostgreSQL\" might expand upward to the broader term \"relational database\" if initial results are sparse.</p> <p>Taxonomies prove particularly valuable for faceted navigation in search interfaces. Users start with a broad category like \"computer systems,\" then progressively narrow by selecting subcategories: \"storage systems\" \u2192 \"databases\" \u2192 \"relational databases\" \u2192 \"PostgreSQL.\" Each selection refines the result set while maintaining context about the broader category hierarchy. This exploratory search pattern suits scenarios where users don't know precise terminology but can recognize relevant categories when presented.</p> IT Knowledge Taxonomy Example     Type: graph-model  Purpose: Illustrate a sample IT knowledge taxonomy showing hierarchical relationships used for query expansion and faceted navigation  Node types: 1. Domain (pink circles, largest size)    - Properties: name, description    - Example: \"Information Technology\"  2. Category (light blue circles, large size)    - Properties: name, description, level    - Examples: \"Storage Systems\", \"Network Infrastructure\"  3. Subcategory (green circles, medium size)    - Properties: name, description, level    - Examples: \"Databases\", \"Routers\", \"Switches\"  4. Technology (orange squares, small size)    - Properties: name, vendor, type    - Examples: \"PostgreSQL\", \"MySQL\", \"Neo4j\"  5. Concept (purple diamonds, small size)    - Properties: name, definition    - Examples: \"Transactions\", \"ACID\", \"Sharding\"  Edge types: 1. HAS_CATEGORY (solid blue arrows)    - Properties: order (for sorting)    - Example: Domain \u2192 Category  2. HAS_SUBCATEGORY (solid green arrows)    - Properties: order    - Example: Category \u2192 Subcategory  3. IS_A (solid orange arrows)    - Properties: none    - Example: PostgreSQL IS_A Relational Database  4. RELATED_TO (dotted gray arrows, bidirectional)    - Properties: relationship_type    - Example: Backup RELATED_TO Recovery  Sample data structure: - Information Technology (Domain)   \u251c\u2500 Storage Systems (Category)   \u2502  \u251c\u2500 Databases (Subcategory)   \u2502  \u2502  \u251c\u2500 Relational Databases   \u2502  \u2502  \u2502  \u251c\u2500 PostgreSQL (Technology)   \u2502  \u2502  \u2502  \u251c\u2500 MySQL (Technology)   \u2502  \u2502  \u2502  \u2514\u2500 Oracle (Technology)   \u2502  \u2502  \u251c\u2500 NoSQL Databases   \u2502  \u2502  \u2502  \u251c\u2500 MongoDB (Technology)   \u2502  \u2502  \u2502  \u2514\u2500 Cassandra (Technology)   \u2502  \u2502  \u2514\u2500 Graph Databases   \u2502  \u2502     \u251c\u2500 Neo4j (Technology)   \u2502  \u2502     \u2514\u2500 JanusGraph (Technology)   \u2502  \u2514\u2500 File Systems (Subcategory)   \u2502     \u251c\u2500 NTFS (Technology)   \u2502     \u2514\u2500 ext4 (Technology)   \u2514\u2500 Networking (Category)      \u251c\u2500 Hardware (Subcategory)      \u2502  \u251c\u2500 Routers (Technology)      \u2502  \u2514\u2500 Switches (Technology)      \u2514\u2500 Protocols (Subcategory)         \u251c\u2500 TCP/IP (Technology)         \u2514\u2500 HTTP (Technology)  Concepts attached to technologies: - PostgreSQL \u2192 ACID (Concept) - PostgreSQL \u2192 Transactions (Concept) - Neo4j \u2192 Index-Free Adjacency (Concept) - MongoDB \u2192 Sharding (Concept)  Layout: Hierarchical tree layout with root at top, expanding downward  Interactive features: - Hover over node: Show full description and properties - Click node: Highlight all related nodes (children, parents, related concepts) - Double-click: Expand/collapse subtree - Right-click: Show \"Query Expansion Options\" (expand to children, expand to siblings, expand to related) - Zoom: Mouse wheel - Pan: Drag background - Search box: Type term to highlight and center on matching node  Visual styling: - Node size reflects hierarchy level (larger = higher level) - Node color coded by type (see above) - Edge thickness indicates strength of relationship - Highlight critical path from selected node to root in gold  Legend (top right): - Node shapes: Circle (categories), Square (technologies), Diamond (concepts) - Node colors and their meanings - Edge types (solid vs dotted, colors) - Interaction hints (hover, click, double-click)  Example search demonstration: - When user searches for \"PostgreSQL\" - Highlight PostgreSQL node - Show expansion path: PostgreSQL \u2192 Relational Databases \u2192 Databases \u2192 Storage Systems \u2192 IT - Display recommended query expansion terms in side panel:   * Narrower terms: ACID, Transactions (concepts)   * Peer terms: MySQL, Oracle (sibling technologies)   * Broader terms: Relational Databases, Databases  Canvas size: 1000x800px  Implementation: vis-network JavaScript library with hierarchical layout algorithm  <p>Building effective taxonomies requires balancing depth (how many levels) against breadth (how many categories at each level). Deep, narrow taxonomies force users to make many navigation decisions but provide precise categorization. Shallow, broad taxonomies simplify navigation but create overwhelming category lists. Enterprise taxonomy design often follows the \"3-clicks rule\"\u2014users should reach specific content within three navigation choices\u2014though this guideline sometimes conflicts with domain complexity.</p>"},{"location":"chapters/02-search-technologies-indexing/#ontologies-formal-knowledge-representation","title":"Ontologies: Formal Knowledge Representation","text":"<p>An ontology represents the most sophisticated form of structured vocabulary, defining not just hierarchical relationships but arbitrary relationships among concepts, along with rules and constraints governing those relationships. While taxonomies answer \"is-a\" questions (\"PostgreSQL is-a relational database\"), ontologies also encode \"part-of,\" \"causes,\" \"requires,\" \"conflicts-with,\" and domain-specific relationships. Ontologies formalize domain knowledge in machine-readable formats, enabling automated reasoning and inference.</p> <p>For search applications, ontologies enable query expansion based on arbitrary relationship types. A query about \"database backup\" might expand to include \"disaster recovery\" (a broader goal that backup supports), \"storage capacity\" (a requirement for backups), and \"backup software\" (a tool used in backup processes)\u2014relationships that taxonomies' hierarchical structure cannot capture. This semantic richness allows search systems to retrieve documents that don't mention query terms directly but discuss closely related concepts.</p> <p>The relationship between taxonomies and ontologies is one of subset: every taxonomy is an ontology (one that uses only hierarchical relationships), but many ontologies employ richer relationship types. In practice, the terminology is often used loosely\u2014what organizations call \"our company ontology\" may actually be a taxonomy if it lacks non-hierarchical relationships. True ontologies, represented in languages like OWL (Web Ontology Language), support logical reasoning: if \"backups require storage\" and \"storage requires disk space,\" the system can infer \"backups require disk space\" even if this relationship wasn't explicitly stated.</p> <p>The complexity and maintenance cost of ontologies significantly exceeds that of simpler controlled vocabularies. Building domain ontologies requires collaboration between domain experts (who understand the concepts) and knowledge engineers (who understand formal representation). For conversational AI applications, ontologies prove most valuable in specialized domains like healthcare, legal systems, and scientific research where the benefits of precise semantic modeling justify the investment.</p>"},{"location":"chapters/02-search-technologies-indexing/#the-role-of-metadata-in-search","title":"The Role of Metadata in Search","text":"<p>Metadata\u2014literally \"data about data\"\u2014provides structured information describing documents, enabling search capabilities beyond full-text matching. While full-text search finds documents based on their content, metadata search finds documents based on their attributes: author, creation date, document type, subject category, security classification, and so forth. For conversational AI systems, metadata enables queries like \"show me documents created by John Smith last month about database security\" that combine content and attribute filters.</p> <p>Metadata falls into several categories, each serving different search scenarios:</p> <ul> <li>Descriptive metadata: Title, author, abstract, subject tags describing what the document is about</li> <li>Structural metadata: Chapter divisions, section headings, citations describing how the document is organized</li> <li>Administrative metadata: Creation date, last modified date, version number, file format</li> <li>Preservation metadata: Checksum, storage location, access rights, retention period</li> <li>Technical metadata: Image resolution, video codec, audio sampling rate for media files</li> </ul> <p>Effective metadata design requires balancing completeness against maintenance burden. Rich metadata enables precise filtering and faceted search, but someone must assign that metadata to every document. Automated metadata extraction from document content (using NLP to identify author names, dates, topics) reduces manual effort but introduces errors. Many organizations employ hybrid approaches: mandatory core metadata fields assigned manually, plus optional extended metadata assigned automatically.</p> Metadata-Enhanced Search Architecture     Type: diagram  Purpose: Show how metadata and full-text search work together in a comprehensive search system architecture  Components to show:  1. Document Input Layer (left side):    - Document repository (file system or CMS)    - Incoming documents (various formats: PDF, DOCX, HTML)  2. Processing Pipeline (left to center):    - Content extraction (extracting text from formats)    - Metadata extraction (automated + manual)    - Text analysis (tokenization, stemming)  3. Storage Layer (center):    - Full-text index (inverted index structure)    - Metadata database (structured fields)    - Document store (original files)  4. Query Processing Layer (center to right):    - Query parser    - Query expansion engine    - Search coordinator (combines full-text + metadata searches)  5. Results Layer (right side):    - Ranking engine    - Results formatter    - User interface  Data flow arrows: - Documents flow from repository \u2192 processing pipeline \u2192 storage - User queries flow from UI \u2192 query processing \u2192 storage \u2192 ranking \u2192 UI - Bidirectional arrows between full-text index and metadata database (joined queries)  Key interactions to highlight: - \"Combined Query\" box showing how full-text search and metadata filters merge - \"Boost by metadata\" annotation showing metadata affecting relevance ranking - \"Faceted navigation\" annotation showing metadata enabling filter UI  Detailed callouts: 1. Metadata Database detail (expandable):    - Table showing sample fields: doc_id, title, author, date, category, security_level    - Indexes on key fields for fast filtering  2. Full-Text Index detail (expandable):    - Inverted index with term \u2192 document mappings    - Metadata enrichment: postings lists include metadata scores  3. Query Example (expandable):    - Input: \"database backup author:Smith date:2024-01\"    - Parsed to: full-text terms [database, backup] AND metadata filters [author=Smith, date range]    - Execution plan: Filter by metadata first (reduces search space), then full-text search  Style: Layered architecture diagram with horizontal flow from left (input) to right (output)  Color scheme: - Purple: Document/data storage components - Blue: Processing and transformation stages - Green: Query and search components - Orange: User-facing components - Gray arrows: Data flow  Labels: - Clear component names - Numbered data flow (1. Ingest, 2. Process, 3. Store, 4. Query, 5. Retrieve) - Annotations explaining key interactions  Implementation: SVG diagram or created with architecture diagramming tools  <p>For chatbot applications, metadata proves particularly valuable in three scenarios. First, security and access control: metadata specifying document security levels enables the chatbot to filter results based on the current user's permissions, ensuring sensitive information stays protected. Second, temporal filtering: when users ask \"what changed recently?\" metadata timestamps enable efficient date-range queries. Third, source provenance: metadata identifying document sources allows users to filter by trusted sources or gives the chatbot context for assessing answer reliability.</p>"},{"location":"chapters/02-search-technologies-indexing/#putting-it-all-together-search-system-architecture","title":"Putting It All Together: Search System Architecture","text":"<p>Modern search systems integrate all the concepts covered in this chapter into cohesive architectures that balance performance, relevance, and maintainability. Understanding how these pieces fit together helps you make informed decisions when building conversational AI applications that depend on effective information retrieval.</p> <p>A typical enterprise search architecture contains these key components working in concert:</p> <ol> <li>Ingestion pipeline: Discovers documents, extracts text and metadata, applies preprocessing</li> <li>Index management: Builds and maintains inverted indexes with appropriate field configurations</li> <li>Query processing: Parses queries, applies expansion rules, optimizes execution plans</li> <li>Retrieval engine: Executes queries against indexes, applies ranking algorithms</li> <li>Result presentation: Formats results with snippets, highlighting, and metadata</li> <li>Feedback loops: Captures user interactions to improve ranking and expansion over time</li> </ol> <p>The architectural choices made at each layer cascade through the system. Aggressive stemming in the ingestion pipeline affects how queries match documents. Synonym expansion rules in query processing determine recall/precision tradeoffs. Index structure decisions impact whether phrase searches execute efficiently or require expensive post-filtering. There is no universally optimal configuration\u2014effective search systems are tuned to their specific document corpus, query patterns, and user expectations.</p> <p>For conversational AI developers, understanding these search fundamentals enables you to:</p> <ul> <li>Choose appropriate search libraries and configure them effectively for your use case</li> <li>Debug why chatbot answers miss relevant documents or return too many irrelevant results</li> <li>Design document preprocessing pipelines that balance index size against search capabilities</li> <li>Implement query expansion strategies that improve recall without degrading precision</li> <li>Optimize search performance to meet conversational latency requirements (sub-second responses)</li> </ul> <p>The next chapter builds on this foundation by introducing semantic search approaches that go beyond keyword matching to understand meaning, context, and intent\u2014capabilities increasingly essential for modern conversational AI systems.</p>"},{"location":"chapters/02-search-technologies-indexing/#key-takeaways","title":"Key Takeaways","text":"<p>Search technologies form the foundation of information retrieval in conversational AI systems:</p> <ul> <li>Keyword search provides simple, fast matching but suffers from vocabulary mismatch and lack of context understanding</li> <li>Search indexes (particularly inverted indexes) enable near-instantaneous lookups by preprocessing documents into term-to-document mappings</li> <li>Full-text search indexes all document content, enabling comprehensive retrieval with features like phrase matching and stemming</li> <li>Boolean search allows precise query formulation through logical operators (AND, OR, NOT) but requires users to understand formal syntax</li> <li>Query parsers transform user input into executable search queries, handling tokenization, syntax validation, and optimization</li> <li>Synonym expansion addresses vocabulary mismatch by automatically adding related terms to queries or indexes</li> <li>Controlled vocabularies and thesauri formalize domain terminology and relationships, trading maintenance cost for improved consistency</li> <li>Taxonomies organize concepts hierarchically, enabling query expansion and faceted navigation</li> <li>Ontologies represent rich semantic relationships among concepts, supporting inference and advanced query expansion</li> <li>Metadata enables attribute-based searching and filtering, complementing content-based full-text search</li> </ul> <p>These techniques work together in production search systems to deliver fast, relevant results. Understanding their strengths, limitations, and tradeoffs empares you to build effective search capabilities into conversational AI applications, setting the stage for more sophisticated semantic search approaches covered in later chapters.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/","title":"Semantic Search and Quality Metrics","text":""},{"location":"chapters/03-semantic-search-quality-metrics/#summary","title":"Summary","text":"<p>This chapter advances your understanding of search by introducing semantic search techniques that go beyond simple keyword matching, along with methods for measuring search quality. You will learn about metadata tagging, vector-based similarity measures, ranking algorithms like Page Rank and TF-IDF, and critical evaluation metrics including precision, recall, and F-measures. These concepts enable you to build more intelligent search systems and objectively assess their performance.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 21 concepts from the learning graph:</p> <ol> <li>Metadata Tagging</li> <li>Dublin Core</li> <li>Semantic Search</li> <li>Vector Similarity</li> <li>Cosine Similarity</li> <li>Euclidean Distance</li> <li>Search Ranking</li> <li>Page Rank Algorithm</li> <li>TF-IDF</li> <li>Term Frequency</li> <li>Document Frequency</li> <li>Search Performance</li> <li>Query Optimization</li> <li>Index Performance</li> <li>Search Precision</li> <li>Search Recall</li> <li>F-Measure</li> <li>F1 Score</li> <li>Confusion Matrix</li> <li>True Positive</li> <li>False Positive</li> </ol>"},{"location":"chapters/03-semantic-search-quality-metrics/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> <li>Chapter 2: Search Technologies and Indexing Techniques</li> </ul>"},{"location":"chapters/03-semantic-search-quality-metrics/#introduction-beyond-keyword-matching","title":"Introduction: Beyond Keyword Matching","text":"<p>The keyword-based search techniques from Chapter 2 work well when users know exact terminology and documents use consistent vocabulary. However, conversational AI systems face a harder challenge: users ask questions in their own words, using synonyms, related concepts, and varying levels of specificity. A user asking \"How do I fix a crashed database?\" expects results about database recovery, restoration, repair, and troubleshooting\u2014even if those documents never use the word \"crashed.\" This is where semantic search becomes essential.</p> <p>This chapter introduces techniques for understanding meaning rather than just matching words, along with methods for measuring how well your search system actually performs. You'll explore how to enrich documents with structured metadata, calculate similarity between concepts using vector mathematics, rank results by relevance and authority, optimize search performance, and rigorously evaluate search quality using precision, recall, and related metrics. These skills enable you to build conversational AI systems that understand what users mean, not just what they say.</p> <p>Understanding search quality metrics is particularly crucial for iterative improvement. Without objective measurements, you can't tell whether changes to your search system help or hurt. With proper metrics, you can A/B test ranking algorithms, tune similarity thresholds, and demonstrate to stakeholders that your chatbot delivers measurably better results than alternatives.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#enriching-documents-with-metadata-tagging","title":"Enriching Documents with Metadata Tagging","text":"<p>While Chapter 2 introduced metadata as document attributes, metadata tagging specifically refers to the process of assigning descriptive labels and structured information to documents to improve their discoverability and organization. In conversational AI contexts, well-tagged documents enable chatbots to filter results by document type, subject area, intended audience, or creation date\u2014capabilities that significantly improve answer relevance.</p> <p>Effective metadata tagging operates on multiple levels:</p> <ul> <li>Manual tagging: Domain experts assign subject tags, keywords, and classifications based on document content and purpose</li> <li>Automated tagging: NLP algorithms extract entities, topics, and categories from document text</li> <li>Hybrid approaches: Automated extraction suggests tags that human reviewers approve or refine</li> <li>Collaborative tagging: Multiple users contribute tags (folksonomy), useful for community knowledge bases</li> </ul> <p>The challenge lies in balancing tag consistency (using standardized terms) against tag coverage (ensuring all important concepts are represented). Too few tags and documents become hard to find; too many tags and the tag namespace becomes cluttered with overlapping, redundant, or contradictory labels. Enterprise organizations often establish tag governance processes defining approved tag vocabularies, tag hierarchies, and tagging policies.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#dublin-core-a-metadata-standard","title":"Dublin Core: A Metadata Standard","text":"<p>Dublin Core represents one of the most widely adopted metadata standards, defining 15 core elements for describing information resources. Originally developed in 1995 in Dublin, Ohio for describing web resources, Dublin Core has become an ISO standard (ISO 15836) used across libraries, archives, museums, and digital repositories worldwide. Understanding Dublin Core provides a foundation for metadata design across any domain.</p> <p>The 15 Dublin Core elements fall into three groups describing content, intellectual property, and instantiation:</p> <p>Content description elements: - Title: Name given to the resource - Subject: Topic of the content (keywords or classification codes) - Description: Account of the content (abstract, table of contents, or free-text description) - Type: Nature or genre of the content (text, image, sound, dataset, software, etc.) - Coverage: Spatial or temporal scope (geographic location, time period)</p> <p>Intellectual property elements: - Creator: Entity primarily responsible for making the content - Publisher: Entity responsible for making the resource available - Contributor: Entity that has made contributions to the content - Rights: Information about rights held in and over the resource</p> <p>Instantiation elements: - Date: Point or period of time associated with the lifecycle - Format: File format, physical medium, or dimensions - Identifier: Unambiguous reference (URI, DOI, ISBN, etc.) - Source: Related resource from which this resource is derived - Language: Language of the intellectual content - Relation: Related resource (is part of, has version, references, etc.)</p> Dublin Core Metadata Example for Technical Documentation     Type: markdown-table  Purpose: Show how Dublin Core elements are applied to a technical document in a conversational AI knowledge base  | Dublin Core Element | Value | Usage in Search/Chatbot | |---------------------|-------|-------------------------| | Title | \"PostgreSQL Backup and Recovery Guide\" | Primary matching for title searches | | Creator | \"Database Administration Team\" | Filter by author/team | | Subject | \"Database, Backup, Recovery, PostgreSQL, RDBMS\" | Keyword matching and topic filtering | | Description | \"Comprehensive guide covering backup strategies, point-in-time recovery, and disaster recovery procedures for PostgreSQL 14+\" | Searchable full-text, displayed in result snippets | | Publisher | \"IT Operations Department\" | Filter by source organization | | Contributor | \"John Smith, Maria Garcia\" | Filter by contributor | | Date | \"2024-03-15\" | Temporal filtering (show recent docs) | | Type | \"Technical Documentation\" | Filter by document type | | Format | \"application/pdf\" | Format-based filtering | | Identifier | \"DOC-DBA-2024-003\" | Unique reference for citation | | Source | \"PostgreSQL Official Documentation v14\" | Provenance tracking | | Language | \"en-US\" | Language filtering | | Coverage | \"PostgreSQL 14.x, 15.x\" | Version-specific filtering | | Rights | \"Internal use only - Confidential\" | Access control, security filtering | | Relation | \"Supersedes: DOC-DBA-2023-012\" | Version navigation, related docs |   <p>For chatbot applications, Dublin Core metadata enables sophisticated query handling. When a user asks \"Show me recent PostgreSQL documentation from the DBA team,\" the chatbot can filter by Type=\"Technical Documentation\" AND Subject contains \"PostgreSQL\" AND Creator=\"Database Administration Team\" AND Date within last 6 months. This structured metadata filtering dramatically improves precision compared to pure full-text search, which might return any document mentioning these terms in passing.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#understanding-semantic-search","title":"Understanding Semantic Search","text":"<p>Semantic search represents a fundamental shift from keyword matching to meaning matching. Rather than asking \"Do the query words appear in the document?\" semantic search asks \"Does the document's meaning relate to the query's meaning?\" This distinction enables systems to find relevant documents even when they use completely different vocabulary than the query.</p> <p>Semantic search systems employ several techniques to understand meaning:</p> <ul> <li>Concept extraction: Identifying the underlying concepts in both queries and documents beyond surface words</li> <li>Relationship understanding: Recognizing that \"database crashed\" relates to \"database recovery\" through cause-effect relationships</li> <li>Contextual interpretation: Understanding that \"Python\" likely means the programming language in a technical knowledge base, not the snake</li> <li>Intent recognition: Determining whether the user wants a definition, procedure, troubleshooting guide, or conceptual explanation</li> </ul> <p>The practical implementation of semantic search has evolved significantly over the past decade. Early approaches relied heavily on manually curated ontologies and knowledge bases encoding semantic relationships. Modern approaches increasingly use machine learning techniques\u2014particularly embeddings and vector representations\u2014to automatically learn semantic relationships from large text corpora. These learned representations capture subtle semantic nuances that would be impractical to encode manually.</p> <p>The transition from keyword to semantic search involves trade-offs. Semantic search typically delivers higher recall (finding more relevant documents) but may sacrifice some precision (returning some less relevant results). It requires more computational resources (calculating semantic similarity is more expensive than keyword matching). However, for conversational AI applications where users employ natural language and expect intelligent understanding, semantic search has become essentially mandatory for good user experience.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#vector-representations-and-similarity-measures","title":"Vector Representations and Similarity Measures","text":"<p>The mathematical foundation of modern semantic search lies in vector similarity\u2014representing words, sentences, or documents as points in high-dimensional space, then measuring how close these points are to each other. Documents with similar meanings end up near each other in this space, even if they use different words. This elegant approach transforms the fuzzy concept of \"semantic similarity\" into precise mathematical calculations.</p> <p>A vector representation (often called an embedding) might represent a document as a list of 300 or 768 numbers. Each dimension captures some aspect of meaning\u2014perhaps one dimension represents \"technical vs. casual,\" another \"database-related vs. network-related,\" another \"conceptual vs. procedural.\" The specific meaning of individual dimensions is often opaque (learned by machine learning models), but collectively these dimensions encode semantic information effectively.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#cosine-similarity-measuring-angular-distance","title":"Cosine Similarity: Measuring Angular Distance","text":"<p>Cosine similarity measures the cosine of the angle between two vectors, providing a value between -1 (completely opposite) and +1 (identical direction), with 0 indicating orthogonality (unrelated). For text similarity, we typically normalize vectors and get values between 0 (completely dissimilar) and 1 (identical). Cosine similarity has become the dominant metric for comparing document embeddings because it focuses on directional similarity rather than magnitude.</p> <p>The formula for cosine similarity between vectors A and B is:</p> <pre><code>cosine_similarity(A, B) = (A \u00b7 B) / (||A|| \u00d7 ||B||)\n</code></pre> <p>Where: - <code>A \u00b7 B</code> is the dot product (sum of element-wise products) - <code>||A||</code> is the magnitude (length) of vector A - <code>||B||</code> is the magnitude (length) of vector B</p> <p>Why use angle rather than distance? Consider two documents: a short abstract and a full book chapter about the same topic. They have similar meaning but vastly different lengths. If we represented them as vectors where dimensions represent word frequencies, the book chapter's vector would have much larger magnitude. Cosine similarity ignores this magnitude difference and focuses on direction\u2014both vectors point in the same semantic direction, so they get high similarity scores despite different lengths.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#euclidean-distance-measuring-spatial-separation","title":"Euclidean Distance: Measuring Spatial Separation","text":"<p>Euclidean distance calculates the straight-line distance between two points in vector space, equivalent to the familiar distance formula from geometry. For two-dimensional vectors, it's the Pythagorean theorem; for higher dimensions, it generalizes naturally. Unlike cosine similarity (which ranges 0-1), Euclidean distance ranges from 0 (identical) to infinity (arbitrarily far apart).</p> <p>The formula for Euclidean distance between vectors A and B is:</p> <pre><code>euclidean_distance(A, B) = sqrt(\u03a3(A[i] - B[i])\u00b2)\n</code></pre> <p>Where the sum is taken over all dimensions i in the vectors.</p> <p>Euclidean distance works well when vector magnitude carries meaningful information. For example, in a space where dimensions represent explicit features with comparable scales (document length, technical complexity score, recency), Euclidean distance appropriately treats a document with score [5, 3, 8] as more similar to [6, 4, 7] than to [2, 1, 3], even though all three might point in similar directions.</p> Vector Similarity Comparison Interactive MicroSim     Type: microsim  Learning objective: Visualize and understand the difference between cosine similarity and Euclidean distance for measuring document similarity  Canvas layout (1000x700px): - Left section (600x700): 2D visualization area showing vector space with document vectors - Right section (400x700): Control panel and metrics display  Visual elements: - 2D coordinate system with X and Y axes (representing two semantic dimensions) - Query vector (red arrow from origin, labeled \"Query\") - Document vectors (blue arrows from origin, labeled Doc1, Doc2, Doc3, etc.) - Similarity visualization:   * For cosine similarity: Show angle between query and each document vector   * For Euclidean distance: Show straight line connecting query point to document point - Highlighted \"most similar\" document based on selected metric  Sample scenario: - Query vector: [4, 3] - Doc1: [8, 6] (same direction, double magnitude) - Doc2: [3, 4] (similar magnitude, slightly different direction) - Doc3: [2, 8] (very different direction) - Doc4: [1, 1] (same direction, smaller magnitude)  Interactive controls: - Radio buttons: Select similarity metric   * Cosine Similarity (default)   * Euclidean Distance - Sliders: Adjust query vector   * X coordinate (0-10, default: 4)   * Y coordinate (0-10, default: 3) - Buttons: Preset scenarios   * \"Same direction, different magnitudes\"   * \"Same magnitude, different directions\"   * \"Mixed scenario\"   * \"Random documents\" - Checkbox: \"Normalize vectors\" (for Euclidean distance comparison)  Metrics display area: - Table showing for each document:   * Document ID   * Cosine similarity to query   * Euclidean distance to query   * Rank by selected metric - Highlight row of \"most similar\" document  Behavior: - When query sliders move, query vector updates in real-time - When metric changes, visualization updates to show appropriate measurement   * Cosine: Draw angle arcs between query and documents   * Euclidean: Draw distance lines from query to documents - Color code documents by similarity:   * Green: Most similar   * Yellow: Moderately similar   * Red: Least similar - Display numeric values on hover  Educational annotations: - When cosine selected and Doc1 (same direction, different magnitude) is most similar:   * \"Cosine similarity ignores magnitude - Doc1 has same direction as query\" - When Euclidean selected and Doc2 (similar magnitude) is most similar:   * \"Euclidean distance considers both direction and magnitude\" - Show specific insight: \"Doc1 cosine: 1.00, Doc4 cosine: 1.00 (same direction!)\" - Show specific insight: \"Doc1 Euclidean: 6.40, Doc4 Euclidean: 3.16 (different distances)\"  Implementation notes: - Use p5.js for rendering - Implement vector math functions (dot product, magnitude, cosine, distance) - Draw vectors as arrows using line() and triangle for arrowhead - Use arc() to show angles for cosine similarity mode - Use line() with dashed stroke for distance lines - Update all calculations in real-time as sliders move  <p>The choice between cosine similarity and Euclidean distance depends on your application. For text embeddings from models like BERT or sentence transformers, cosine similarity is standard because these models produce normalized vectors where magnitude is not semantically meaningful. For feature vectors where magnitude matters (perhaps combining semantic similarity with recency scores and user ratings), Euclidean distance or other distance metrics may be more appropriate.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#ranking-results-by-relevance-and-authority","title":"Ranking Results by Relevance and Authority","text":"<p>Finding potentially relevant documents solves only half the search problem; the other half is search ranking\u2014determining which results to show first. Users rarely examine more than the top 10 results, so ranking quality directly impacts perceived search effectiveness. Poor ranking makes good search engines feel bad; excellent ranking makes decent search engines feel great.</p> <p>Ranking algorithms typically combine multiple signals:</p> <ul> <li>Query relevance: How well does the document match the query (keyword overlap, semantic similarity)?</li> <li>Document quality: Is this a high-quality, authoritative source?</li> <li>Recency: Is this information current or outdated?</li> <li>User engagement: Do users click this result and find it helpful?</li> <li>Personalization: Does this match the current user's role, preferences, or history?</li> </ul> <p>Effective ranking is critical for chatbot applications. When a chatbot presents an answer synthesized from multiple sources, it should primarily draw from the highest-ranked (most relevant, most authoritative) documents. Answering from low-quality or tangentially-related sources makes the chatbot appear unreliable.</p>"},{"location":"chapters/03-semantic-search-quality-metrics/#the-page-rank-algorithm-measuring-authority","title":"The Page Rank Algorithm: Measuring Authority","text":"<p>The Page Rank algorithm, developed by Google founders Larry Page and Sergey Brin, revolutionized web search by using link structure to measure document authority. The core insight: a page linked to by many high-quality pages is probably high-quality itself. This recursive definition\u2014important pages are linked to by other important pages\u2014creates a powerful ranking signal resistant to simple manipulation.</p> <p>Page Rank models the web as a directed graph where pages are nodes and links are edges. It simulates a \"random surfer\" who clicks links randomly, occasionally jumping to random pages. The probability that this surfer is on any given page at any moment represents that page's Page Rank. Pages that many paths lead to accumulate higher probability and thus higher rank.</p> <p>The simplified Page Rank formula for page A is:</p> <pre><code>PR(A) = (1-d)/N + d \u00d7 \u03a3(PR(T[i]) / C(T[i]))\n</code></pre> <p>Where: - <code>d</code> is a damping factor (typically 0.85) representing probability surfer follows a link - <code>N</code> is total number of pages - <code>T[i]</code> are pages linking to page A - <code>C(T[i])</code> is the count of outbound links from page T[i] - The sum is over all pages T that link to A</p> Page Rank Algorithm Visualization     Type: graph-model  Purpose: Visualize how Page Rank flows through a document citation network, demonstrating how authority propagates  Node types: 1. Document (circles with varying sizes based on Page Rank score)    - Properties: title, page_rank_score, inbound_link_count, outbound_link_count    - Examples: \"Database Administration Guide\", \"PostgreSQL Backup Tutorial\", \"Recovery Best Practices\"  Edge types: 1. CITES (directed arrows from citing document to cited document)    - Properties: link_weight (for visualization thickness)    - Represents: One document citing/referencing another  Sample data (10 documents): 1. \"Database Fundamentals\" - Central authoritative doc with many inbound citations 2. \"PostgreSQL Backup Guide\" - High-quality doc cited by many specific tutorials 3. \"MySQL Administration\" - Another authoritative doc in different subtopic 4. \"Quick Backup Tutorial\" - Cites Database Fundamentals and PostgreSQL Backup Guide 5. \"Recovery Procedures\" - Cites Database Fundamentals and PostgreSQL Backup Guide 6. \"Disaster Recovery\" - Cites Database Fundamentals and Recovery Procedures 7. \"Point-in-Time Recovery\" - Cites PostgreSQL Backup Guide and Recovery Procedures 8. \"Automated Backup Scripts\" - Cites PostgreSQL Backup Guide 9. \"Backup Testing\" - Cites Quick Backup Tutorial and PostgreSQL Backup Guide 10. \"Legacy Backup Methods\" - Isolated doc with no citations (low Page Rank)  Link structure (directed edges): - Doc 4 \u2192 Doc 1, Doc 2 - Doc 5 \u2192 Doc 1, Doc 2 - Doc 6 \u2192 Doc 1, Doc 5 - Doc 7 \u2192 Doc 2, Doc 5 - Doc 8 \u2192 Doc 2 - Doc 9 \u2192 Doc 2, Doc 4 - Docs 1, 2, 3 have no outbound links (terminal authorities) - Doc 10 has no inbound or outbound links (isolated)  Calculated Page Rank scores (example values): - Doc 1: 0.25 (highest - cited by many) - Doc 2: 0.22 (very high - cited by many) - Doc 3: 0.15 (high - independent authority) - Doc 5: 0.12 (medium - cited by some, cites authorities) - Doc 4, 6, 7: 0.08-0.10 (medium) - Doc 8, 9: 0.05-0.06 (low - leaf nodes) - Doc 10: 0.03 (lowest - isolated)  Visual styling: - Node size proportional to Page Rank score (larger = higher rank) - Node color gradient: Dark green (highest rank) \u2192 Yellow \u2192 Red (lowest rank) - Edge thickness proportional to Page Rank flow along that link - Edge color: Blue for active citation links  Layout: Force-directed with high-rank nodes gravitating toward center  Interactive features: - Hover over node: Show Page Rank score, inbound/outbound link counts, title - Click node: Highlight all nodes that cite this one (inbound) in green, all nodes it cites (outbound) in blue - Button: \"Run Page Rank Iteration\" - Animate one iteration showing rank flowing through links - Button: \"Reset\" - Return to initial state - Slider: Damping factor (0.1 to 0.95, default 0.85) - Recalculate ranks when changed - Display: Current iteration number, convergence status - Toggle: \"Show rank flow animation\" - Animate particles flowing along edges  Animation behavior: - When \"Run Iteration\" clicked:   * Show animated particles flowing from each node to nodes it cites   * Particle speed proportional to rank transferred   * Update node sizes and colors as ranks recalculate   * Continue for 10 iterations or until convergence - Final state: Nodes sized and colored by final Page Rank scores  Educational annotations: - \"Doc 1 has highest rank - cited by 3 documents\" - \"Doc 10 is isolated - has lowest possible rank\" - \"Doc 5 gains rank from citations and passes it to Doc 1 and Doc 2\" - \"Lowering damping factor reduces importance of link structure\"  Legend: - Node size scale (0.03 \u2192 0.25) - Color gradient (red \u2192 yellow \u2192 green) - Edge meaning (citation relationship)  Canvas size: 1000x800px  Implementation: vis-network JavaScript library with physics simulation"},{"location":"chapters/04-large-language-models-tokenization/","title":"Large Language Models and Tokenization","text":""},{"location":"chapters/04-large-language-models-tokenization/#summary","title":"Summary","text":"<p>This chapter introduces large language models (LLMs), the powerful AI systems that enable modern conversational agents to understand and generate human-like text. You will learn about transformer architecture, the attention mechanism that makes LLMs effective, and the critical process of tokenization that converts text into units processable by neural networks. These concepts form the foundation for understanding how chatbots generate intelligent responses.</p>"},{"location":"chapters/04-large-language-models-tokenization/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 7 concepts from the learning graph:</p> <ol> <li>Large Language Model</li> <li>Transformer Architecture</li> <li>Attention Mechanism</li> <li>Token</li> <li>Tokenization</li> <li>Subword Tokenization</li> <li>Byte Pair Encoding</li> </ol>"},{"location":"chapters/04-large-language-models-tokenization/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/05-embeddings-vector-databases/","title":"Embeddings and Vector Databases","text":""},{"location":"chapters/05-embeddings-vector-databases/#summary","title":"Summary","text":"<p>This chapter explores how words and sentences can be represented as numerical vectors in high-dimensional spaces, enabling machines to understand semantic relationships between text. You will learn about various embedding models including Word2Vec, GloVe, and FastText, understand vector space models and dimensionality, and discover how vector databases enable fast similarity searches. These technologies are essential for semantic search and retrieval-augmented generation systems.</p>"},{"location":"chapters/05-embeddings-vector-databases/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 17 concepts from the learning graph:</p> <ol> <li>Word Embedding</li> <li>Embedding Vector</li> <li>Vector Space Model</li> <li>Vector Dimension</li> <li>Embedding Model</li> <li>Word2Vec</li> <li>GloVe</li> <li>FastText</li> <li>Sentence Embedding</li> <li>Contextual Embedding</li> <li>Vector Database</li> <li>Vector Store</li> <li>Vector Index</li> <li>Approximate Nearest Neighbor</li> <li>FAISS</li> <li>Pinecone</li> <li>Weaviate</li> </ol>"},{"location":"chapters/05-embeddings-vector-databases/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> <li>Chapter 3: Semantic Search and Quality Metrics</li> <li>Chapter 4: Large Language Models and Tokenization</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/06-building-chatbots-intent/","title":"Building Chatbots and Intent Recognition","text":""},{"location":"chapters/06-building-chatbots-intent/#summary","title":"Summary","text":"<p>This chapter introduces the core concepts and techniques for building conversational agents, focusing on understanding user intentions and extracting relevant information from queries. You will learn about chatbot architectures, dialog systems, intent recognition and classification, entity extraction techniques, and how to build FAQ-based systems. These foundational chatbot concepts prepare you to create intelligent conversational interfaces.</p>"},{"location":"chapters/06-building-chatbots-intent/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 15 concepts from the learning graph:</p> <ol> <li>Chatbot</li> <li>Conversational Agent</li> <li>Dialog System</li> <li>Intent Recognition</li> <li>Intent Modeling</li> <li>Intent Classification</li> <li>Entity Extraction</li> <li>Named Entity Recognition</li> <li>Entity Type</li> <li>Entity Linking</li> <li>FAQ</li> <li>FAQ Analysis</li> <li>Question-Answer Pair</li> <li>User Query</li> <li>User Intent</li> </ol>"},{"location":"chapters/06-building-chatbots-intent/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> <li>Chapter 4: Large Language Models and Tokenization</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/07-chatbot-frameworks-ui/","title":"Chatbot Frameworks and User Interfaces","text":""},{"location":"chapters/07-chatbot-frameworks-ui/#summary","title":"Summary","text":"<p>This chapter explores the practical tools, frameworks, and interface components used to build production-ready chatbots. You will learn about popular chatbot frameworks like Rasa, Dialogflow, LangChain, and LlamaIndex, discover JavaScript libraries for chatbot development, and understand how to design effective chat user interfaces. Additionally, you will explore conversation management including chat history, context preservation, and session handling.</p>"},{"location":"chapters/07-chatbot-frameworks-ui/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 16 concepts from the learning graph:</p> <ol> <li>Chatbot Response</li> <li>Response Generation</li> <li>Response Quality</li> <li>Response Latency</li> <li>Conversation Context</li> <li>Session Management</li> <li>Chatbot Framework</li> <li>Rasa</li> <li>Dialogflow</li> <li>Botpress</li> <li>LangChain</li> <li>LlamaIndex</li> <li>JavaScript Library</li> <li>Node.js</li> <li>React Chatbot</li> <li>Chat Widget</li> </ol>"},{"location":"chapters/07-chatbot-frameworks-ui/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Building Chatbots and Intent Recognition</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/08-user-feedback-improvement/","title":"User Feedback and Continuous Improvement","text":""},{"location":"chapters/08-user-feedback-improvement/#summary","title":"Summary","text":"<p>This chapter focuses on collecting user feedback to continuously improve chatbot performance through iterative learning cycles. You will learn about feedback mechanisms including thumbs up/down buttons, the AI flywheel concept that drives continuous improvement, and techniques for personalizing chatbot responses based on user context, preferences, and history. Understanding these concepts enables you to build chatbots that learn and improve over time.</p>"},{"location":"chapters/08-user-feedback-improvement/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 15 concepts from the learning graph:</p> <ol> <li>User Feedback</li> <li>Feedback Button</li> <li>Thumbs Up/Down</li> <li>Feedback Loop</li> <li>AI Flywheel</li> <li>Continuous Improvement</li> <li>User Interface</li> <li>Chat Interface</li> <li>Message Bubble</li> <li>Chat History</li> <li>User Context</li> <li>User Profile</li> <li>User Preferences</li> <li>User History</li> <li>Personalization</li> </ol>"},{"location":"chapters/08-user-feedback-improvement/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Building Chatbots and Intent Recognition</li> <li>Chapter 7: Chatbot Frameworks and User Interfaces</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/09-rag-pattern/","title":"The Retrieval Augmented Generation Pattern","text":""},{"location":"chapters/09-rag-pattern/#summary","title":"Summary","text":"<p>This chapter introduces the Retrieval Augmented Generation (RAG) pattern, a powerful technique that enhances LLM responses by retrieving relevant information from external knowledge sources. You will learn about the three-step RAG process (retrieval, augmentation, generation), how to work with both public and private knowledge bases, prompt engineering techniques, context windows, and important limitations including hallucination. The RAG pattern is essential for building chatbots that provide accurate, up-to-date information grounded in specific knowledge sources.</p>"},{"location":"chapters/09-rag-pattern/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>External Knowledge</li> <li>Public Knowledge Base</li> <li>Internal Knowledge</li> <li>Private Documents</li> <li>Document Corpus</li> <li>RAG Pattern</li> <li>Retrieval Augmented Generation</li> <li>Retrieval Step</li> <li>Augmentation Step</li> <li>Generation Step</li> <li>Context Window</li> <li>Prompt Engineering</li> <li>System Prompt</li> <li>User Prompt</li> <li>RAG Limitations</li> <li>Context Length Limit</li> <li>Hallucination</li> <li>Factual Accuracy</li> </ol>"},{"location":"chapters/09-rag-pattern/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 4: Large Language Models and Tokenization</li> <li>Chapter 5: Embeddings and Vector Databases</li> <li>Chapter 6: Building Chatbots and Intent Recognition</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/10-knowledge-graphs-graphrag/","title":"Knowledge Graphs and GraphRAG","text":""},{"location":"chapters/10-knowledge-graphs-graphrag/#summary","title":"Summary","text":"<p>This chapter explores knowledge graphs as structured representations of information and introduces the GraphRAG pattern that combines graph databases with retrieval-augmented generation. You will learn about graph database fundamentals including nodes, edges, and triples, query languages like Cypher and OpenCypher, the RDF standard, and how knowledge graphs can serve as the \"corporate nervous system\" for organizations. The GraphRAG pattern addresses many limitations of traditional RAG by leveraging the rich relationships encoded in knowledge graphs.</p>"},{"location":"chapters/10-knowledge-graphs-graphrag/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 15 concepts from the learning graph:</p> <ol> <li>GraphRAG Pattern</li> <li>Knowledge Graph</li> <li>Graph Database</li> <li>Node</li> <li>Edge</li> <li>Triple</li> <li>Subject-Predicate-Object</li> <li>RDF</li> <li>Graph Query</li> <li>OpenCypher</li> <li>Cypher Query Language</li> <li>Neo4j</li> <li>Corporate Nervous System</li> <li>Organizational Knowledge</li> <li>Knowledge Management</li> </ol>"},{"location":"chapters/10-knowledge-graphs-graphrag/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Search Technologies and Indexing Techniques</li> <li>Chapter 9: The Retrieval Augmented Generation Pattern</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/11-nlp-pipelines-processing/","title":"NLP Pipelines and Text Processing","text":""},{"location":"chapters/11-nlp-pipelines-processing/#summary","title":"Summary","text":"<p>This chapter covers NLP pipelines and advanced text processing techniques that prepare raw text for analysis and understanding by conversational AI systems. You will learn about text preprocessing steps including normalization, stemming, and lemmatization, as well as linguistic analysis techniques like part-of-speech tagging, dependency parsing, and coreference resolution. These NLP pipeline components are essential for extracting structured information from unstructured text.</p>"},{"location":"chapters/11-nlp-pipelines-processing/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 8 concepts from the learning graph:</p> <ol> <li>NLP Pipeline</li> <li>Text Preprocessing</li> <li>Text Normalization</li> <li>Stemming</li> <li>Lemmatization</li> <li>Part-of-Speech Tagging</li> <li>Dependency Parsing</li> <li>Coreference Resolution</li> </ol>"},{"location":"chapters/11-nlp-pipelines-processing/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</li> <li>Chapter 6: Building Chatbots and Intent Recognition</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/12-database-queries-parameters/","title":"Database Queries and Parameter Extraction","text":""},{"location":"chapters/12-database-queries-parameters/#summary","title":"Summary","text":"<p>This chapter teaches how to enable chatbots to execute database queries based on natural language questions, a critical capability for data-driven conversational applications. You will learn about database query fundamentals, SQL query construction, parameter extraction from user questions, query templates and parameterization, natural language to SQL conversion, and slot filling techniques. These skills enable chatbots to answer questions that require accessing structured data from databases.</p>"},{"location":"chapters/12-database-queries-parameters/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 11 concepts from the learning graph:</p> <ol> <li>Database Query</li> <li>SQL Query</li> <li>Query Parameter</li> <li>Parameter Extraction</li> <li>Query Template</li> <li>Parameterized Query</li> <li>Query Execution</li> <li>Query Description</li> <li>Natural Language to SQL</li> <li>Question to Query Mapping</li> <li>Slot Filling</li> </ol>"},{"location":"chapters/12-database-queries-parameters/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Building Chatbots and Intent Recognition</li> <li>Chapter 11: NLP Pipelines and Text Processing</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/13-security-privacy-users/","title":"Security, Privacy, and User Management","text":""},{"location":"chapters/13-security-privacy-users/#summary","title":"Summary","text":"<p>This chapter addresses critical security, privacy, and access control considerations for production chatbot systems. You will learn about authentication and authorization mechanisms, role-based access control (RBAC), data privacy regulations including GDPR, handling personally identifiable information (PII), data retention policies, and logging systems for monitoring and compliance. Understanding these concepts is essential for building chatbots that protect user data and comply with regulatory requirements.</p>"},{"location":"chapters/13-security-privacy-users/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 16 concepts from the learning graph:</p> <ol> <li>Security</li> <li>Authentication</li> <li>Authorization</li> <li>User Permission</li> <li>Role-Based Access Control</li> <li>RBAC</li> <li>Access Policy</li> <li>Data Privacy</li> <li>PII</li> <li>Personally Identifiable Info</li> <li>GDPR</li> <li>Data Retention</li> <li>Log Storage</li> <li>Chat Log</li> <li>Logging System</li> <li>Log Analysis</li> </ol>"},{"location":"chapters/13-security-privacy-users/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Building Chatbots and Intent Recognition</li> <li>Chapter 8: User Feedback and Continuous Improvement</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/14-evaluation-optimization-careers/","title":"Evaluation, Optimization, and Career Development","text":""},{"location":"chapters/14-evaluation-optimization-careers/#summary","title":"Summary","text":"<p>This chapter covers the evaluation and optimization of chatbot systems, along with career opportunities in the conversational AI field. You will learn about chatbot metrics and KPIs, dashboard design for monitoring performance, techniques for measuring user satisfaction and acceptance rates, A/B testing methodologies, performance tuning strategies, and approaches for team and capstone projects. The chapter concludes with an exploration of career paths in chatbot development and conversational AI.</p>"},{"location":"chapters/14-evaluation-optimization-careers/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>Query Frequency</li> <li>Frequency Analysis</li> <li>Pareto Analysis</li> <li>80/20 Rule</li> <li>Chatbot Metrics</li> <li>KPI</li> <li>Key Performance Indicator</li> <li>Chatbot Dashboard</li> <li>Acceptance Rate</li> <li>User Satisfaction</li> <li>Response Accuracy</li> <li>Chatbot Evaluation</li> <li>A/B Testing</li> <li>Performance Tuning</li> <li>Optimization</li> <li>Team Project</li> <li>Capstone Project</li> <li>Chatbot Career</li> </ol>"},{"location":"chapters/14-evaluation-optimization-careers/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 3: Semantic Search and Quality Metrics</li> <li>Chapter 7: Chatbot Frameworks and User Interfaces</li> <li>Chapter 8: User Feedback and Continuous Improvement</li> <li>Chapter 13: Security, Privacy, and User Management</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"learning-graph/","title":"Learning Graph for Conversational AI","text":"<p>This section contains the learning graph for this textbook. A learning graph is a graph of concepts used in this textbook. Each concept is represented by a node in a network graph. Concepts are connected by directed edges that indicate what concepts each node depends on before that concept is understood by the student.</p> <p>A learning graph is the foundational data structure for intelligent textbooks that can recommend learning paths. A learning graph is like a roadmap of concepts to help students arrive at their learning goals.</p> <p>At the left of the learning graph are prerequisite or foundational concepts. They have no outbound edges. They only have inbound edges for other concepts that depend on understanding these foundational prerequisite concepts. At the far right we have the most advanced concepts in the course. To master these concepts you must understand all the concepts that they point to.</p> <p>Here are other files used by the learning graph.</p>"},{"location":"learning-graph/#course-description","title":"Course Description","text":"<p>We use the Course Description as the source document for the concepts that are included in this course. The course description uses the 2001 Bloom taxonomy to order learning objectives.</p>"},{"location":"learning-graph/#list-of-concepts","title":"List of Concepts","text":"<p>We use generative AI to convert the course description into a Concept List. Each concept is in the form of a short Title Case label with most labels under 32 characters long.</p>"},{"location":"learning-graph/#concept-dependency-list","title":"Concept Dependency List","text":"<p>We next use generative AI to create a Directed Acyclic Graph (DAG). DAGs do not have cycles where concepts depend on themselves. We provide the DAG in two formats. One is a CSV file and the other format is a JSON file that uses the vis-network JavaScript library format. The vis-network format uses <code>nodes</code>, <code>edges</code> and <code>metadata</code> elements with edges containing <code>from</code> and <code>to</code> properties. This makes it easy for you to view and edit the learning graph using an editor built with the vis-network tools.</p>"},{"location":"learning-graph/#analysis-documentation","title":"Analysis &amp; Documentation","text":""},{"location":"learning-graph/#course-description-quality-assessment","title":"Course Description Quality Assessment","text":"<p>This report rates the overall quality of the course description for the purpose of generating a learning graph.</p> <ul> <li>Course description fields and content depth analysis</li> <li>Validates course description has sufficient depth for generating 200 concepts</li> <li>Compares course description against similar courses</li> <li>Identifies content gaps and strengths</li> <li>Suggests areas of improvement</li> </ul> <p>View the Course Description Quality Assessment</p>"},{"location":"learning-graph/#learning-graph-quality-validation","title":"Learning Graph Quality Validation","text":"<p>This report gives you an overall assessment of the quality of the learning graph. It uses graph algorithms to look for specific quality patterns in the graph.</p> <ul> <li>Graph structure validation - all concepts are connected</li> <li>DAG validation (no cycles detected)</li> <li>Foundational concepts: 7 entry points</li> <li>Indegree distribution analysis</li> <li>Longest dependency chains</li> <li>Connectivity: all nodes connected in single graph</li> </ul> <p>View the Learning Graph Quality Validation</p>"},{"location":"learning-graph/#concept-taxonomy","title":"Concept Taxonomy","text":"<p>In order to see patterns in the learning graph, it is useful to assign colors to each concept based on the concept type. We use generative AI to create about a dozen categories for our concepts and then place each concept into a single primary classifier.</p> <ul> <li>A concept classifier taxonomy with 13 categories</li> <li>Category organization - foundational elements first, course projects last</li> <li>Balanced categories (1.5% - 23% each)</li> <li>All categories under 30% threshold</li> <li>Pedagogical flow recommendations</li> <li>Clear 3-5 letter abbreviations for use in CSV file</li> </ul> <p>View the Concept Taxonomy</p>"},{"location":"learning-graph/#taxonomy-distribution","title":"Taxonomy Distribution","text":"<p>This report shows how many concepts fit into each category of the taxonomy. Our goal is a somewhat balanced taxonomy where each category holds an equal number of concepts. We also don't want any category to contain over 30% of our concepts.</p> <ul> <li>Statistical breakdown</li> <li>Detailed concept listing by category</li> <li>Visual distribution table</li> <li>Balance verification</li> </ul> <p>View the Taxonomy Distribution Report</p>"},{"location":"learning-graph/concept-list/","title":"Concept List for Conversational AI Course","text":"<p>This list contains 200 concepts organized to support the learning graph generation.</p> <ol> <li>Artificial Intelligence</li> <li>AI Timeline</li> <li>AI Doubling Rate</li> <li>Moore's Law</li> <li>Natural Language Processing</li> <li>Text Processing</li> <li>String Matching</li> <li>Regular Expressions</li> <li>Grep Command</li> <li>Keyword Search</li> <li>Search Index</li> <li>Inverted Index</li> <li>Reverse Index</li> <li>Full-Text Search</li> <li>Boolean Search</li> <li>Search Query</li> <li>Query Parser</li> <li>Synonym Expansion</li> <li>Thesaurus</li> <li>Ontology</li> <li>Taxonomy</li> <li>Controlled Vocabulary</li> <li>Metadata</li> <li>Metadata Tagging</li> <li>Dublin Core</li> <li>Semantic Search</li> <li>Vector Similarity</li> <li>Cosine Similarity</li> <li>Euclidean Distance</li> <li>Search Ranking</li> <li>Page Rank Algorithm</li> <li>TF-IDF</li> <li>Term Frequency</li> <li>Document Frequency</li> <li>Search Precision</li> <li>Search Recall</li> <li>F-Measure</li> <li>F1 Score</li> <li>Confusion Matrix</li> <li>True Positive</li> <li>False Positive</li> <li>Search Performance</li> <li>Query Optimization</li> <li>Index Performance</li> <li>Large Language Model</li> <li>Transformer Architecture</li> <li>Attention Mechanism</li> <li>Token</li> <li>Tokenization</li> <li>Subword Tokenization</li> <li>Byte Pair Encoding</li> <li>Word Embedding</li> <li>Embedding Vector</li> <li>Vector Space Model</li> <li>Vector Dimension</li> <li>Embedding Model</li> <li>Word2Vec</li> <li>GloVe</li> <li>FastText</li> <li>Sentence Embedding</li> <li>Contextual Embedding</li> <li>Vector Database</li> <li>Vector Store</li> <li>Vector Index</li> <li>Approximate Nearest Neighbor</li> <li>FAISS</li> <li>Pinecone</li> <li>Weaviate</li> <li>Chatbot</li> <li>Conversational Agent</li> <li>Dialog System</li> <li>Intent Recognition</li> <li>Intent Modeling</li> <li>Intent Classification</li> <li>Entity Extraction</li> <li>Named Entity Recognition</li> <li>Entity Type</li> <li>Entity Linking</li> <li>FAQ</li> <li>FAQ Analysis</li> <li>Question-Answer Pair</li> <li>User Query</li> <li>User Intent</li> <li>Chatbot Response</li> <li>Response Generation</li> <li>Response Quality</li> <li>Response Latency</li> <li>User Feedback</li> <li>Feedback Button</li> <li>Thumbs Up/Down</li> <li>Feedback Loop</li> <li>AI Flywheel</li> <li>Continuous Improvement</li> <li>User Interface</li> <li>Chat Interface</li> <li>Message Bubble</li> <li>Chat History</li> <li>Conversation Context</li> <li>Session Management</li> <li>Chatbot Framework</li> <li>Rasa</li> <li>Dialogflow</li> <li>Botpress</li> <li>LangChain</li> <li>LlamaIndex</li> <li>JavaScript Library</li> <li>Node.js</li> <li>React Chatbot</li> <li>Chat Widget</li> <li>External Knowledge</li> <li>Public Knowledge Base</li> <li>Internal Knowledge</li> <li>Private Documents</li> <li>Document Corpus</li> <li>RAG Pattern</li> <li>Retrieval Augmented Generation</li> <li>Retrieval Step</li> <li>Augmentation Step</li> <li>Generation Step</li> <li>Context Window</li> <li>Prompt Engineering</li> <li>System Prompt</li> <li>User Prompt</li> <li>RAG Limitations</li> <li>Context Length Limit</li> <li>Hallucination</li> <li>Factual Accuracy</li> <li>GraphRAG Pattern</li> <li>Knowledge Graph</li> <li>Graph Database</li> <li>Node</li> <li>Edge</li> <li>Triple</li> <li>Subject-Predicate-Object</li> <li>RDF</li> <li>Graph Query</li> <li>OpenCypher</li> <li>Cypher Query Language</li> <li>Neo4j</li> <li>Corporate Nervous System</li> <li>Organizational Knowledge</li> <li>Knowledge Management</li> <li>NLP Pipeline</li> <li>Text Preprocessing</li> <li>Text Normalization</li> <li>Stemming</li> <li>Lemmatization</li> <li>Part-of-Speech Tagging</li> <li>Dependency Parsing</li> <li>Coreference Resolution</li> <li>Database Query</li> <li>SQL Query</li> <li>Query Parameter</li> <li>Parameter Extraction</li> <li>Query Template</li> <li>Parameterized Query</li> <li>Query Execution</li> <li>Query Description</li> <li>Natural Language to SQL</li> <li>Question to Query Mapping</li> <li>Slot Filling</li> <li>User Context</li> <li>User Profile</li> <li>User Preferences</li> <li>User History</li> <li>Personalization</li> <li>Security</li> <li>Authentication</li> <li>Authorization</li> <li>User Permission</li> <li>Role-Based Access Control</li> <li>RBAC</li> <li>Access Policy</li> <li>Data Privacy</li> <li>PII</li> <li>Personally Identifiable Info</li> <li>GDPR</li> <li>Data Retention</li> <li>Log Storage</li> <li>Chat Log</li> <li>Logging System</li> <li>Log Analysis</li> <li>Query Frequency</li> <li>Frequency Analysis</li> <li>Pareto Analysis</li> <li>80/20 Rule</li> <li>Chatbot Metrics</li> <li>KPI</li> <li>Key Performance Indicator</li> <li>Chatbot Dashboard</li> <li>Acceptance Rate</li> <li>User Satisfaction</li> <li>Response Accuracy</li> <li>Chatbot Evaluation</li> <li>A/B Testing</li> <li>Performance Tuning</li> <li>Optimization</li> <li>Team Project</li> <li>Capstone Project</li> <li>Chatbot Career</li> </ol>"},{"location":"learning-graph/concept-taxonomy/","title":"Concept Taxonomy","text":"<p>This taxonomy organizes the 200 concepts into 12 categories for better navigation and understanding.</p>"},{"location":"learning-graph/concept-taxonomy/#1-foundation-concepts-found","title":"1. Foundation Concepts (FOUND)","text":"<p>TaxonomyID: FOUND</p> <p>Description: Core AI and NLP fundamentals that form the basis for conversational AI systems, including basic AI concepts, timelines, and natural language processing principles.</p>"},{"location":"learning-graph/concept-taxonomy/#2-search-technologies-search","title":"2. Search Technologies (SEARCH)","text":"<p>TaxonomyID: SEARCH</p> <p>Description: Various search approaches and algorithms including keyword search, semantic search, full-text search, and search indexing techniques like inverted indexes and Page Rank.</p>"},{"location":"learning-graph/concept-taxonomy/#3-search-quality-metrics-metric","title":"3. Search Quality Metrics (METRIC)","text":"<p>TaxonomyID: METRIC</p> <p>Description: Metrics and measurements for evaluating search quality including precision, recall, F-measures, confusion matrices, and performance indicators.</p>"},{"location":"learning-graph/concept-taxonomy/#4-language-models-llm","title":"4. Language Models (LLM)","text":"<p>TaxonomyID: LLM</p> <p>Description: Large language models, transformer architectures, attention mechanisms, and tokenization techniques including subword tokenization and byte pair encoding.</p>"},{"location":"learning-graph/concept-taxonomy/#5-embeddings-and-vectors-embed","title":"5. Embeddings and Vectors (EMBED)","text":"<p>TaxonomyID: EMBED</p> <p>Description: Word embeddings, sentence embeddings, vector spaces, vector databases, and similarity measures like cosine similarity and Euclidean distance.</p>"},{"location":"learning-graph/concept-taxonomy/#6-chatbot-systems-chat","title":"6. Chatbot Systems (CHAT)","text":"<p>TaxonomyID: CHAT</p> <p>Description: Chatbot fundamentals, conversational agents, dialog systems, intent recognition, FAQ systems, user interfaces, and chatbot frameworks.</p>"},{"location":"learning-graph/concept-taxonomy/#7-rag-patterns-rag","title":"7. RAG Patterns (RAG)","text":"<p>TaxonomyID: RAG</p> <p>Description: Retrieval Augmented Generation patterns, including retrieval steps, augmentation, generation, context windows, prompt engineering, and RAG limitations.</p>"},{"location":"learning-graph/concept-taxonomy/#8-knowledge-graphs-graph","title":"8. Knowledge Graphs (GRAPH)","text":"<p>TaxonomyID: GRAPH</p> <p>Description: Knowledge graphs, graph databases, nodes, edges, triples, RDF, graph query languages (OpenCypher, Cypher), and GraphRAG patterns.</p>"},{"location":"learning-graph/concept-taxonomy/#9-nlp-processing-nlp","title":"9. NLP Processing (NLP)","text":"<p>TaxonomyID: NLP</p> <p>Description: NLP pipelines, text preprocessing, normalization, stemming, lemmatization, part-of-speech tagging, dependency parsing, and entity extraction.</p>"},{"location":"learning-graph/concept-taxonomy/#10-query-systems-query","title":"10. Query Systems (QUERY)","text":"<p>TaxonomyID: QUERY</p> <p>Description: Database queries, SQL, query parameters, parameter extraction, natural language to SQL conversion, and query execution systems.</p>"},{"location":"learning-graph/concept-taxonomy/#11-security-and-privacy-sec","title":"11. Security and Privacy (SEC)","text":"<p>TaxonomyID: SEC</p> <p>Description: Security, authentication, authorization, role-based access control, data privacy, PII, GDPR compliance, logging, and data retention policies.</p>"},{"location":"learning-graph/concept-taxonomy/#12-evaluation-and-optimization-eval","title":"12. Evaluation and Optimization (EVAL)","text":"<p>TaxonomyID: EVAL</p> <p>Description: Chatbot evaluation, KPIs, dashboards, acceptance rates, user satisfaction, feedback systems, A/B testing, performance tuning, and optimization strategies.</p>"},{"location":"learning-graph/concept-taxonomy/#13-tools-and-projects-tool","title":"13. Tools and Projects (TOOL)","text":"<p>TaxonomyID: TOOL</p> <p>Description: Chatbot frameworks (Rasa, Dialogflow, LangChain), JavaScript libraries, development tools, team projects, capstone projects, and career paths.</p>"},{"location":"learning-graph/course-description-assessment/","title":"Course Description Quality Assessment","text":"<p>Overall Score: 95/100</p> <p>Quality Rating: Excellent - Ready for learning graph generation</p>"},{"location":"learning-graph/course-description-assessment/#detailed-scoring-breakdown","title":"Detailed Scoring Breakdown","text":"Element Points Earned Max Points Status Title 5 5 \u2713 Complete Target Audience 5 5 \u2713 Complete Prerequisites 0 5 \u2717 Missing Main Topics Covered 10 10 \u2713 Complete Topics Excluded 5 5 \u2713 Complete Learning Outcomes Header 5 5 \u2713 Complete Remember Level 10 10 \u2713 Complete Understand Level 10 10 \u2713 Complete Apply Level 10 10 \u2713 Complete Analyze Level 10 10 \u2713 Complete Evaluate Level 10 10 \u2713 Complete Create Level 10 10 \u2713 Complete Descriptive Context 5 5 \u2713 Complete"},{"location":"learning-graph/course-description-assessment/#summary","title":"Summary","text":"<p>The course description is excellent and well-prepared for learning graph generation. Key strengths include:</p> <ol> <li>Comprehensive Topic Coverage: 70+ topics spanning AI fundamentals through advanced GraphRAG implementations</li> <li>Excellent Bloom's Taxonomy Coverage: All six cognitive levels have 6-7 well-crafted outcomes each</li> <li>Clear Progression: Logical flow from basic keyword search to advanced GraphRAG patterns</li> <li>Practical Focus: Strong emphasis on hands-on projects</li> <li>Well-Defined Boundaries: Clear \"Topics Not Covered\" section</li> </ol>"},{"location":"learning-graph/course-description-assessment/#estimated-concept-potential","title":"Estimated Concept Potential","text":"<p>220-250 concepts can be derived from this course description, well exceeding the target of 200 concepts.</p>"},{"location":"learning-graph/course-description-assessment/#recommendation","title":"Recommendation","text":"<p>\u2713 Proceed with learning graph generation</p> <p>The quality score of 95/100 indicates this course description is ready for comprehensive learning graph generation.</p>"},{"location":"learning-graph/quality-metrics/","title":"Learning Graph Quality Metrics Report","text":""},{"location":"learning-graph/quality-metrics/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 200</li> <li>Foundational Concepts (no dependencies): 7</li> <li>Concepts with Dependencies: 193</li> <li>Average Dependencies per Concept: 1.24</li> </ul>"},{"location":"learning-graph/quality-metrics/#graph-structure-validation","title":"Graph Structure Validation","text":"<ul> <li>Valid DAG Structure: \u274c No</li> <li>Self-Dependencies: None detected \u2705</li> <li>Cycles Detected: 0</li> </ul>"},{"location":"learning-graph/quality-metrics/#foundational-concepts","title":"Foundational Concepts","text":"<p>These concepts have no prerequisites:</p> <ul> <li>1: Artificial Intelligence</li> <li>54: Vector Space Model</li> <li>94: User Interface</li> <li>106: JavaScript Library</li> <li>110: External Knowledge</li> <li>129: Knowledge Graph</li> <li>151: Database Query</li> </ul>"},{"location":"learning-graph/quality-metrics/#dependency-chain-analysis","title":"Dependency Chain Analysis","text":"<ul> <li>Maximum Dependency Chain Length: 13</li> </ul>"},{"location":"learning-graph/quality-metrics/#longest-learning-path","title":"Longest Learning Path:","text":"<ol> <li>Artificial Intelligence (ID: 1)</li> <li>Natural Language Processing (ID: 5)</li> <li>Chatbot (ID: 69)</li> <li>Security (ID: 167)</li> <li>Data Privacy (ID: 174)</li> <li>Data Retention (ID: 178)</li> <li>Log Storage (ID: 179)</li> <li>Chat Log (ID: 180)</li> <li>Log Analysis (ID: 182)</li> <li>Query Frequency (ID: 183)</li> <li>Frequency Analysis (ID: 184)</li> <li>Pareto Analysis (ID: 185)</li> <li>80/20 Rule (ID: 186)</li> </ol>"},{"location":"learning-graph/quality-metrics/#orphaned-nodes-analysis","title":"Orphaned Nodes Analysis","text":"<ul> <li>Total Orphaned Nodes: 93</li> </ul> <p>Concepts that are not prerequisites for any other concept:</p> <ul> <li>4: Moore's Law</li> <li>9: Grep Command</li> <li>13: Reverse Index</li> <li>14: Full-Text Search</li> <li>15: Boolean Search</li> <li>17: Query Parser</li> <li>19: Thesaurus</li> <li>22: Controlled Vocabulary</li> <li>25: Dublin Core</li> <li>26: Semantic Search</li> <li>28: Cosine Similarity</li> <li>29: Euclidean Distance</li> <li>31: Page Rank Algorithm</li> <li>32: TF-IDF</li> <li>38: F1 Score</li> <li>40: True Positive</li> <li>41: False Positive</li> <li>43: Query Optimization</li> <li>44: Index Performance</li> <li>47: Attention Mechanism</li> </ul> <p>...and 73 more</p>"},{"location":"learning-graph/quality-metrics/#connected-components","title":"Connected Components","text":"<ul> <li>Number of Connected Components: 1</li> </ul> <p>\u2705 All concepts are connected in a single graph.</p>"},{"location":"learning-graph/quality-metrics/#indegree-analysis","title":"Indegree Analysis","text":"<p>Top 10 concepts that are prerequisites for the most other concepts:</p> Rank Concept ID Concept Label Indegree 1 10 Keyword Search 11 2 69 Chatbot 11 3 5 Natural Language Processing 9 4 45 Large Language Model 7 5 129 Knowledge Graph 7 6 187 Chatbot Metrics 7 7 1 Artificial Intelligence 6 8 6 Text Processing 6 9 63 Vector Store 5 10 100 Chatbot Framework 5"},{"location":"learning-graph/quality-metrics/#outdegree-distribution","title":"Outdegree Distribution","text":"Dependencies Number of Concepts 0 7 1 149 2 42 3 2"},{"location":"learning-graph/quality-metrics/#recommendations","title":"Recommendations","text":"<ul> <li>\u26a0\ufe0f Many orphaned nodes (93): Consider if these should be prerequisites for advanced concepts</li> <li>\u2139\ufe0f Consider adding cross-dependencies: More connections could create richer learning pathways</li> </ul> <p>Report generated by learning-graph-reports/analyze_graph.py</p>"},{"location":"learning-graph/taxonomy-distribution/","title":"Taxonomy Distribution Report","text":""},{"location":"learning-graph/taxonomy-distribution/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 200</li> <li>Number of Taxonomies: 13</li> <li>Average Concepts per Taxonomy: 15.4</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#distribution-summary","title":"Distribution Summary","text":"Category TaxonomyID Count Percentage Status CHAT CHAT 46 23.0% \u2705 SEARCH SEARCH 28 14.0% \u2705 RAG RAG 18 9.0% \u2705 EMBED EMBED 17 8.5% \u2705 SEC SEC 16 8.0% \u2705 GRAPH GRAPH 15 7.5% \u2705 EVAL EVAL 15 7.5% \u2705 QUERY QUERY 11 5.5% \u2705 Foundation Concepts - Prerequisites FOUND 9 4.5% \u2705 NLP NLP 8 4.0% \u2705 METRIC METRIC 7 3.5% \u2705 LLM LLM 7 3.5% \u2705 TOOL TOOL 3 1.5% \u2139\ufe0f Under"},{"location":"learning-graph/taxonomy-distribution/#visual-distribution","title":"Visual Distribution","text":"<pre><code>CHAT   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  46 ( 23.0%)\nSEARCH \u2588\u2588\u2588\u2588\u2588\u2588\u2588  28 ( 14.0%)\nRAG    \u2588\u2588\u2588\u2588  18 (  9.0%)\nEMBED  \u2588\u2588\u2588\u2588  17 (  8.5%)\nSEC    \u2588\u2588\u2588\u2588  16 (  8.0%)\nGRAPH  \u2588\u2588\u2588  15 (  7.5%)\nEVAL   \u2588\u2588\u2588  15 (  7.5%)\nQUERY  \u2588\u2588  11 (  5.5%)\nFOUND  \u2588\u2588   9 (  4.5%)\nNLP    \u2588\u2588   8 (  4.0%)\nMETRIC \u2588   7 (  3.5%)\nLLM    \u2588   7 (  3.5%)\nTOOL      3 (  1.5%)\n</code></pre>"},{"location":"learning-graph/taxonomy-distribution/#balance-analysis","title":"Balance Analysis","text":""},{"location":"learning-graph/taxonomy-distribution/#no-over-represented-categories","title":"\u2705 No Over-Represented Categories","text":"<p>All categories are under the 30% threshold. Good balance!</p>"},{"location":"learning-graph/taxonomy-distribution/#i-under-represented-categories-3","title":"\u2139\ufe0f Under-Represented Categories (&lt;3%)","text":"<ul> <li>TOOL (TOOL): 3 concepts (1.5%)</li> <li>Note: Small categories are acceptable for specialized topics</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#category-details","title":"Category Details","text":""},{"location":"learning-graph/taxonomy-distribution/#chat-chat","title":"CHAT (CHAT)","text":"<p>Count: 46 concepts (23.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Chatbot</li> </ol> </li> <li> <ol> <li>Conversational Agent</li> </ol> </li> <li> <ol> <li>Dialog System</li> </ol> </li> <li> <ol> <li>Intent Recognition</li> </ol> </li> <li> <ol> <li>Intent Modeling</li> </ol> </li> <li> <ol> <li>Intent Classification</li> </ol> </li> <li> <ol> <li>Entity Extraction</li> </ol> </li> <li> <ol> <li>Named Entity Recognition</li> </ol> </li> <li> <ol> <li>Entity Type</li> </ol> </li> <li> <ol> <li>Entity Linking</li> </ol> </li> <li> <ol> <li>FAQ</li> </ol> </li> <li> <ol> <li>FAQ Analysis</li> </ol> </li> <li> <ol> <li>Question-Answer Pair</li> </ol> </li> <li> <ol> <li>User Query</li> </ol> </li> <li> <ol> <li>User Intent</li> </ol> </li> <li>...and 31 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#search-search","title":"SEARCH (SEARCH)","text":"<p>Count: 28 concepts (14.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Keyword Search</li> </ol> </li> <li> <ol> <li>Search Index</li> </ol> </li> <li> <ol> <li>Inverted Index</li> </ol> </li> <li> <ol> <li>Reverse Index</li> </ol> </li> <li> <ol> <li>Full-Text Search</li> </ol> </li> <li> <ol> <li>Boolean Search</li> </ol> </li> <li> <ol> <li>Search Query</li> </ol> </li> <li> <ol> <li>Query Parser</li> </ol> </li> <li> <ol> <li>Synonym Expansion</li> </ol> </li> <li> <ol> <li>Thesaurus</li> </ol> </li> <li> <ol> <li>Ontology</li> </ol> </li> <li> <ol> <li>Taxonomy</li> </ol> </li> <li> <ol> <li>Controlled Vocabulary</li> </ol> </li> <li> <ol> <li>Metadata</li> </ol> </li> <li> <ol> <li>Metadata Tagging</li> </ol> </li> <li>...and 13 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#rag-rag","title":"RAG (RAG)","text":"<p>Count: 18 concepts (9.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>External Knowledge</li> </ol> </li> <li> <ol> <li>Public Knowledge Base</li> </ol> </li> <li> <ol> <li>Internal Knowledge</li> </ol> </li> <li> <ol> <li>Private Documents</li> </ol> </li> <li> <ol> <li>Document Corpus</li> </ol> </li> <li> <ol> <li>RAG Pattern</li> </ol> </li> <li> <ol> <li>Retrieval Augmented Generation</li> </ol> </li> <li> <ol> <li>Retrieval Step</li> </ol> </li> <li> <ol> <li>Augmentation Step</li> </ol> </li> <li> <ol> <li>Generation Step</li> </ol> </li> <li> <ol> <li>Context Window</li> </ol> </li> <li> <ol> <li>Prompt Engineering</li> </ol> </li> <li> <ol> <li>System Prompt</li> </ol> </li> <li> <ol> <li>User Prompt</li> </ol> </li> <li> <ol> <li>RAG Limitations</li> </ol> </li> <li>...and 3 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#embed-embed","title":"EMBED (EMBED)","text":"<p>Count: 17 concepts (8.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Word Embedding</li> </ol> </li> <li> <ol> <li>Embedding Vector</li> </ol> </li> <li> <ol> <li>Vector Space Model</li> </ol> </li> <li> <ol> <li>Vector Dimension</li> </ol> </li> <li> <ol> <li>Embedding Model</li> </ol> </li> <li> <ol> <li>Word2Vec</li> </ol> </li> <li> <ol> <li>GloVe</li> </ol> </li> <li> <ol> <li>FastText</li> </ol> </li> <li> <ol> <li>Sentence Embedding</li> </ol> </li> <li> <ol> <li>Contextual Embedding</li> </ol> </li> <li> <ol> <li>Vector Database</li> </ol> </li> <li> <ol> <li>Vector Store</li> </ol> </li> <li> <ol> <li>Vector Index</li> </ol> </li> <li> <ol> <li>Approximate Nearest Neighbor</li> </ol> </li> <li> <ol> <li>FAISS</li> </ol> </li> <li>...and 2 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#sec-sec","title":"SEC (SEC)","text":"<p>Count: 16 concepts (8.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Security</li> </ol> </li> <li> <ol> <li>Authentication</li> </ol> </li> <li> <ol> <li>Authorization</li> </ol> </li> <li> <ol> <li>User Permission</li> </ol> </li> <li> <ol> <li>Role-Based Access Control</li> </ol> </li> <li> <ol> <li>RBAC</li> </ol> </li> <li> <ol> <li>Access Policy</li> </ol> </li> <li> <ol> <li>Data Privacy</li> </ol> </li> <li> <ol> <li>PII</li> </ol> </li> <li> <ol> <li>Personally Identifiable Info</li> </ol> </li> <li> <ol> <li>GDPR</li> </ol> </li> <li> <ol> <li>Data Retention</li> </ol> </li> <li> <ol> <li>Log Storage</li> </ol> </li> <li> <ol> <li>Chat Log</li> </ol> </li> <li> <ol> <li>Logging System</li> </ol> </li> <li>...and 1 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#graph-graph","title":"GRAPH (GRAPH)","text":"<p>Count: 15 concepts (7.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>GraphRAG Pattern</li> </ol> </li> <li> <ol> <li>Knowledge Graph</li> </ol> </li> <li> <ol> <li>Graph Database</li> </ol> </li> <li> <ol> <li>Node</li> </ol> </li> <li> <ol> <li>Edge</li> </ol> </li> <li> <ol> <li>Triple</li> </ol> </li> <li> <ol> <li>Subject-Predicate-Object</li> </ol> </li> <li> <ol> <li>RDF</li> </ol> </li> <li> <ol> <li>Graph Query</li> </ol> </li> <li> <ol> <li>OpenCypher</li> </ol> </li> <li> <ol> <li>Cypher Query Language</li> </ol> </li> <li> <ol> <li>Neo4j</li> </ol> </li> <li> <ol> <li>Corporate Nervous System</li> </ol> </li> <li> <ol> <li>Organizational Knowledge</li> </ol> </li> <li> <ol> <li>Knowledge Management</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#eval-eval","title":"EVAL (EVAL)","text":"<p>Count: 15 concepts (7.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Query Frequency</li> </ol> </li> <li> <ol> <li>Frequency Analysis</li> </ol> </li> <li> <ol> <li>Pareto Analysis</li> </ol> </li> <li> <ol> <li>80/20 Rule</li> </ol> </li> <li> <ol> <li>Chatbot Metrics</li> </ol> </li> <li> <ol> <li>KPI</li> </ol> </li> <li> <ol> <li>Key Performance Indicator</li> </ol> </li> <li> <ol> <li>Chatbot Dashboard</li> </ol> </li> <li> <ol> <li>Acceptance Rate</li> </ol> </li> <li> <ol> <li>User Satisfaction</li> </ol> </li> <li> <ol> <li>Response Accuracy</li> </ol> </li> <li> <ol> <li>Chatbot Evaluation</li> </ol> </li> <li> <ol> <li>A/B Testing</li> </ol> </li> <li> <ol> <li>Performance Tuning</li> </ol> </li> <li> <ol> <li>Optimization</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#query-query","title":"QUERY (QUERY)","text":"<p>Count: 11 concepts (5.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Database Query</li> </ol> </li> <li> <ol> <li>SQL Query</li> </ol> </li> <li> <ol> <li>Query Parameter</li> </ol> </li> <li> <ol> <li>Parameter Extraction</li> </ol> </li> <li> <ol> <li>Query Template</li> </ol> </li> <li> <ol> <li>Parameterized Query</li> </ol> </li> <li> <ol> <li>Query Execution</li> </ol> </li> <li> <ol> <li>Query Description</li> </ol> </li> <li> <ol> <li>Natural Language to SQL</li> </ol> </li> <li> <ol> <li>Question to Query Mapping</li> </ol> </li> <li> <ol> <li>Slot Filling</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#foundation-concepts-prerequisites-found","title":"Foundation Concepts - Prerequisites (FOUND)","text":"<p>Count: 9 concepts (4.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Artificial Intelligence</li> </ol> </li> <li> <ol> <li>AI Timeline</li> </ol> </li> <li> <ol> <li>AI Doubling Rate</li> </ol> </li> <li> <ol> <li>Moore's Law</li> </ol> </li> <li> <ol> <li>Natural Language Processing</li> </ol> </li> <li> <ol> <li>Text Processing</li> </ol> </li> <li> <ol> <li>String Matching</li> </ol> </li> <li> <ol> <li>Regular Expressions</li> </ol> </li> <li> <ol> <li>Grep Command</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#nlp-nlp","title":"NLP (NLP)","text":"<p>Count: 8 concepts (4.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>NLP Pipeline</li> </ol> </li> <li> <ol> <li>Text Preprocessing</li> </ol> </li> <li> <ol> <li>Text Normalization</li> </ol> </li> <li> <ol> <li>Stemming</li> </ol> </li> <li> <ol> <li>Lemmatization</li> </ol> </li> <li> <ol> <li>Part-of-Speech Tagging</li> </ol> </li> <li> <ol> <li>Dependency Parsing</li> </ol> </li> <li> <ol> <li>Coreference Resolution</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#metric-metric","title":"METRIC (METRIC)","text":"<p>Count: 7 concepts (3.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Search Precision</li> </ol> </li> <li> <ol> <li>Search Recall</li> </ol> </li> <li> <ol> <li>F-Measure</li> </ol> </li> <li> <ol> <li>F1 Score</li> </ol> </li> <li> <ol> <li>Confusion Matrix</li> </ol> </li> <li> <ol> <li>True Positive</li> </ol> </li> <li> <ol> <li>False Positive</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#llm-llm","title":"LLM (LLM)","text":"<p>Count: 7 concepts (3.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Large Language Model</li> </ol> </li> <li> <ol> <li>Transformer Architecture</li> </ol> </li> <li> <ol> <li>Attention Mechanism</li> </ol> </li> <li> <ol> <li>Token</li> </ol> </li> <li> <ol> <li>Tokenization</li> </ol> </li> <li> <ol> <li>Subword Tokenization</li> </ol> </li> <li> <ol> <li>Byte Pair Encoding</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#tool-tool","title":"TOOL (TOOL)","text":"<p>Count: 3 concepts (1.5%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Team Project</li> </ol> </li> <li> <ol> <li>Capstone Project</li> </ol> </li> <li> <ol> <li>Chatbot Career</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#recommendations","title":"Recommendations","text":"<ul> <li>\u2705 Good balance: Categories are reasonably distributed (spread: 21.5%)</li> <li>\u2705 MISC category minimal: Good categorization specificity</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#educational-use-recommendations","title":"Educational Use Recommendations","text":"<ul> <li>Use taxonomy categories for color-coding in graph visualizations</li> <li>Design curriculum modules based on taxonomy groupings</li> <li>Create filtered views for focused learning paths</li> <li>Use categories for assessment organization</li> <li>Enable navigation by topic area in interactive tools</li> </ul> <p>Report generated by learning-graph-reports/taxonomy_distribution.py</p>"},{"location":"prompts/01-run-the-course-description-analyzer-skill/","title":"Course Description Analyzer Skill","text":"<p>Prompt</p> <p>run the couse-description-analyzer skill </p>"},{"location":"prompts/02-graph-viewer-legend/","title":"Graph Viewer Legend Update","text":"<p>Change the CSS rules in @docs/sims/graph-viewer/local.css so that the legend table  first column has a 100px minimum and the second column has a 50px maximum </p> <p>Updated docs/sims/graph-viewer/local.css with 8 additions        106      font-size: 16px;        107    }        108          109 +  .legend-table td:first-child {        110 +    min-width: 100px;        111 +  }        112 +        113 +  .legend-table td:nth-child(2) {        114 +    max-width: 50px;        115 +  }        116 +        117    .legend-table input[type=\"checkbox\"] {        118      margin-right: 5px;        119    }</p>"},{"location":"prompts/03-rewrite-course-description/","title":"03 rewrite course description","text":"<p>please rewrite the @docs/course-description.md to sound professional but fun.  Make it  compeling so that students really want to sign up for the course</p>"},{"location":"prompts/04-social-media-preview/","title":"Social Media Preview Image","text":"<p>Prompt</p> <p>Please generate a wide-landscape cover image for the social media preview.  The image has \"Conversational AI\" in white text in the center with enough padding to not merge with the background.  The background is a collage of imagery from the course description.  Use a high-energy positive impact theme with AI as center to the imagery.  The image MUST have an aspect ratio of width to height of 1.91:1 to conform with the social graph standards.</p>"},{"location":"sims/","title":"List of MicroSims","text":"<p>Learning Graph Viewer</p>"},{"location":"sims/graph-viewer/","title":"Learning Graph Viewer","text":"<p>Run the Learning Graph Viewer</p> <p>This viewer reads a learning graph data from ../../learning-graph/learning-graph.json:</p> <ol> <li>Search Functionality - Quick node lookup with autocomplete</li> <li>Taxonomy Legend Controls - Filter nodes by category/taxonomy</li> </ol>"},{"location":"sims/graph-viewer/#features","title":"Features","text":""},{"location":"sims/graph-viewer/#search","title":"Search","text":"<ul> <li>Type-ahead search for node names</li> <li>Displays matching results in a dropdown</li> <li>Shows node group/category in results</li> <li>Clicking a result focuses and highlights the node on the graph</li> <li>Only searches visible nodes (respects taxonomy filters)</li> </ul>"},{"location":"sims/graph-viewer/#taxonomy-legend-with-checkboxes","title":"Taxonomy Legend with Checkboxes","text":"<ul> <li>Sidebar legend with all node categories</li> <li>Toggle visibility of entire node groups</li> <li>Color-coded categories matching the graph</li> <li>\"Check All\" and \"Uncheck All\" buttons for bulk operations</li> <li>Collapsible sidebar to maximize graph viewing area</li> </ul>"},{"location":"sims/graph-viewer/#graph-statistics","title":"Graph Statistics","text":"<p>Real-time statistics that update as you filter: - Nodes: Count of visible nodes - Edges: Count of visible edges (both endpoints must be visible) - Orphans: Nodes with no connections (this is an indication that the learning graph needs editing)</p>"},{"location":"sims/graph-viewer/#sample-graph-demo","title":"Sample Graph Demo","text":"<p>The demo includes a Graph Theory learning graph with 10 taxonomy categories:</p> <ul> <li>Foundation (Red) - Core concepts in red boxes that should be pinned to the left</li> <li>Types (Orange) - Graph types</li> <li>Representations (Gold) - Data structures</li> <li>Algorithms (Green) - Basic algorithms</li> <li>Paths (Blue) - Shortest path algorithms</li> <li>Flow (Indigo) - Network flow algorithms</li> <li>Advanced (Violet) - Advanced topics</li> <li>Metrics (Gray) - Centrality measures</li> <li>Spectral (Brown) - Spectral theory</li> <li>ML &amp; Networks (Teal) - Machine learning</li> </ul>"},{"location":"sims/graph-viewer/#usage-tips","title":"Usage Tips","text":"<ol> <li>Hide a category - Uncheck a category in the sidebar to hide all nodes in that group</li> <li>Search within visible nodes - Use search to quickly find specific concepts among visible nodes</li> <li>Focus on a topic - Uncheck all categories, then check only the ones you want to study</li> <li>Collapse sidebar - Click the menu button (\u2630) to hide the sidebar and expand the graph view</li> <li>Find orphans - Check the statistics to see if any nodes lack connections</li> </ol>"},{"location":"sims/graph-viewer/#implementation-notes","title":"Implementation Notes","text":"<p>This viewer follows the standard vis.js architectural patterns:</p> <ul> <li>Uses <code>vis.DataSet</code> for nodes and edges</li> <li>Implements node <code>hidden</code> property for filtering</li> <li>Combines separate search and legend features</li> <li>Updates statistics dynamically based on visibility</li> <li>Maintains consistent styling across features</li> </ul>"},{"location":"sims/graph-viewer/#use-cases","title":"Use Cases","text":"<ul> <li>Course planning - Filter by topic area to design lesson sequences</li> <li>Concept exploration - Search for specific concepts and see their dependencies</li> <li>Gap analysis - Use orphan count to identify disconnected concepts</li> <li>Progressive learning - Start with foundation concepts, gradually enable advanced topics</li> </ul>"}]}