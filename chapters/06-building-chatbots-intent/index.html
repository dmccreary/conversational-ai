
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A college level course on creating chatbots using AI.">
      
      
        <meta name="author" content="Dan McCreary">
      
      
        <link rel="canonical" href="https://dmccreary.github.io/conversational-ai/chapters/06-building-chatbots-intent/">
      
      
        <link rel="prev" href="../05-embeddings-vector-databases/quiz/">
      
      
        <link rel="next" href="quiz/">
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Content - Conversational AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Content - Conversational AI" >
      
        <meta  property="og:description"  content="A college level course on creating chatbots using AI." >
      
        <meta  property="og:image"  content="https://dmccreary.github.io/conversational-ai/assets/images/social/chapters/06-building-chatbots-intent/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://dmccreary.github.io/conversational-ai/chapters/06-building-chatbots-intent/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Content - Conversational AI" >
      
        <meta  name="twitter:description"  content="A college level course on creating chatbots using AI." >
      
        <meta  name="twitter:image"  content="https://dmccreary.github.io/conversational-ai/assets/images/social/chapters/06-building-chatbots-intent/index.png" >
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="gold" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#building-chatbots-and-intent-recognition" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Conversational AI" class="md-header__button md-logo" aria-label="Conversational AI" data-md-component="logo">
      
  <img src="../../img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Conversational AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Content
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/dmccreary/conversational-ai" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Conversational AI" class="md-nav__button md-logo" aria-label="Conversational AI" data-md-component="logo">
      
  <img src="../../img/logo.png" alt="logo">

    </a>
    Conversational AI
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dmccreary/conversational-ai" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Course Description
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Chapters
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Chapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../01-foundations-ai-nlp/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 1 - Foundations of AI and NLP
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../02-search-technologies-indexing/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 2 - Search Technologies and Indexing
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../03-semantic-search-quality-metrics/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 3 - Semantic Search and Quality Metrics
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../04-large-language-models-tokenization/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 4 - Large Language Models and Tokenization
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../05-embeddings-vector-databases/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 5 - Embeddings and Vector Databases
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  
  <span class="md-ellipsis">
    Chapter 6 - Building Chatbots and Intent Recognition
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            Chapter 6 - Building Chatbots and Intent Recognition
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="quiz/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quiz
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../07-chatbot-frameworks-ui/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 7 - Chatbot Frameworks and User Interfaces
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../08-user-feedback-improvement/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 8 - User Feedback and Continuous Improvement
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../09-rag-pattern/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 9 - The RAG Pattern
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../10-knowledge-graphs-graphrag/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 10 - Knowledge Graphs and GraphRAG
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../11-nlp-pipelines-processing/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 11 - NLP Pipelines and Text Processing
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../12-database-queries-parameters/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 12 - Database Queries and Parameter Extraction
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../13-security-privacy-users/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 13 - Security Privacy and User Management
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../14-evaluation-optimization-careers/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 14 - Evaluation Optimization and Career Development
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../sims/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    MicroSims
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Learning Graph
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../prompts/01-bloom-taxonomy-enrichment/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Sample Prompts
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQs
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how-we-built-this-site/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How We Built This Site
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    References
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../feedback/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feedback
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contact/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contact
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-conversational-interfaces" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Conversational Interfaces
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-user-queries" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding User Queries
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding User Queries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-user-query-components" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: User Query Components
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frequently-asked-questions-and-question-answer-pairs" class="md-nav__link">
    <span class="md-ellipsis">
      Frequently Asked Questions and Question-Answer Pairs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Frequently Asked Questions and Question-Answer Pairs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-faq-system-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: FAQ System Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chatbots-and-conversational-agents" class="md-nav__link">
    <span class="md-ellipsis">
      Chatbots and Conversational Agents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dialog-systems-and-conversation-management" class="md-nav__link">
    <span class="md-ellipsis">
      Dialog Systems and Conversation Management
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dialog Systems and Conversation Management">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-dialog-system-state-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Dialog System State Machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-user-intent" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding User Intent
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding User Intent">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-intent-classification-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Intent Classification Pipeline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entity-extraction-and-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Entity Extraction and Recognition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Entity Extraction and Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-entity-extraction-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Entity Extraction Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-named-entity-recognition-with-bio-tagging" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Named Entity Recognition with BIO Tagging
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-your-first-intent-based-chatbot" class="md-nav__link">
    <span class="md-ellipsis">
      Building Your First Intent-Based Chatbot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-topics-context-and-multi-turn-dialogue" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Topics: Context and Multi-Turn Dialogue
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#faq-analysis-for-continuous-improvement" class="md-nav__link">
    <span class="md-ellipsis">
      FAQ Analysis for Continuous Improvement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Summary and Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/dmccreary/conversational-ai/blob/master/docs/chapters/06-building-chatbots-intent/index.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="building-chatbots-and-intent-recognition">Building Chatbots and Intent Recognition</h1>
<h2 id="summary">Summary</h2>
<p>This chapter introduces the core concepts and techniques for building conversational agents, focusing on understanding user intentions and extracting relevant information from queries. You will learn about chatbot architectures, dialog systems, intent recognition and classification, entity extraction techniques, and how to build FAQ-based systems. These foundational chatbot concepts prepare you to create intelligent conversational interfaces.</p>
<h2 id="concepts-covered">Concepts Covered</h2>
<p>This chapter covers the following 15 concepts from the learning graph:</p>
<ol>
<li>Chatbot</li>
<li>Conversational Agent</li>
<li>Dialog System</li>
<li>Intent Recognition</li>
<li>Intent Modeling</li>
<li>Intent Classification</li>
<li>Entity Extraction</li>
<li>Named Entity Recognition</li>
<li>Entity Type</li>
<li>Entity Linking</li>
<li>FAQ</li>
<li>FAQ Analysis</li>
<li>Question-Answer Pair</li>
<li>User Query</li>
<li>User Intent</li>
</ol>
<h2 id="prerequisites">Prerequisites</h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../01-foundations-ai-nlp/">Chapter 1: Foundations of Artificial Intelligence and Natural Language Processing</a></li>
<li><a href="../04-large-language-models-tokenization/">Chapter 4: Large Language Models and Tokenization</a></li>
</ul>
<hr />
<h2 id="introduction-to-conversational-interfaces">Introduction to Conversational Interfaces</h2>
<p>Every time you ask Siri about the weather, message a customer service bot about your order status, or use ChatGPT to answer a question, you're interacting with a conversational interface. These systems, broadly known as chatbots or conversational agents, have evolved from simple keyword-matching programs to sophisticated AI systems capable of understanding context, extracting information, and maintaining coherent multi-turn dialogues. This chapter explores the foundational concepts behind building these systems, focusing on how they understand what users want and extract the critical information needed to respond appropriately.</p>
<p>At the heart of every effective conversational agent lies the ability to answer two fundamental questions: "What does the user want?" and "What information do I need to fulfill that request?" The first question addresses intent recognition—understanding the user's goal. The second focuses on entity extraction—identifying specific data points like dates, names, locations, or product identifiers. Together, these capabilities transform raw text into structured, actionable information that systems can process and respond to intelligently.</p>
<h2 id="understanding-user-queries">Understanding User Queries</h2>
<p>A <strong>user query</strong> represents any input provided by a user to a conversational system, whether typed into a chat interface, spoken to a voice assistant, or selected from quick-reply options. Unlike structured database queries written in SQL or other formal languages, user queries arrive in natural language—messy, ambiguous, and highly variable. The same intent can be expressed in dozens of ways:</p>
<ul>
<li>"What's the weather like today?"</li>
<li>"Is it going to rain?"</li>
<li>"Do I need an umbrella?"</li>
<li>"Will it be sunny this afternoon?"</li>
</ul>
<p>Each query asks fundamentally the same thing (weather information), but uses different vocabulary, structure, and level of specificity. This variability presents both the central challenge and the fundamental requirement for conversational systems: they must map diverse natural language expressions onto a consistent set of system capabilities.</p>
<p>User queries typically contain two types of information. First, they express an <strong>intent</strong>—the underlying goal or action the user wants to accomplish, such as checking weather, booking a flight, or finding product information. Second, they often include specific details called <strong>entities</strong>—concrete values like "today," "New York," or "size 10" that parameterize the request. Effective chatbots must identify both components to respond appropriately.</p>
<h4 id="diagram-user-query-components">Diagram: User Query Components</h4>
<details>
<summary>Anatomy of a User Query</summary>
<p>Type: diagram</p>
<p>Purpose: Illustrate how a natural language user query contains both intent and entity information that must be extracted</p>
<p>Components to show:
- User query at top: "Book a flight to San Francisco next Tuesday"
- Arrow pointing down to two branches:
  - Left branch: "Intent: Book Flight" (highlighted in blue)
  - Right branch: "Entities" containing:
    - Destination: San Francisco (orange)
    - Date: next Tuesday (green)
- Below intent: "System Action" box showing "Search available flights"
- Below entities: "Parameters" box showing structured data</p>
<p>Connections:
- Arrows from intent and entities converging at bottom to "Actionable Request" box
- Dotted lines showing how entities fill parameter slots in the system action</p>
<p>Style: Flowchart with boxes and arrows, hierarchical layout</p>
<p>Labels:
- "Natural Language Input" above user query
- "Semantic Understanding" in middle layer
- "Structured Output" at bottom</p>
<p>Color scheme: Blue for intent, orange/green for different entity types, gray for system components</p>
<p>Implementation: SVG diagram with clear visual hierarchy</p>
</details>
<h2 id="frequently-asked-questions-and-question-answer-pairs">Frequently Asked Questions and Question-Answer Pairs</h2>
<p>Many conversational systems begin their lifecycle as <strong>FAQ</strong> (Frequently Asked Questions) systems. An FAQ system maintains a curated collection of <strong>question-answer pairs</strong>—explicit mappings from common user questions to predetermined responses. This approach offers several advantages for organizations just starting with conversational AI: it requires no machine learning expertise, leverages existing documentation, and provides predictable, controllable responses.</p>
<p>A question-answer pair consists of two components: a representative question that captures a common user need, and a corresponding answer that addresses that need. For example:</p>
<table>
<thead>
<tr>
<th>Question</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>How do I reset my password?</td>
<td>Click "Forgot Password" on the login page. Enter your email address, and we'll send you a reset link within 5 minutes.</td>
</tr>
<tr>
<td>What are your business hours?</td>
<td>We're open Monday through Friday, 9 AM to 6 PM EST. Weekend support is available via email only.</td>
</tr>
<tr>
<td>Do you offer student discounts?</td>
<td>Yes! Students receive 20% off with a valid .edu email address. Click here to verify your student status.</td>
</tr>
</tbody>
</table>
<p>The fundamental challenge in FAQ systems lies in matching user queries to the appropriate question-answer pair. Users rarely phrase questions exactly as they appear in the FAQ database. Someone might ask "I can't log in, help!" when the relevant FAQ question is "How do I reset my password?" Effective FAQ systems must handle this variability through synonym expansion, semantic similarity matching, or machine learning-based retrieval techniques covered in earlier chapters.</p>
<p><strong>FAQ analysis</strong> involves examining collections of user questions to identify patterns, coverage gaps, and optimization opportunities. By analyzing which questions users ask most frequently, organizations can prioritize high-impact improvements. FAQ analysis also reveals when questions cluster around similar intents but use different phrasings—a signal that intent classification might provide better coverage than simple keyword matching.</p>
<h4 id="diagram-faq-system-architecture">Diagram: FAQ System Architecture</h4>
<details>
<summary>FAQ-Based Chatbot Architecture</summary>
<p>Type: diagram</p>
<p>Purpose: Show how FAQ systems process user queries through matching, retrieval, and response generation</p>
<p>Components to show:
- User interface (top left): Chat window with user query "how do I reset password"
- Query processing layer (middle left):
  - Text normalization box
  - Synonym expansion box
  - Embedding generation box
- FAQ database (center): Collection of Q&amp;A pairs represented as stacked cards
- Matching engine (middle right):
  - Similarity calculation
  - Ranking algorithm
  - Confidence threshold
- Response selection (bottom right): Top-ranked answer
- Feedback loop (bottom): Thumbs up/down returning to database</p>
<p>Connections:
- User query flows through processing pipeline
- Processed query connects to matching engine
- Matching engine queries FAQ database
- Results ranked and filtered by confidence
- Selected response returned to user interface
- User feedback flows back to database for improvement</p>
<p>Style: Data flow diagram with layered architecture</p>
<p>Labels:
- "Input Processing" for normalization layer
- "Semantic Matching" for matching engine
- "Response Delivery" for output
- Confidence scores shown on connection from matching to response (e.g., "0.87")</p>
<p>Color scheme: Purple for user interface, blue for processing, orange for database, green for matching, teal for response</p>
<p>Implementation: Block diagram with directional arrows showing data flow</p>
</details>
<h2 id="chatbots-and-conversational-agents">Chatbots and Conversational Agents</h2>
<p>The terms <strong>chatbot</strong> and <strong>conversational agent</strong> are often used interchangeably, though subtle distinctions exist. A chatbot typically refers to any software system that engages in text-based conversation with users, regardless of sophistication level. This broad category includes simple rule-based systems that respond to specific keywords, FAQ retrievers, and advanced AI-powered assistants.</p>
<p>A <strong>conversational agent</strong> implies a higher level of sophistication—a system capable of multi-turn dialogue, context maintenance, and intelligent decision-making. Conversational agents understand conversation flow, remember previous exchanges, and can handle complex, multi-step interactions. While all conversational agents are chatbots, not all chatbots qualify as true conversational agents. A simple FAQ bot that matches keywords to canned responses is a chatbot; an AI assistant that helps you plan a multi-city trip over several conversational turns is a conversational agent.</p>
<p>Modern chatbots exist on a spectrum of capabilities:</p>
<ul>
<li><strong>Rule-based chatbots</strong>: Use pattern matching and decision trees to respond to predefined inputs. Fast and predictable, but brittle when users deviate from expected patterns.</li>
<li><strong>Retrieval-based chatbots</strong>: Select responses from a predefined set based on similarity to the user query. More flexible than rule-based systems, but limited to responses in their database.</li>
<li><strong>Generative chatbots</strong>: Use language models to generate novel responses dynamically. Highly flexible and capable of handling unexpected inputs, but require careful prompt engineering and safety measures.</li>
<li><strong>Task-oriented agents</strong>: Focus on completing specific tasks like booking reservations or answering product questions, often combining retrieval and generation strategies.</li>
<li><strong>Open-domain agents</strong>: Engage in general conversation on any topic, prioritizing engagement and coherence over task completion.</li>
</ul>
<p>The choice of architecture depends on your use case, available data, and tolerance for unpredictable responses. Customer service chatbots often favor retrieval-based or task-oriented approaches to ensure accurate, compliant responses. Entertainment or companion bots may embrace generative models for more engaging, varied interactions.</p>
<p>The following table compares key characteristics across chatbot types:</p>
<table>
<thead>
<tr>
<th>Characteristic</th>
<th>Rule-Based</th>
<th>Retrieval-Based</th>
<th>Generative</th>
<th>Hybrid</th>
</tr>
</thead>
<tbody>
<tr>
<td>Development complexity</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
<td>High</td>
</tr>
<tr>
<td>Response predictability</td>
<td>Complete</td>
<td>High</td>
<td>Variable</td>
<td>Medium-High</td>
</tr>
<tr>
<td>Handling unexpected input</td>
<td>Poor</td>
<td>Moderate</td>
<td>Excellent</td>
<td>Good</td>
</tr>
<tr>
<td>Training data required</td>
<td>None</td>
<td>Moderate</td>
<td>Large</td>
<td>Moderate-Large</td>
</tr>
<tr>
<td>Response variety</td>
<td>Very low</td>
<td>Medium</td>
<td>Very high</td>
<td>High</td>
</tr>
<tr>
<td>Typical accuracy</td>
<td>High (in scope)</td>
<td>Medium-High</td>
<td>Variable</td>
<td>High</td>
</tr>
<tr>
<td>Best for</td>
<td>Simple FAQs</td>
<td>Customer support</td>
<td>Open conversation</td>
<td>Enterprise apps</td>
</tr>
</tbody>
</table>
<h2 id="dialog-systems-and-conversation-management">Dialog Systems and Conversation Management</h2>
<p>While simple chatbots handle isolated queries independently, <strong>dialog systems</strong> manage extended conversations with multiple turns, context tracking, and state management. A dialog system maintains awareness of conversation history, understands references to previously mentioned entities, and guides users through multi-step processes toward goal completion.</p>
<p>Consider a conversation with a flight booking system. The dialog unfolds over multiple turns, each building on previous exchanges:</p>
<p><strong>User</strong>: "I need to book a flight to Chicago"
<strong>System</strong>: "I can help with that. What date would you like to depart?"
<strong>User</strong>: "Next Monday"
<strong>System</strong>: "Departing Monday, January 22nd. Where will you be flying from?"
<strong>User</strong>: "Boston"
<strong>System</strong>: "Perfect. What time of day do you prefer?"
<strong>User</strong>: "Morning"</p>
<p>Notice how the system doesn't ask for all information at once, but instead guides the user through a structured information-gathering process. It remembers the destination (Chicago) mentioned in the first turn and doesn't ask for it again. When the user says "next Monday," the system resolves the relative date reference to an absolute date. This contextual awareness and conversation management distinguishes dialog systems from simpler single-turn chatbots.</p>
<p>Dialog systems typically implement one of several conversation management strategies:</p>
<ul>
<li><strong>Finite state machines</strong>: Model conversations as a graph of states (e.g., "greeting," "gathering departure info," "confirming booking") with transitions triggered by user inputs. Simple to implement and reason about, but can feel rigid.</li>
<li><strong>Frame-based systems</strong>: Define templates (frames) for each task with slots to fill (destination, date, time). The system asks questions to fill empty slots and confirms when complete. Works well for structured tasks with clear information requirements.</li>
<li><strong>Plan-based systems</strong>: Model conversation as a planning problem where the system pursues goals while accounting for user intentions and beliefs. More sophisticated but computationally complex.</li>
<li><strong>End-to-end neural systems</strong>: Use deep learning models to map conversation history directly to system responses. Flexible and capable of learning from data, but less interpretable and harder to control.</li>
</ul>
<p>Modern production systems often combine approaches, using structured frameworks for critical transactional flows while employing neural models for handling unexpected inputs or conversational elements outside the main task flow.</p>
<h4 id="diagram-dialog-system-state-machine">Diagram: Dialog System State Machine</h4>
<details>
<summary>Finite State Machine for Flight Booking Dialog</summary>
<p>Type: workflow</p>
<p>Purpose: Illustrate how dialog systems manage conversation flow through states and transitions for a flight booking task</p>
<p>Visual style: State diagram with circular nodes for states, arrows for transitions, and labeled conditions</p>
<p>States:
1. Start: "Greeting"
   Hover text: "System welcomes user and offers to help with flight booking"</p>
<ol>
<li>
<p>State: "Collect Destination"
   Hover text: "System asks 'Where would you like to fly?' if destination not provided"</p>
</li>
<li>
<p>State: "Collect Origin"
   Hover text: "System asks 'Where will you depart from?' if origin not provided"</p>
</li>
<li>
<p>State: "Collect Date"
   Hover text: "System asks 'What date?' and resolves relative references like 'next Monday'"</p>
</li>
<li>
<p>State: "Collect Time Preference"
   Hover text: "System asks 'What time of day: morning, afternoon, or evening?'"</p>
</li>
<li>
<p>Decision: "All Slots Filled?"
   Hover text: "Check if destination, origin, date, and time are all collected"</p>
</li>
<li>
<p>State: "Display Options"
   Hover text: "System queries flight database and shows available flights matching criteria"</p>
</li>
<li>
<p>State: "Confirm Selection"
   Hover text: "User selects flight; system confirms details before booking"</p>
</li>
<li>
<p>End: "Booking Complete"
   Hover text: "System provides confirmation number and sends email receipt"</p>
</li>
</ol>
<p>Transitions:
- Greeting → Collect Destination (user expresses flight intent)
- Collect Destination → Collect Origin (destination provided)
- Collect Destination → Collect Destination (if user provides unclear input)
- Collect Origin → Collect Date (origin provided)
- Collect Date → Collect Time Preference (date provided and validated)
- Collect Time Preference → All Slots Filled? (time preference provided)
- All Slots Filled? → Display Options (YES: all required info collected)
- All Slots Filled? → [return to missing slot] (NO: redirect to first empty slot)
- Display Options → Confirm Selection (user picks a flight)
- Display Options → [modify slots] (user wants to change criteria)
- Confirm Selection → Booking Complete (user confirms)</p>
<p>Color coding:
- Green: Start state
- Blue: Information gathering states
- Yellow: Decision point
- Orange: Transaction states
- Purple: End state</p>
<p>Edge labels:
- Show user intents that trigger transitions (e.g., "provides destination", "changes mind", "confirms")</p>
<p>Swimlanes: Single flow representing system perspective</p>
<p>Implementation: Mermaid state diagram or interactive SVG with clickable states</p>
</details>
<h2 id="understanding-user-intent">Understanding User Intent</h2>
<p>While user queries vary greatly in phrasing, they typically express a limited set of underlying intentions. <strong>User intent</strong> represents the goal a user wants to accomplish—the action they expect the system to take or the information they seek. Understanding intent is fundamental to conversational AI because it allows systems to map diverse surface forms onto consistent behaviors.</p>
<p>In a banking chatbot, user queries like "What's my balance?", "How much money do I have?", "Check my account," and "Show my funds" all express the same intent: <code>check_balance</code>. Similarly, "I lost my card," "My credit card was stolen," and "I need to freeze my card" all map to <code>report_lost_card</code>. By identifying the intent category rather than processing each unique phrasing separately, systems can provide consistent responses and scale to handle variation.</p>
<p><strong>Intent recognition</strong> is the task of automatically identifying which intent category a user query belongs to. This classification problem typically uses machine learning models trained on labeled examples. Given a new user query, the model predicts the most likely intent from a predefined set of possibilities.</p>
<p><strong>Intent modeling</strong> refers to the process of designing your intent taxonomy—deciding what intents your system should recognize and how granular they should be. Good intent modeling balances specificity and coverage:</p>
<ul>
<li><strong>Too few intents</strong> (e.g., just "question" and "command"): System can't differentiate between different user needs and provide appropriate responses</li>
<li><strong>Too many intents</strong> (e.g., separate intents for "check savings balance" and "check checking balance"): System becomes brittle, requires more training data, and may fragment related queries</li>
</ul>
<p>Effective intent modeling follows several principles:</p>
<ul>
<li><strong>Mutual exclusivity</strong>: Each user query should map to exactly one intent; overlapping intents create classification ambiguity</li>
<li><strong>Actionable distinction</strong>: Different intents should trigger different system responses; if two intents lead to the same action, they should probably merge</li>
<li><strong>Balanced frequency</strong>: Avoid creating highly specific intents for rare queries while lumping common queries into catch-all categories</li>
<li><strong>User-centric naming</strong>: Define intents based on user goals, not system implementation details</li>
</ul>
<p>Here's an example intent taxonomy for a restaurant reservation chatbot:</p>
<ul>
<li><code>make_reservation</code>: User wants to book a table</li>
<li><code>modify_reservation</code>: User wants to change an existing booking</li>
<li><code>cancel_reservation</code>: User wants to cancel</li>
<li><code>check_availability</code>: User asks if tables are available (without committing to book)</li>
<li><code>ask_location</code>: User wants to know where the restaurant is located</li>
<li><code>ask_hours</code>: User asks about opening hours or specific date availability</li>
<li><code>ask_menu</code>: User wants to see the menu or asks about specific dishes</li>
<li><code>ask_dietary</code>: User has questions about allergies, vegetarian options, etc.</li>
<li><code>chitchat</code>: General conversation not related to specific booking tasks</li>
</ul>
<p><strong>Intent classification</strong> is the machine learning task that implements intent recognition. Modern intent classifiers typically use one of several approaches:</p>
<ol>
<li>
<p><strong>Traditional ML with engineered features</strong>: Extract features like n-grams, TF-IDF vectors, or part-of-speech patterns, then train classifiers like logistic regression, SVM, or random forests. Interpretable and works well with limited data, but requires feature engineering expertise.</p>
</li>
<li>
<p><strong>Deep learning with word embeddings</strong>: Encode queries using pre-trained word embeddings (Word2Vec, GloVe), then pass through neural networks (CNNs, LSTMs) for classification. Better handles semantic similarity without manual feature engineering.</p>
</li>
<li>
<p><strong>Transformer-based models</strong>: Fine-tune pre-trained language models (BERT, RoBERTa, DistilBERT) on labeled intent data. Currently achieves state-of-the-art performance, especially with limited training examples, due to transfer learning from large-scale pre-training.</p>
</li>
<li>
<p><strong>Large language model prompting</strong>: Use LLMs like GPT-4 with few-shot examples in the prompt to classify intents. No training required, highly flexible, but slower and more expensive per query than fine-tuned models.</p>
</li>
</ol>
<p>The choice depends on your available labeled data, latency requirements, and accuracy needs. Many production systems use a hybrid approach: fast, fine-tuned classifiers for common intents with LLM fallback for edge cases or confidence scores below a threshold.</p>
<h4 id="diagram-intent-classification-pipeline">Diagram: Intent Classification Pipeline</h4>
<details>
<summary>Intent Classification Architecture</summary>
<p>Type: diagram</p>
<p>Purpose: Show the complete pipeline from user query to predicted intent, including preprocessing, feature extraction, classification, and confidence scoring</p>
<p>Components to show:
- Input layer (top): User query text box: "I need to change my reservation for tomorrow"
- Preprocessing layer:
  - Text normalization box (lowercasing, punctuation removal)
  - Tokenization box
  - Stopword filtering (optional, shown with dotted border)
- Feature extraction layer:
  - Option A: TF-IDF vectorization (shown on left branch)
  - Option B: BERT encoding (shown on right branch, highlighted as preferred)
- Model layer (center):
  - Intent classifier neural network
  - Input dimension matching feature vectors
  - Output layer with softmax activation
- Output layer (bottom):
  - Intent probabilities table showing:
    - modify_reservation: 0.87 (highlighted in green)
    - cancel_reservation: 0.08
    - make_reservation: 0.03
    - ask_hours: 0.02
  - Confidence threshold line at 0.70
  - Final prediction: "modify_reservation" with confidence 0.87</p>
<p>Connections:
- User query → Preprocessing (solid arrow)
- Preprocessing → Feature extraction (splits into two paths)
- Both feature extraction paths → Model (merge)
- Model → Output probabilities
- Threshold check → Final prediction</p>
<p>Annotations:
- Badge on BERT encoding: "Recommended: Better generalization"
- Badge on output: "High confidence - proceed with action"
- Note near threshold: "Queries below 0.70 escalate to human"</p>
<p>Style: Flowchart with layered architecture, showing parallel paths for different approaches</p>
<p>Labels:
- "Text Processing" for preprocessing layer
- "Semantic Encoding" for feature extraction
- "Classification" for model layer
- "Prediction &amp; Confidence" for output</p>
<p>Color scheme:
- Blue for preprocessing
- Purple for feature extraction
- Orange for model
- Green for high-confidence predictions
- Yellow for medium confidence
- Red for below-threshold (not shown in this example)</p>
<p>Implementation: SVG diagram with clear information flow and decision points</p>
</details>
<h2 id="entity-extraction-and-recognition">Entity Extraction and Recognition</h2>
<p>While intent recognition identifies what users want, <strong>entity extraction</strong> identifies the specific details within their queries. Entities are the concrete values—dates, names, locations, product IDs, monetary amounts—that parameterize user requests. A query like "Book a table for 4 people tomorrow at 7 PM" expresses the intent <code>make_reservation</code>, but also contains critical entities:</p>
<ul>
<li>Party size: 4 people</li>
<li>Date: tomorrow</li>
<li>Time: 7 PM</li>
</ul>
<p>Without extracting these entities, the system knows the user wants a reservation but lacks the information needed to fulfill it. Entity extraction transforms unstructured text into structured data that systems can act upon.</p>
<p><strong>Entity types</strong> categorize the kinds of information your system needs to extract. Common entity types include:</p>
<ul>
<li><strong>Temporal</strong>: dates, times, durations (e.g., "tomorrow," "3:30 PM," "two weeks")</li>
<li><strong>Numeric</strong>: quantities, amounts, measurements (e.g., "4 people," "$50," "2 miles")</li>
<li><strong>Geographic</strong>: locations, addresses, regions (e.g., "Boston," "123 Main St," "New England")</li>
<li><strong>Personal</strong>: names, titles, contact information</li>
<li><strong>Categorical</strong>: options from predefined sets (e.g., "vegetarian," "window seat," "economy class")</li>
<li><strong>Custom</strong>: domain-specific entities like product IDs, account numbers, or reservation codes</li>
</ul>
<p><strong>Named Entity Recognition</strong> (NER) is the task of identifying and classifying named entities—specific named references to people, organizations, locations, and other proper nouns. Traditional NER focuses on a standard set of entity types (Person, Organization, Location, Date, etc.), while custom entity extraction extends this to domain-specific categories relevant to your application.</p>
<p>Modern entity extraction systems use several approaches:</p>
<ol>
<li>
<p><strong>Rule-based extraction</strong>: Use regular expressions and pattern matching to find entities with predictable formats (dates, phone numbers, email addresses). Fast and accurate for well-formatted inputs, but brittle with variation.</p>
</li>
<li>
<p><strong>Dictionary-based lookup</strong>: Maintain lists of known entities (city names, product names, etc.) and match query text against these dictionaries. Works well for closed-domain entities but requires maintenance and misses variations.</p>
</li>
<li>
<p><strong>Sequence labeling models</strong>: Treat entity extraction as a token-level classification problem where each word receives a label (B-PERSON, I-PERSON, O for outside entity, etc.). CRF (Conditional Random Fields) and BiLSTM-CRF models were standard; now transformer-based models like BERT for token classification achieve state-of-the-art results.</p>
</li>
<li>
<p><strong>LLM-based extraction</strong>: Prompt large language models to extract entities from text, either through few-shot examples or by fine-tuning on labeled data. Highly flexible and can adapt to new entity types without retraining specialized models.</p>
</li>
</ol>
<p>Many production systems combine approaches: use rules for simple, high-confidence entities like dates and phone numbers; employ trained models for complex entities; leverage LLMs for rare or newly introduced entity types.</p>
<p>The following table shows example entity extractions from user queries:</p>
<table>
<thead>
<tr>
<th>User Query</th>
<th>Intent</th>
<th>Entities Extracted</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Book a flight to NYC next Friday"</td>
<td>book_flight</td>
<td>destination: "NYC", date: "next Friday"</td>
</tr>
<tr>
<td>"Table for 2 at 8 PM tonight"</td>
<td>make_reservation</td>
<td>party_size: 2, time: "8 PM", date: "tonight"</td>
</tr>
<tr>
<td>"Cancel my order #12345"</td>
<td>cancel_order</td>
<td>order_id: "12345"</td>
</tr>
<tr>
<td>"What's the weather in Boston tomorrow?"</td>
<td>check_weather</td>
<td>location: "Boston", date: "tomorrow"</td>
</tr>
<tr>
<td>"Send $50 to John Smith"</td>
<td>transfer_money</td>
<td>amount: "$50", recipient: "John Smith"</td>
</tr>
</tbody>
</table>
<p><strong>Entity linking</strong> takes entity extraction one step further by connecting recognized entities to entries in a knowledge base or database. For example, when a user mentions "Apple," entity linking disambiguates whether they mean the fruit, the technology company, or Apple Records. The system links the recognized entity to a specific identifier in a knowledge graph, enabling richer semantic understanding and integration with structured data sources.</p>
<p>Entity linking typically involves:</p>
<ol>
<li><strong>Candidate generation</strong>: Identify possible knowledge base entries the mention could refer to (e.g., "Apple" might link to Apple Inc., Apple (fruit), or Apple Corps)</li>
<li><strong>Disambiguation</strong>: Use context to determine which candidate is most likely (e.g., a query about "iPhone and Apple" clearly refers to the company)</li>
<li><strong>Linking</strong>: Connect the entity mention to the canonical knowledge base identifier</li>
</ol>
<p>This process enables more sophisticated reasoning. A travel chatbot that links "Paris" to a knowledge graph can access related information like country, population, time zone, and major attractions without explicitly storing all connections in the chat system.</p>
<h4 id="diagram-entity-extraction-architecture">Diagram: Entity Extraction Architecture</h4>
<details>
<summary>Multi-Strategy Entity Extraction System</summary>
<p>Type: diagram</p>
<p>Purpose: Show how modern entity extraction systems combine rule-based, model-based, and LLM approaches for comprehensive coverage</p>
<p>Components to show:
- Input (top): User query: "Book 2 tickets to Boston on March 15th for John Smith"
- Parallel extraction strategies (three branches):</p>
<p>Branch 1 - Rules (left):
  - Regex patterns box
  - Date parser (extracts "March 15th")
  - Number extractor (extracts "2")
  - Email/phone patterns</p>
<p>Branch 2 - ML Model (center):
  - BERT-based NER model
  - Token classification layer
  - Outputs: Person ("John Smith"), Location ("Boston")
  - Confidence scores shown: 0.94, 0.89</p>
<p>Branch 3 - LLM (right):
  - GPT-4 few-shot prompt
  - Custom entity extraction
  - Fallback for ambiguous cases
  - Shown with dotted border (used when others have low confidence)</p>
<ul>
<li>Merging layer (middle):</li>
<li>Conflict resolution logic</li>
<li>Priority: Rules &gt; ML &gt; LLM for known patterns</li>
<li>
<p>Confidence aggregation</p>
</li>
<li>
<p>Entity linking layer (bottom middle):</p>
</li>
<li>Knowledge base lookup</li>
<li>"Boston" → Boston, MA (city ID: BST-MA-US)</li>
<li>
<p>"John Smith" → Account #7834 (from customer database)</p>
</li>
<li>
<p>Output (bottom): Structured entity dictionary:
  <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div><pre><span></span><code>{
  &quot;quantity&quot;: 2,
  &quot;destination&quot;: &quot;Boston, MA&quot;,
  &quot;destination_id&quot;: &quot;BST-MA-US&quot;,
  &quot;date&quot;: &quot;2024-03-15&quot;,
  &quot;passenger&quot;: &quot;John Smith&quot;,
  &quot;passenger_id&quot;: &quot;7834&quot;
}
</code></pre></div></td></tr></table></div></p>
</li>
</ul>
<p>Connections:
- Query flows into all three extraction branches simultaneously
- Extracted entities from each branch flow to merging layer
- Merged entities flow to entity linking
- Linked entities produce final structured output</p>
<p>Annotations:
- "Fast, high precision" label on Rules branch
- "Balanced accuracy &amp; coverage" on ML branch
- "Flexible fallback" on LLM branch
- "Canonicalization" label on linking layer</p>
<p>Style: Parallel pipeline architecture with merge point</p>
<p>Color scheme:
- Green for rules (deterministic)
- Blue for ML model
- Purple for LLM
- Orange for merging logic
- Teal for entity linking
- Gray for output structure</p>
<p>Implementation: Block diagram with parallel data flows converging to single output</p>
</details>
<h4 id="diagram-named-entity-recognition-with-bio-tagging">Diagram: Named Entity Recognition with BIO Tagging</h4>
<details>
<summary>NER Sequence Labeling Visualization</summary>
<p>Type: microsim</p>
<p>Learning objective: Demonstrate how NER models label each token in a sequence with BIO tags to identify entity boundaries and types</p>
<p>Canvas layout (900x500px):
- Top section (900x100): Input sentence display
- Middle section (900x300): Interactive token labeling visualization
- Bottom section (900x100): Control panel and legend</p>
<p>Visual elements:
- Input sentence: "John Smith works at Apple in San Francisco"
- Tokens displayed in boxes, each showing:
  - Token text (large)
  - BIO tag (small, below token)
  - Entity type (color-coded background)</p>
<p>Token breakdown:
- "John": B-PERSON (light blue background)
- "Smith": I-PERSON (light blue background)
- "works": O (white background)
- "at": O (white background)
- "Apple": B-ORG (light orange background)
- "in": O (white background)
- "San": B-LOC (light green background)
- "Francisco": I-LOC (light green background)</p>
<p>Interactive controls:
- Dropdown: Select example sentence (5 pre-loaded examples)
- Radio buttons: Show/hide BIO tags, Show/hide entity types
- Button: "Add Custom Sentence" (allows user to type their own)
- Checkbox: "Highlight entities only" (grays out O tokens)</p>
<p>Additional visualization:
- Arrows connecting I-tags to their B-tag start
- Brackets grouping multi-token entities
- Color legend showing entity types:
  - Light blue: PERSON
  - Light orange: ORG
  - Light green: LOC
  - Light yellow: DATE
  - Light purple: MISC
  - White: O (outside entity)</p>
<p>Example sentences in dropdown:
1. "John Smith works at Apple in San Francisco"
2. "The meeting is scheduled for January 15th in New York"
3. "Dr. Emily Johnson published research at MIT last year"
4. "Amazon launched new products in Europe and Asia"
5. "The conference will be held on March 3rd, 2024"</p>
<p>Default parameters:
- Selected sentence: Example 1
- Show BIO tags: true
- Show entity types: true
- Highlight entities only: false</p>
<p>Behavior:
- When user selects different sentence, tokens update with new labels
- When user toggles "Highlight entities only", O tokens fade to 50% opacity
- When user hovers over a token, show full annotation details in tooltip
- When user clicks "Add Custom Sentence", show text input and run simple rule-based NER</p>
<p>Implementation notes:
- Use p5.js for rendering tokens and interactions
- Implement simple regex-based NER for custom sentences (capital words = potential entities)
- Store pre-labeled examples with correct BIO tags
- Use color coding for clear visual distinction between entity types</p>
</details>
<h2 id="building-your-first-intent-based-chatbot">Building Your First Intent-Based Chatbot</h2>
<p>With an understanding of intents and entities, you're ready to build a practical intent-based chatbot. This architecture combines the intent classification and entity extraction techniques covered in this chapter to create a system that understands structured user requests and responds appropriately.</p>
<p>The basic architecture follows these steps:</p>
<ol>
<li>
<p><strong>Receive user input</strong>: Capture the user's message from a chat interface, API, or voice input transcription.</p>
</li>
<li>
<p><strong>Preprocess text</strong>: Normalize the input by lowercasing, removing extra whitespace, and handling special characters. Optionally apply spelling correction for robustness.</p>
</li>
<li>
<p><strong>Classify intent</strong>: Pass the preprocessed text through your intent classifier to determine which action the user wants to perform. If confidence is below your threshold (typically 0.6-0.8), route to a fallback handler.</p>
</li>
<li>
<p><strong>Extract entities</strong>: Run entity extraction to identify specific values referenced in the query. Combine rule-based extraction for common patterns with ML models for more complex entities.</p>
</li>
<li>
<p><strong>Validate completeness</strong>: Check whether all required entities for the identified intent have been extracted. If information is missing, generate a follow-up question to fill the gaps.</p>
</li>
<li>
<p><strong>Execute action</strong>: With intent and entities identified, trigger the appropriate system action—query a database, call an API, or retrieve a response from your knowledge base.</p>
</li>
<li>
<p><strong>Generate response</strong>: Format the results into a natural language response appropriate for the identified intent. Include error handling for failed actions.</p>
</li>
<li>
<p><strong>Collect feedback</strong>: Provide thumbs up/down or other feedback mechanisms to capture user satisfaction and improve your models over time.</p>
</li>
</ol>
<p>Let's walk through a concrete example. A user asks: "What's the weather like in Seattle tomorrow?"</p>
<p><strong>Step 1</strong>: Input received: "What's the weather like in Seattle tomorrow?"</p>
<p><strong>Step 2</strong>: Preprocessed: "what's the weather like in seattle tomorrow"</p>
<p><strong>Step 3</strong>: Intent classification:
- Intent: <code>check_weather</code> (confidence: 0.92)</p>
<p><strong>Step 4</strong>: Entity extraction:
- Location: "Seattle" (type: CITY)
- Date: "tomorrow" (normalized to: 2024-01-16)</p>
<p><strong>Step 5</strong>: Validation:
- Required entities present: location ✓, date ✓
- Proceed to action</p>
<p><strong>Step 6</strong>: Execute action:
- Call weather API: <code>getWeather(location="Seattle", date="2024-01-16")</code>
- Result: {temp: 52°F, conditions: "partly cloudy", precipitation: 20%}</p>
<p><strong>Step 7</strong>: Generate response:
- "The weather in Seattle tomorrow will be partly cloudy with a high of 52°F and a 20% chance of rain."</p>
<p><strong>Step 8</strong>: Display with feedback buttons for continuous improvement.</p>
<p>This straightforward pipeline handles the majority of user queries in task-oriented chatbots. More sophisticated systems add context tracking to handle multi-turn conversations, personalization based on user history, and graceful degradation when components fail.</p>
<p>Here's a comparison of different chatbot architectures and when to use each:</p>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Best For</th>
<th>Advantages</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td>Rule-based pattern matching</td>
<td>Simple FAQs, very small domain</td>
<td>Fast, predictable, no training needed</td>
<td>Brittle, doesn't scale</td>
</tr>
<tr>
<td>Intent + Entity extraction</td>
<td>Task-oriented chatbots with clear actions</td>
<td>Structured, interpretable, efficient</td>
<td>Requires training data, limited to predefined intents</td>
</tr>
<tr>
<td>Retrieval-based (RAG)</td>
<td>Knowledge-intensive Q&amp;A</td>
<td>Grounded responses, cites sources</td>
<td>Can't perform actions, needs good retrieval</td>
</tr>
<tr>
<td>Generative (LLM-based)</td>
<td>Open-domain conversation, creative tasks</td>
<td>Flexible, handles unexpected inputs</td>
<td>Unpredictable, hallucination risk, expensive</td>
</tr>
<tr>
<td>Hybrid (Intent + LLM)</td>
<td>Enterprise chatbots needing both structure and flexibility</td>
<td>Combines reliability and adaptability</td>
<td>More complex to build and maintain</td>
</tr>
</tbody>
</table>
<p>For most business applications—customer support, internal IT help desks, booking systems—the intent + entity extraction architecture offers the best balance of accuracy, control, and cost-effectiveness. You can always add generative components for specific use cases while maintaining structured handling for critical transactions.</p>
<h2 id="advanced-topics-context-and-multi-turn-dialogue">Advanced Topics: Context and Multi-Turn Dialogue</h2>
<p>Real conversations rarely consist of isolated single-turn exchanges. Users make references to previous statements, ask follow-up questions, and change topics mid-conversation. Handling this conversational context separates basic chatbots from sophisticated dialog systems.</p>
<p>Consider this multi-turn exchange:</p>
<p><strong>User</strong>: "What's the weather in Boston?"
<strong>System</strong>: "Currently 45°F and cloudy in Boston."
<strong>User</strong>: "What about tomorrow?"
<strong>System</strong>: "Tomorrow in Boston will be sunny with a high of 52°F."
<strong>User</strong>: "And New York?"
<strong>System</strong>: "Tomorrow in New York will be partly cloudy with a high of 48°F."</p>
<p>Notice how the system maintains context across turns. The second query "What about tomorrow?" omits the location, but the system understands it still refers to Boston from the first query. The third query "And New York?" changes the location but maintains the temporal context (tomorrow). This contextual resolution requires the system to track conversational state.</p>
<p>Modern dialog systems implement context tracking through several mechanisms:</p>
<ul>
<li>
<p><strong>Conversation history buffer</strong>: Store the last N turns of the conversation, feeding them as context to the intent classifier and entity extractor. This helps models understand references and pronouns.</p>
</li>
<li>
<p><strong>Entity memory</strong>: Maintain a dictionary of entities mentioned in the conversation, updating it as new information arrives. When entities are missing from the current query, check the memory before asking the user.</p>
</li>
<li>
<p><strong>Dialog state tracking</strong>: Model the conversation as a structured state object tracking the current task, filled slots, and next expected information. Common in task-oriented systems like booking or troubleshooting bots.</p>
</li>
<li>
<p><strong>Attention mechanisms</strong>: Use transformer models that can attend to relevant parts of conversation history when processing new inputs, automatically learning which context matters for each turn.</p>
</li>
</ul>
<p>The complexity of context tracking should match your use case. Simple FAQ bots may need no context at all. Task-oriented bots benefit from slot-filling frameworks. Open-domain conversational agents require sophisticated neural approaches to maintain coherence over long conversations.</p>
<h2 id="faq-analysis-for-continuous-improvement">FAQ Analysis for Continuous Improvement</h2>
<p>Building a chatbot is not a one-time effort—effective conversational systems evolve based on real user interactions. FAQ analysis provides systematic methods for identifying gaps, measuring performance, and prioritizing improvements.</p>
<p>Key metrics to track for FAQ and intent-based systems:</p>
<ul>
<li><strong>Coverage rate</strong>: Percentage of user queries that match to a known intent or FAQ above your confidence threshold</li>
<li><strong>Accuracy</strong>: For queries with user feedback, percentage marked as helpful/correct</li>
<li><strong>Response time</strong>: Latency from query submission to response delivery</li>
<li><strong>Escalation rate</strong>: Percentage of conversations that transfer to human agents</li>
<li><strong>Intent distribution</strong>: How frequently each intent appears in real traffic</li>
<li><strong>Unhandled query patterns</strong>: Clusters of low-confidence queries that might represent missing intents</li>
</ul>
<p>Regular FAQ analysis sessions should examine logs to find:</p>
<ol>
<li>
<p><strong>Common question variations</strong>: Multiple users asking the same thing in different ways suggests you need better training examples or synonym handling for that intent.</p>
</li>
<li>
<p><strong>Coverage gaps</strong>: Frequent low-confidence queries about topics not in your current intent set indicate missing capabilities.</p>
</li>
<li>
<p><strong>Ambiguous intents</strong>: Queries that oscillate between multiple intents or show low confidence across the board may indicate overlapping intent definitions needing refinement.</p>
</li>
<li>
<p><strong>Entity extraction failures</strong>: Queries where the intent was correctly identified but entity extraction missed critical information require better entity training data or additional extraction rules.</p>
</li>
<li>
<p><strong>Temporal patterns</strong>: Usage spikes for certain intents during specific times (e.g., "reset password" on Monday mornings, "check order status" after promotional emails) can inform staffing and proactive messaging.</p>
</li>
</ol>
<p>By analyzing these patterns monthly or quarterly, you can systematically improve your chatbot's capabilities. Start by focusing on high-frequency, low-accuracy queries—small improvements here deliver large impact. Build out coverage for newly discovered intents. Refine ambiguous intent boundaries to reduce classification errors.</p>
<p>The most successful chatbot teams implement continuous learning loops where user feedback directly updates training data, models retrain weekly or monthly, and performance dashboards make improvement trends visible to stakeholders.</p>
<h2 id="summary-and-key-takeaways">Summary and Key Takeaways</h2>
<p>This chapter introduced the foundational concepts for building conversational interfaces that understand user intentions and extract relevant information from natural language queries. You learned how chatbots and conversational agents differ in sophistication, how dialog systems manage multi-turn conversations, and how intent classification and entity extraction transform unstructured text into actionable structured data.</p>
<p>Key concepts to remember:</p>
<ul>
<li><strong>User queries</strong> are natural language inputs that express intents and contain entities needing extraction</li>
<li><strong>FAQ systems</strong> map user questions to predefined answers, forming the simplest conversational interface</li>
<li><strong>Chatbots</strong> range from simple rule-based systems to sophisticated conversational agents with context tracking</li>
<li><strong>Dialog systems</strong> manage multi-turn conversations with state tracking and context awareness</li>
<li><strong>Intent recognition</strong> identifies what users want; <strong>entity extraction</strong> identifies the specific details they're referencing</li>
<li><strong>Intent modeling</strong> requires careful design to balance granularity, coverage, and actionability</li>
<li><strong>Named Entity Recognition (NER)</strong> identifies people, places, organizations, and other proper nouns</li>
<li><strong>Entity linking</strong> connects recognized entities to knowledge base entries for deeper semantic understanding</li>
<li><strong>Context tracking</strong> enables multi-turn conversations by maintaining entity memory and conversation history</li>
<li><strong>FAQ analysis</strong> drives continuous improvement by identifying coverage gaps and accuracy issues</li>
</ul>
<p>These concepts form the foundation for more advanced conversational AI architectures. In later chapters, you'll see how Retrieval Augmented Generation (RAG) extends beyond FAQ matching with semantic search, how knowledge graphs enable entity linking and reasoning, and how modern LLMs can handle both intent classification and entity extraction through prompting rather than training specialized models.</p>
<p>The intent + entity architecture remains fundamental even as models grow more sophisticated—understanding what users want and what information they're providing applies whether you're using regex patterns, fine-tuned BERT models, or few-shot prompting with GPT-4. Master these concepts, and you'll be prepared to build conversational interfaces across the full spectrum of modern AI approaches.</p>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../05-embeddings-vector-databases/quiz/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Quiz">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
          </a>
        
        
          
          <a href="quiz/" class="md-footer__link md-footer__link--next" aria-label="Next: Quiz">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "toc.follow", "navigation.top", "navigation.footer", "content.action.edit"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../js/extra.js"></script>
      
    
  </body>
</html>